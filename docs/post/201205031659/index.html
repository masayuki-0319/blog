<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link rel="canonical" href="http://yut.hatenablog.com/entry/20120503/1336031972" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.55.4" />

  <title>Apache Mahout 機械学習Libraryを使って「魔法少女まどか☆マギカ」の台詞をテキストマイニングしてみた &middot; Y&#39;s note</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://yutakikuchi.github.io/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://yutakikuchi.github.io/css/my.css">
    
  
  
    
        <script src="https://yutakikuchi.github.io/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://yutakikuchi.github.io/">Y's note</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/yutakikuchi_" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://facebook.com/yuta.kikuchi.007" target="_blank"><i class="fa fa-facebook-square fa-fw"></i>Facebook</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/https://www.slideshare.net/yutakikuchi58/" target="_blank"><i class="fa fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/https://www.linkedin.com/in/%E4%BD%91%E5%A4%AA-%E8%8F%8A%E6%B1%A0-36291a44/" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yutakikuchi" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2019. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Apache Mahout 機械学習Libraryを使って「魔法少女まどか☆マギカ」の台詞をテキストマイニングしてみた</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 May 03, 16:59</time>
  </div>

  

  

  

</div>

  

<h2 id="hadoop-apache-mahout-機械学習libraryを使って-魔法少女まどか-マギカ-の台詞をテキストマイニングしてみた">[Hadoop] : Apache Mahout 機械学習Libraryを使って「魔法少女まどか☆マギカ」の台詞をテキストマイニングしてみた</h2>

<p><div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/1935182684/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/51RzkfSSfBL._SL160_.jpg" class="hatena-asin-detail-image" alt="Mahout in Action" title="Mahout in Action"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/1935182684/yutakikuchi-22/">Mahout in Action</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> Sean Owen,Robin Anil,Ted Dunning,Ellen Friedman</li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> Manning Pubns Co</li><li><span class="hatena-asin-detail-label">発売日:</span> 2011/10/28</li><li><span class="hatena-asin-detail-label">メディア:</span> ペーパーバック</li><li><span class="hatena-asin-detail-label">購入</span>: 4人 <span class="hatena-asin-detail-label">クリック</span>: 81回</li><li><a href="http://d.hatena.ne.jp/asin/1935182684/yutakikuchi-22" target="_blank">この商品を含むブログ (10件) を見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

<div class="section">
<h4>Index</h4>

<blockquote>
    
<ul>
<li>Information & Links</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> Mahout
<ul>
<li>Abouc <a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> Mahout</li>
<li>Mahout has machine learning libraries</li>
<li>Mahout Download / Setting</li>
</ul></li>
<li>Madmagi Words
<ul>
<li>Scraping</li>
<li>Word MA</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a> MA</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a> PUT</li>
</ul></li>
<li>Clustering Theory
<ul>
<li>TF/IDF</li>
<li>K-Means</li>
<li>Canopy Clustering</li>
</ul></li>
<li>Word <a class="keyword" href="http://d.hatena.ne.jp/keyword/Vector">Vector</a></li>
<li>Clustering</li>
<li>Graph Display
<ul>
<li>Required JAR</li>
<li>Sample Graph Image</li>
</ul></li>
</ul>
</blockquote>

</div>
<div class="section">
<h4>Information & Links</h4>

<blockquote>
    <p>この記事は「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CB%E2%CB%A1%BE%AF%BD%F7%A4%DE%A4%C9%A4%AB%A1%F9%A5%DE%A5%AE%A5%AB">魔法少女まどか☆マギカ</a>」の台詞を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>によりClusteringした内容についての記録です。<span class="deco" style="color:#FF0000;font-weight:bold;">Clustering/Graph Image出力などの実験/検証が不十分であるため後日再挑戦します</span>ができたところまで公開します。以下はこの記事で参考にしたリンクです。</p>

<ul>
<li><a href="http://d.hatena.ne.jp/yutakikuchi/20120403/1333409284">「魔法少女まどか☆マギカ」の台詞をJavaScriptでMapReduceしてGoogle Chart APIでグラフ出力したよ！ - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20120403/1333409284"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20120403/1333409284" alt="はてなブックマーク - 「魔法少女まどか☆マギカ」の台詞をJavaScriptでMapReduceしてGoogle Chart APIでグラフ出力したよ！ - Yuta.Kikuchiの日記" border="0" /></a></li>
<li><a href="http://www.atmarkit.co.jp/fjava/rensai4/bigdata_java04/01.html">試すのが難しい―機械学習の常識はMahoutで変わる (1/3) - ＠IT</a> <a href="http://b.hatena.ne.jp/entry/www.atmarkit.co.jp/fjava/rensai4/bigdata_java04/01.html"><img src="http://b.hatena.ne.jp/entry/image/http://www.atmarkit.co.jp/fjava/rensai4/bigdata_java04/01.html" alt="はてなブックマーク - 試すのが難しい―機械学習の常識はMahoutで変わる (1/3) - ＠IT" border="0" /></a></li>
<li><a href="http://www.ibm.com/developerworks/jp/java/library/j-mahout/">Apache Mahout の紹介</a> <a href="http://b.hatena.ne.jp/entry/www.ibm.com/developerworks/jp/java/library/j-mahout/"><img src="http://b.hatena.ne.jp/entry/image/http://www.ibm.com/developerworks/jp/java/library/j-mahout/" alt="はてなブックマーク - Apache Mahout の紹介" border="0" /></a></li>
<li><a href="http://sites.google.com/site/mahoutjp/">Mahout JP</a> <a href="http://b.hatena.ne.jp/entry/sites.google.com/site/mahoutjp/"><img src="http://b.hatena.ne.jp/entry/image/http://sites.google.com/site/mahoutjp/" alt="はてなブックマーク - Mahout JP" border="0" /></a></li>
<li><a href="http://www.atmarkit.co.jp/fjava/index/index_hadoop_tm.html">テキストマイニングで始める実践Hadoop活用</a> <a href="http://b.hatena.ne.jp/entry/www.atmarkit.co.jp/fjava/index/index_hadoop_tm.html"><img src="http://b.hatena.ne.jp/entry/image/http://www.atmarkit.co.jp/fjava/index/index_hadoop_tm.html" alt="はてなブックマーク - テキストマイニングで始める実践Hadoop活用" border="0" /></a></li>
<li><a href="http://hadoop.apache.org/common/docs/r0.20.2/api/">Overview (Hadoop 0.20.2 API)</a> <a href="http://b.hatena.ne.jp/entry/hadoop.apache.org/common/docs/r0.20.2/api/"><img src="http://b.hatena.ne.jp/entry/image/http://hadoop.apache.org/common/docs/r0.20.2/api/" alt="はてなブックマーク - Overview (Hadoop 0.20.2 API)" border="0" /></a></li>
<li><a href="http://javasourcecode.org/html/open-source/">Open Source Java Code Online - JavaSourceCode</a> <a href="http://b.hatena.ne.jp/entry/javasourcecode.org/html/open-source/"><img src="http://b.hatena.ne.jp/entry/image/http://javasourcecode.org/html/open-source/" alt="はてなブックマーク - Open Source Java Code Online - JavaSourceCode" border="0" /></a></li>
<li><a href="http://www.java2s.com/Code/Jar/CatalogJar.htm">Jar File Download examples (example source code) Organized by topic</a> <a href="http://b.hatena.ne.jp/entry/www.java2s.com/Code/Jar/CatalogJar.htm"><img src="http://b.hatena.ne.jp/entry/image/http://www.java2s.com/Code/Jar/CatalogJar.htm" alt="はてなブックマーク - Jar File Download examples (example source code) Organized by topic" border="0" /></a></li>
</ul>
</blockquote>

</div>
<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> Mahout</h4>

<blockquote>
    
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> Mahout</h5>
<p><a href="http://mahout.apache.org/">Apache Mahout: Scalable machine learning and data mining</a> <a href="http://b.hatena.ne.jp/entry/mahout.apache.org/"><img src="http://b.hatena.ne.jp/entry/image/http://mahout.apache.org/" alt="はてなブックマーク - Apache Mahout: Scalable machine learning and data mining" border="0" /></a><br />
Mahout(マハウト)と呼ぶ<a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> <a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>と利用できるスケーラブルな<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>ライブラリです。協調学習やユーザレコメンド、k-meansなどの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>のライブラリ機能を持っているためそれらを簡単に利用できます。</p>

</div>
<div class="section">
<h5>Mahout has machine learning libraries</h5>
<p>Mahoutには以下の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>ライブラリが備わっています。</p>

<ul>
<li>Collaborative Filtering</li>
<li>User and Item based recommenders</li>
<li>K-Means, Fuzzy K-Means clustering</li>
<li>Mean Shift clustering</li>
<li>Dirichlet process clustering</li>
<li>Latent Dirichlet Allocation</li>
<li>Singular value decomposition</li>
<li>Parallel Frequent Pattern mining</li>
<li>Complementary Naive Bayes classifier</li>
<li>Random forest decision tree based classifier</li>
<li>High performance <a class="keyword" href="http://d.hatena.ne.jp/keyword/java">java</a> collections (previously colt collections)</li>
<li>A vibrant community</li>
<li>and many more cool stuff to come by this summer thanks to <a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a> <a class="keyword" href="http://d.hatena.ne.jp/keyword/summer%20of%20code">summer of code</a></li>
</ul>
</div>
<div class="section">
<h5>Mahout Download / Setting</h5>
<p><a href="http://ftp.meisei-u.ac.jp/mirror/apache/dist/mahout/">http://ftp.meisei-u.ac.jp/mirror/apache/dist/mahout/</a><br />
ここからMahoutをダウンロード/インストールします。ここでの説明は既に<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>がインストールされている事を前提としています。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>の設定については<a href="http://d.hatena.ne.jp/yutakikuchi/20111205/1323041424">CentOSでHadoopを使ってみる - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20111205/1323041424"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20111205/1323041424" alt="はてなブックマーク - CentOSでHadoopを使ってみる - Yuta.Kikuchiの日記" border="0" /></a>を参照してください。基本的にはmahout本体の展開だけで動くと思いますが、<a href="http://maven.apache.org/download.html">Maven</a>が必要な場合はインストールしてください。尚今回インストールした環境はCentos5.7になります。Mahoutを動かすには<a class="keyword" href="http://d.hatena.ne.jp/keyword/JAVA">JAVA</a>_HOME、<a class="keyword" href="http://d.hatena.ne.jp/keyword/HADOOP">HADOOP</a>_HOME、<a class="keyword" href="http://d.hatena.ne.jp/keyword/HADOOP">HADOOP</a>_CONF_DIRの環境設定が必要なので.zshrcに加えておきます。</p>
<pre class="code" data-lang="" data-unlink>$ cat /etc/redhat-release 
CentOS release 5.7 (Final)

$ wget http://ftp.meisei-u.ac.jp/mirror/apache/dist/mahout/0.6/mahout-distribution-0.6.tar.gz
$ tar -xzf mahout-distribution-0.6.tar.gz
$ file mahout-distribution-0.6/bin/mahout //実行コマンド
mahout-distribution-0.6/bin/mahout: Bourne-Again shell script text executable
$ cd mahout-distribution-0.6
$ ls -al
-rw-r--r--  1 yuta yuta    39588  2月  1 22:30 LICENSE.txt
-rw-r--r--  1 yuta yuta     1888  2月  1 22:30 NOTICE.txt
-rw-r--r--  1 yuta yuta     1200  2月  1 22:30 README.txt
drwxr-xr-x  2 yuta yuta     4096  4月  8 19:15 bin
drwxr-xr-x  3 yuta yuta     4096  4月  8 19:15 buildtools
drwxr-xr-x  2 yuta yuta     4096  2月  1 22:29 conf
drwxr-xr-x  3 yuta yuta     4096  4月  8 19:15 core
drwxr-xr-x  3 yuta yuta     4096  4月  8 19:15 distribution
drwxr-xr-x  6 yuta yuta     4096  4月  8 19:15 docs
drwxr-xr-x  5 yuta yuta     4096  4月  8 19:15 examples
drwxr-xr-x  3 yuta yuta     4096  4月  8 19:15 integration
drwxr-xr-x  2 yuta yuta     4096  4月  8 19:15 lib
-rw-r--r--  1 yuta yuta 11190212  2月  1 22:31 mahout-core-0.6-job.jar
-rw-r--r--  1 yuta yuta  1662876  2月  1 22:31 mahout-core-0.6.jar
-rw-r--r--  1 yuta yuta 23593299  2月  1 22:33 mahout-examples-0.6-job.jar
-rw-r--r--  1 yuta yuta   379461  2月  1 22:33 mahout-examples-0.6.jar
-rw-r--r--  1 yuta yuta   284781  2月  1 22:32 mahout-integration-0.6.jar
-rw-r--r--  1 yuta yuta   288914  2月  1 22:30 mahout-math-0.6.jar
drwxr-xr-x  3 yuta yuta     4096  4月  8 19:15 math</pre><pre class="code" data-lang="" data-unlink>export JAVA_HOME=/usr/java/default/
export PATH=$JAVA_HOME/bin:$PATH
export HADOOP_HOME=/usr/lib/hadoop-0.20
export HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
export PATH=$HADOOP_HOME/bin:$PATH</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4>Madmagi Words</h4>

<blockquote>
    <p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%CB%E2%CB%A1%BE%AF%BD%F7%A4%DE%A4%C9%A4%AB%A1%F9%A5%DE%A5%AE%A5%AB">魔法少女まどか☆マギカ</a>の台詞をScrapingします。Scrapingした結果をNLTKを利用して単語区切りと<a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a>によるMAした結果を<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a> <a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a>上に保存します。</p>

<div class="section">
<h5>Scraping</h5>
<pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>

<span class="synPreProc">import</span> sys,re,urllib,urllib2
urls = ( <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/170.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/175.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/179.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/180.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/200.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/247.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/244.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/249.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/250.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/252.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/241.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/254.html'</span>
     )   
f = <span class="synIdentifier">open</span>( <span class="synConstant">'./madmagi.txt'</span>, <span class="synConstant">'w'</span> )
opener = urllib2.build_opener()
ua = <span class="synConstant">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/    534.51.22'</span>
referer = <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/'</span>
opener.addheaders = [( <span class="synConstant">'User-Agent'</span>, ua ),( <span class="synConstant">'Referer'</span>, referer )]
<span class="synStatement">for</span> url <span class="synStatement">in</span> urls:
content = opener.<span class="synIdentifier">open</span>( url ).read()
<span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<div class="contents".*?>((.|\n)*?)</div>'</span>, re.M ).search( content ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
    data = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<div class="contents".*?>((.|\n)*?)</div>'</span>, re.M ).search( content ).group()
    <span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'「(.*?)」'</span>, re.M ).search( data ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>: 
        lines = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'「(.*?)」'</span>, re.M ).findall( data )
        <span class="synStatement">for</span> line <span class="synStatement">in</span> lines:
            f.write( line + <span class="synConstant">"</span><span class="synSpecial">\n</span><span class="synConstant">"</span> )
f.close()
</pre>
</div>
<div class="section">
<h5>Word MA</h5>
<p>スペース区切りで<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%AC%A4%AB%A4%C1%BD%F1%A4%AD">分かち書き</a>を行います。</p>
<pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> nltk
<span class="synPreProc">from</span> nltk.corpus.reader <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.corpus.reader.util <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.text <span class="synPreProc">import</span> Text

jp_sent_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'[^　「」！？。]*[！？。]'</span>)
jp_chartype_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'([ぁ-んー]+|[ァ-ンー]+|[</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+|[^ぁ-んァ-ンー</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+)'</span>)
data = PlaintextCorpusReader( <span class="synConstant">'./'</span>, <span class="synConstant">r'madmagi.txt'</span>,
                          encoding=<span class="synConstant">'utf-8'</span>,
                          para_block_reader=read_line_block,
                          sent_tokenizer=jp_sent_tokenizer,
                          word_tokenizer=jp_chartype_tokenizer )

<span class="synComment">#ファイル保存</span>
f = <span class="synIdentifier">open</span>( <span class="synConstant">'./word.txt'</span>, <span class="synConstant">'w'</span> )
<span class="synStatement">for</span> i <span class="synStatement">in</span> data.words():
f.write( i + <span class="synConstant">" "</span> )
f.close
</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a> MA</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a>による<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%AC%A4%AB%A4%C1%BD%F1%A4%AD">分かち書き</a>を行います。</p>
<pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> MeCab
mecab = MeCab.Tagger(<span class="synConstant">'-Ochasen'</span>)

data = <span class="synIdentifier">open</span>( <span class="synConstant">'./madmagi.txt'</span> ).read()

f = <span class="synIdentifier">open</span>( <span class="synConstant">'./ma.txt'</span>, <span class="synConstant">'w'</span> )

node = mecab.parseToNode( data )
phrases = node.<span class="synIdentifier">next</span>
<span class="synStatement">while</span> phrases:
<span class="synStatement">try</span>:
    k = node.surface
    f.write( k + <span class="synConstant">" "</span> )
    node = node.<span class="synIdentifier">next</span>
<span class="synStatement">except</span> <span class="synType">AttributeError</span>:
   <span class="synStatement">break</span> 
f.close()
</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a> PUT</h5>
<p>抽出したWordMA/MecabMAデータを<a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a>上にputします。</p>
<pre class="code" data-lang="" data-unlink>$ alias hdfs='hadoop dfs'
$ hdfs -mkdir madmagi
$ hdfs -put data/ma.txt madmagi_in/
$ hdfs -put data/word.txt madmagi_in/
$ hdfs -lsr madmagi_in
-rw-r--r--   1 yuta supergroup     104440 2012-03-26 01:16 /user/yuta/madmagi_in/ma.txt
-rw-r--r--   1 yuta supergroup     101266 2012-03-26 01:16 /user/yuta/madmagi_in/word.txt</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4>Clustering Theory</h4>

<blockquote>
    <p>Mahoutの処理を行う前に理論的な内容を少し整理します。</p>

<div class="section">
<h5>TF/IDF</h5>
<p><a href="http://ja.wikipedia.org/wiki/Tf-idf">tf-idf - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/Tf-idf"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/Tf-idf" alt="はてなブックマーク - tf-idf - Wikipedia" border="0" /></a><br />
情報検索に置ける単語の重み付けの手法。TFが単語出現頻度、IDFが逆文書頻度といった内容で単語の重要度を測る手法です。</p>

</div>
<div class="section">
<h5>K-Means</h5>
<p><a href="http://ja.wikipedia.org/wiki/K平均法">K平均法 - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/K平均法"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/K平均法" alt="はてなブックマーク - K平均法 - Wikipedia" border="0" /></a><br />
K平均法は単純な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF%A5%EA%A5%F3%A5%B0">クラスタリング</a><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>で、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>の中心計算を反復させより精度の高い<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>を導きだす仕組みです。以下に単純な処理の流れを記載します。</p>

<ol>
<li>各nodeに対してランダムな<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>を割り当てる。</li>
<li>割り当てた<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>の中心を計算する。</li>
<li>計算した中心に対して近いnodeを割り当てる。</li>
<li>再度<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>の中心を計算。以降<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>が変化しなくなるまで任意の数繰り返す。</li>
</ol>
</div>
<div class="section">
<h5>Canopy Clustering</h5>
<p><a href="https://cwiki.apache.org/MAHOUT/canopy-clustering.html">Canopy Clustering</a> <a href="http://b.hatena.ne.jp/entry/s/cwiki.apache.org/MAHOUT/canopy-clustering.html"><img src="http://b.hatena.ne.jp/entry/image/https://cwiki.apache.org/MAHOUT/canopy-clustering.html" alt="はてなブックマーク - Canopy Clustering" border="0" /></a><br />
Canopy Clusteringについても簡単に触れます。Canopyは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF%A5%EA%A5%F3%A5%B0">クラスタリング</a>の中心点からT1、T2という最大半径、最小半径を指定しそれらを同一<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>として認識させます。</p>

</div>
</blockquote>

</div>
<div class="section">
<h4>Word <a class="keyword" href="http://d.hatena.ne.jp/keyword/Vector">Vector</a></h4>

<blockquote>
    <p>Mahoutを利用して<a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a> MAした結果を<a class="keyword" href="http://d.hatena.ne.jp/keyword/vector">vector</a>に変換します。※Word MAの方については記述しませんが、MecabMAと同様に行えばClustering可能だと思います。変換にはMahoutのseqdirectoryとseq2sparseコマンドを使います。まずはseqdirectoryとseq2sparseコマンドのhelpを見てみます。</p>
<pre class="code" data-lang="" data-unlink>$ bin/mahout seqdirectory -h
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
usage: <command> [Generic Options] [Job-Specific Options]
Generic Options:
 -archives <paths>              comma separated archives to be unarchived
                            on the compute machines.
 -conf <configuration file>     specify an application configuration file
 -D <property=value>            use value for given property
 -files <paths>                 comma separated files to be copied to the
                            map reduce cluster
 -fs <local|namenode:port>      specify a namenode
 -jt <local|jobtracker:port>    specify a job tracker
 -libjars <paths>               comma separated jar files to include in
                            the classpath.
 -tokenCacheFile <tokensFile>   name of the file with the tokens
Job-Specific Options:                                                           
  --input (-i) input                             Path to job input directory.   
  --output (-o) output                           The directory pathname for     
                                             output.                        
  --overwrite (-ow)                              If present, overwrite the      
                                             output directory before        
                                             running job                    
  --chunkSize (-chunk) chunkSize                 The chunkSize in MegaBytes.    
                                             Defaults to 64                 
  --fileFilterClass (-filter) fileFilterClass    The name of the class to use   
                                             for file parsing. Default:     
                                             org.apache.mahout.text.PrefixAd
                                             ditionFilter                   
  --keyPrefix (-prefix) keyPrefix                The prefix to be prepended to  
                                             the key                        
  --charset (-c) charset                         The name of the character      
                                             encoding of the input files.   
                                             Default to UTF-8               
  --help (-h)                                    Print out help                 
  --tempDir tempDir                              Intermediate output directory  
  --startPhase startPhase                        First phase to run             
  --endPhase endPhase                            Last phase to run              

$ bin/mahout seq2sparse -h  
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
Usage:                                                                          
 [--minSupport <minSupport> --analyzerName <analyzerName> --chunkSize           
<chunkSize> --output <output> --input <input> --minDF <minDF> --maxDFSigma      
<maxDFSigma> --maxDFPercent <maxDFPercent> --weight <weight> --norm <norm>      
--minLLR <minLLR> --numReducers <numReducers> --maxNGramSize <ngramSize>        
--overwrite --help --sequentialAccessVector --namedVector --logNormalize]       
Options                                                                         
  --minSupport (-s) minSupport        (Optional) Minimum Support. Default       
                                  Value: 2                                  
  --analyzerName (-a) analyzerName    The class name of the analyzer            
  --chunkSize (-chunk) chunkSize      The chunkSize in MegaBytes. 100-10000 MB  
  --output (-o) output                The directory pathname for output.        
  --input (-i) input                  Path to job input directory.              
  --minDF (-md) minDF                 The minimum document frequency.  Default  
                                  is 1                                      
  --maxDFSigma (-xs) maxDFSigma       What portion of the tf (tf-idf) vectors   
                                  to be used, expressed in times the        
                                  standard deviation (sigma) of the         
                                  document frequencies of these vectors.    
                                  Can be used to remove really high         
                                  frequency terms. Expressed as a double    
                                  value. Good value to be specified is 3.0. 
                                  In case the value is less then 0 no       
                                  vectors will be filtered out. Default is  
                                  -1.0.  Overrides maxDFPercent             
  --maxDFPercent (-x) maxDFPercent    The max percentage of docs for the DF.    
                                  Can be used to remove really high         
                                  frequency terms. Expressed as an integer  
                                  between 0 and 100. Default is 99.  If     
                                  maxDFSigma is also set, it will override  
                                  this value.                               
  --weight (-wt) weight               The kind of weight to use. Currently TF   
                                  or TFIDF                                  
  --norm (-n) norm                    The norm to use, expressed as either a    
                                  float or "INF" if you want to use the     
                                  Infinite norm.  Must be greater or equal  
                                  to 0.  The default is not to normalize    
  --minLLR (-ml) minLLR               (Optional)The minimum Log Likelihood      
                                  Ratio(Float)  Default is 1.0              
  --numReducers (-nr) numReducers     (Optional) Number of reduce tasks.        
                                  Default Value: 1                          
  --maxNGramSize (-ng) ngramSize      (Optional) The maximum size of ngrams to  
                                  create (2 = bigrams, 3 = trigrams, etc)   
                                  Default Value:1                           
  --overwrite (-ow)                   If set, overwrite the output directory    
  --help (-h)                         Print out help                            
  --sequentialAccessVector (-seq)     (Optional) Whether output vectors should  
                                  be SequentialAccessVectors. If set true   
                                  else false                                
  --namedVector (-nv)                 (Optional) Whether output vectors should  
                                  be NamedVectors. If set true else false   
  --logNormalize (-lnorm)             (Optional) Whether output vectors should  
                                  be logNormalize. If set true else false</pre><p>seqdirectoryにてテキ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%C8%A5%D5%A5%A1%A5%A4">ストファイ</a>ルをSequenceFileに変換、seq2sparseにてSequenceFileを<a class="keyword" href="http://d.hatena.ne.jp/keyword/vector">vector</a>にします。seq2sparseのオプションで重要な項目を表にします。</p>

<table>
<tr>
<th> option </th>
<th> 説明 </th>
</tr>
<tr>
<td> minSupport </td>
<td> レコードごとの最少登場回数 </td>
</tr>
<tr>
<td> minDF </td>
<td> 最少登場文書数 </td>
</tr>
<tr>
<td> maxDFPercent </td>
<td> 登場する文書の割合がこれを超えたら不採用 </td>
<td> </td>
</tr>
<tr>
<td> maxNGramSize </td>
<td> 熟語の可能性を検討する最大語数 </td>
</tr>
<tr>
<td> minLLR  </td>
<td> 熟語として採用するための同時発生確率の最少値 </td>
</tr>
<tr>
<td> sequentialAccessVector </td>
<td> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%E0%BC%A1">逐次</a>アクセス用のファイル形式 </td>
</tr>
<tr>
<td> namedVector </td>
<td> 各<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%AF%A5%BF">ベクタ</a>に名前を付ける </td>
<td> </td>
</tr>
</table><pre class="code" data-lang="" data-unlink>$ bin/mahout seqdirectory \
--input madmagi_in/ma.txt \
--output madmagi_out_ma/seq \
-c UTF-8
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 08:46:20 INFO common.AbstractJob: Command line arguments: {--charset=UTF-8, --chunkSize=64, --endPhase=2147483647, --fileFilterClass=org.apache.mahout.text.PrefixAdditionFilter, --input=madmagi_in/ma.txt, --keyPrefix=, --output=madmagi_out_ma/seq, --startPhase=0, --tempDir=temp}
12/05/03 08:46:25 INFO driver.MahoutDriver: Program took 5835 ms (Minutes: 0.09725)

$ bin/mahout seq2sparse \
--input madmagi_out_ma/seq \
--output madmagi_out_ma/vector \
--minSupport 10 \
--minDF 20 \
--maxDFPercent 40 \
--maxNGramSize 3</pre><p>それぞれの解析結果により<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>種類のファイルが作成されます。</p>
<pre class="code" data-lang="" data-unlink>$ hdfs -ls madmagi_out_ma/vector
Found 7 items
drwxr-xr-x   - yuta supergroup          0 2012-05-03 09:32 /user/yuta/madmagi_out_ma/vector/df-count
-rw-r--r--   1 yuta supergroup      17602 2012-05-03 09:30 /user/yuta/madmagi_out_ma/vector/dictionary.file-0
-rw-r--r--   1 yuta supergroup      17613 2012-05-03 09:32 /user/yuta/madmagi_out_ma/vector/frequency.file-0
drwxr-xr-x   - yuta supergroup          0 2012-05-03 09:31 /user/yuta/madmagi_out_ma/vector/tf-vectors
drwxr-xr-x   - yuta supergroup          0 2012-05-03 09:33 /user/yuta/madmagi_out_ma/vector/tfidf-vectors
drwxr-xr-x   - yuta supergroup          0 2012-05-03 09:29 /user/yuta/madmagi_out_ma/vector/tokenized-documents
drwxr-xr-x   - yuta supergroup          0 2012-05-03 09:30 /user/yuta/madmagi_out_ma/vector/wordcount</pre><p><span class="deco" style="color:#FF0000;font-weight:bold;">seqdumperまたはvectordump</span>を使って作成されたSequenceFileの中身を見てみます。tfidfの<a class="keyword" href="http://d.hatena.ne.jp/keyword/vector">vector</a>値とwordcountのが分かります。wordcountはグリーフシード/<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BD%A5%A6%A5%EB%A5%B8%A5%A7%A5%E0">ソウルジェム</a>/ワルプルギス/マミなどの特徴的な単語数が多く目立ちます。</p>
<pre class="code" data-lang="" data-unlink>$ bin/mahout seqdumper -s /user/yuta/madmagi_out_ma/vector/tfidf-vectors/part-r-00000
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 10:38:17 INFO common.AbstractJob: Command line arguments: &#230;--endPhase=2147483647, --seqFile=/user/yuta/madmagi_out_ma/vector/tfidf-vectors/part-r-00000, --startPhase=0, --tempDir=temp&#229;
Input Path: /user/yuta/madmagi_out_ma/vector/tfidf-vectors/part-r-00000
Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.mahout.math.VectorWritable
Key: /ma.txt: Value: &#230;867:-6.465347766876221,866:-7.082433700561523,865:-9.58966064453125,
864:-15.704275131225586,863:-16.735137939453125,862:-9.369179725646973,861:-6.465347766876221,860:-15.299805641174316,859:-9.80518627166748,
858:-8.674174308776855,857:-6.780914306640625,856:-6.465347766876221,855:-8.674174308776855,854:-10.818595886230469,853:-7.918401718139648,

$ bin/mahout seqdumper -s /user/yuta/madmagi_out_ma/vector/wordcount/ngrams/part-r-00000
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 10:41:25 INFO common.AbstractJob: Command line arguments: &#230;--endPhase=2147483647, --seqFile=/user/yuta/madmagi_out_ma/vector/wordcount/ngrams/part-r-00000, --startPhase=0, --tempDir=temp&#229;
Input Path: /user/yuta/madmagi_out_ma/vector/wordcount/ngrams/part-r-00000
Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.hadoop.io.DoubleWritable

Key: アイツ: Value: 12.0
Key: アタシ: Value: 30.0
Key: アンタ: Value: 30.0
Key: エネルギー: Value: 12.0
Key: キュゥ: Value: 13.0
Key: グリーフシード: Value: 10.0
Key: ソウルジェム: Value: 17.0
Key: ダメ: Value: 15.0
Key: バカ: Value: 16.0
Key: ホント: Value: 10.0
Key: マミ: Value: 20.0
Key: ワルプルギス: Value: 10.0</pre><p>上のseq2sparseの結果のTF/IDFの値がマイナスになっているのが気持ち悪いのでseq2sparseの実行オプションを修正して再度実行します。</p>
<pre class="code" data-lang="" data-unlink>$ bin/mahout seq2sparse \
--input madmagi_out_ma/seq \
--output madmagi_out_ma_test/vector \
--maxDFPercent 40 \
--maxNGramSize 6 \
--sequentialAccessVector \
--namedVector

$ bin/mahout seqdumper -s /user/yuta/madmagi_out_ma_test/vector/tfidf-vectors/part-r-00000
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 12:58:43 INFO common.AbstractJob: Command line arguments: {--endPhase=2147483647, --seqFile=/user/yuta/madmagi_out_ma_test/vector/tfidf-vectors/part-r-00000, --startPhase=0, --tempDir=temp}
Input Path: /user/yuta/madmagi_out_ma_test/vector/tfidf-vectors/part-r-00000
Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.mahout.math.VectorWritable
Key: /ma.txt: Value: /ma.txt:{0:0.4339554011821747,1:0.4339554011821747,2:0.811856210231781,3:2.1479697227478027,4:5.765240669250488,5:0.6861437559127808,6:10.023337364196777,7:1.0177156925201416,8:6.868295669555664,9:2.1479697227478027,
10:4.653653144836426,11:2.744575023651123,12:8.564437866210938,13:5.699537754058838,14:4.01262092590332,15:1.4716144800186157,16:4.572004318237305,17:1.3722875118255615,18:4.713962554931641,
19:1.708484172821045,20:5.341354846954346,21:2.0584311485290527

$ bin/mahout seqdumper -s /user/yuta/madmagi_out_ma_test/vector/wordcount/ngrams/part-r-00000
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 13:06:39 INFO common.AbstractJob: Command line arguments: {--endPhase=2147483647, --seqFile=/user/yuta/madmagi_out_ma_test/vector/wordcount/ngrams/part-r-00000, --startPhase=0, --tempDir=temp}
Input Path: /user/yuta/madmagi_out_ma_test/vector/wordcount/ngrams/part-r-00000
Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.hadoop.io.DoubleWritable

Key: アイツ: Value: 12.0
Key: アタシ: Value: 30.0
Key: アンタ: Value: 30.0
Key: イレギュラー: Value: 2.0
Key: インキュベーター: Value: 3.0
Key: ウザ: Value: 3.0
Key: ウゼェ: Value: 2.0
Key: エネルギー: Value: 12.0
Key: エントロピー: Value: 2.0
Key: オイ: Value: 5.0
Key: オイッ: Value: 2.0
Key: カッコ: Value: 3.0
Key: キュゥ: Value: 13.0
Key: キュウ: Value: 2.0
Key: クラス: Value: 2.0
Key: グリーフシード: Value: 10.0
Key: コイツ: Value: 5.0
Key: ゴメン: Value: 2.0
Key: ゼロ: Value: 2.0
Key: ソウルジェム: Value: 17.0
Key: ゾンビ: Value: 2.0
Key: タツヤ: Value: 2.0
Key: ダメ: Value: 15.0
Key: チッ: Value: 2.0
Key: ッ: Value: 5.0
Key: テメェ: Value: 9.0
Key: ナメ: Value: 3.0
Key: ハッ: Value: 3.0
Key: バカ: Value: 16.0
Key: バランス: Value: 2.0
Key: バレ: Value: 2.0
Key: ベテラン: Value: 2.0
Key: ホント: Value: 10.0
Key: ママ: Value: 2.0
Key: マミ: Value: 20.0
Key: ミス: Value: 3.0
Key: モノ: Value: 2.0
Key: リハビリ: Value: 4.0
Key: リンゴ: Value: 2.0
Key: ルール: Value: 3.0
Key: ワルプルギス: Value: 10.0</pre>
</blockquote>

</div>
<div class="section">
<h4>Clustering</h4>

<blockquote>
    <p>以下ではCanopyとK-meansのClusteringを行います。<a class="keyword" href="http://d.hatena.ne.jp/keyword/vector">vector</a>の値はTF/IDFの値を利用します。またclusterdumpというコマンドを使って実際に抽出されたClusteringを見てみます。まずは最初にcanopyとkmeansのhelpを確認します。</p>
<pre class="code" data-lang="" data-unlink>$ bin/mahout canopy -h
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
usage: <command> [Generic Options] [Job-Specific Options]
Generic Options:
 -archives <paths>              comma separated archives to be unarchived
                            on the compute machines.
 -conf <configuration file>     specify an application configuration file
 -D <property=value>            use value for given property
 -files <paths>                 comma separated files to be copied to the
                            map reduce cluster
 -fs <local|namenode:port>      specify a namenode
 -jt <local|jobtracker:port>    specify a job tracker
 -libjars <paths>               comma separated jar files to include in
                            the classpath.
 -tokenCacheFile <tokensFile>   name of the file with the tokens
Job-Specific Options:                                                           
  --input (-i) input                                    Path to job input       
                                                    directory.              
  --output (-o) output                                  The directory pathname  
                                                    for output.             
  --distanceMeasure (-dm) distanceMeasure               The classname of the    
                                                    DistanceMeasure.        
                                                    Default is              
                                                    SquaredEuclidean        
  --t1 (-t1) t1                                         T1 threshold value      
  --t2 (-t2) t2                                         T2 threshold value      
  --t3 (-t3) t3                                         T3 (Reducer T1)         
                                                    threshold value         
  --t4 (-t4) t4                                         T4 (Reducer T2)         
                                                    threshold value         
  --clusterFilter (-cf,-clusterFilter) clusterFilter    Cluster filter          
                                                    suppresses small        
                                                    canopies from mapper    
  --overwrite (-ow)                                     If present, overwrite   
                                                    the output directory    
                                                    before running job      
  --clustering (-cl)                                    If present, run         
                                                    clustering after the    
                                                    iterations have taken   
                                                    place                   
  --method (-xm) method                                 The execution method to 
                                                    use: sequential or      
                                                    mapreduce. Default is   
                                                    mapreduce               
  --help (-h)                                           Print out help          
  --tempDir tempDir                                     Intermediate output     
                                                    directory               
  --startPhase startPhase                               First phase to run      
  --endPhase endPhase                                   Last phase to run   

$ bin/mahout kmeans -h
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
usage: <command> [Generic Options] [Job-Specific Options]
Generic Options:
 -archives <paths>              comma separated archives to be unarchived
                            on the compute machines.
 -conf <configuration file>     specify an application configuration file
 -D <property=value>            use value for given property
 -files <paths>                 comma separated files to be copied to the
                            map reduce cluster
 -fs <local|namenode:port>      specify a namenode
 -jt <local|jobtracker:port>    specify a job tracker
 -libjars <paths>               comma separated jar files to include in
                            the classpath.
 -tokenCacheFile <tokensFile>   name of the file with the tokens
Job-Specific Options:                                                           
  --input (-i) input                           Path to job input directory.     
  --output (-o) output                         The directory pathname for       
                                           output.                          
  --distanceMeasure (-dm) distanceMeasure      The classname of the             
                                           DistanceMeasure. Default is      
                                           SquaredEuclidean                 
  --clusters (-c) clusters                     The input centroids, as Vectors. 
                                           Must be a SequenceFile of        
                                           Writable, Cluster/Canopy.  If k  
                                           is also specified, then a random 
                                           set of vectors will be selected  
                                           and written out to this path     
                                           first                            
  --numClusters (-k) k                         The k in k-Means.  If specified, 
                                           then a random selection of k     
                                           Vectors will be chosen as the    
                                           Centroid and written to the      
                                           clusters input path.             
  --convergenceDelta (-cd) convergenceDelta    The convergence delta value.     
                                           Default is 0.5                   
  --maxIter (-x) maxIter                       The maximum number of            
                                           iterations.                      
  --overwrite (-ow)                            If present, overwrite the output 
                                           directory before running job     
  --clustering (-cl)                           If present, run clustering after 
                                           the iterations have taken place  
  --method (-xm) method                        The execution method to use:     
                                           sequential or mapreduce. Default 
                                           is mapreduce                     
  --help (-h)                                  Print out help                   
  --tempDir tempDir                            Intermediate output directory    
  --startPhase startPhase                      First phase to run               
  --endPhase endPhase                          Last phase to run     </pre>
<div class="section">
<h5>Canopy</h5>
<pre class="code" data-lang="" data-unlink>$ bin/mahout canopy \
--input madmagi_out_ma_test/vector/tfidf-vectors/part-r-00000 \
--output madmagi_out_ma_test/canopy \
--t1 0.9 \
--t2 0.8 \
-dm org.apache.mahout.common.distance.CosineDistanceMeasure
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 13:44:35 INFO common.AbstractJob: Command line arguments: {--distanceMeasure=org.apache.mahout.common.distance.CosineDistanceMeasure, --endPhase=2147483647, --input=madmagi_out_ma_test/vector/tfidf-vectors/part-r-00000, --method=mapreduce, --output=madmagi_out_ma_test/canopy, --startPhase=0, --t1=0.8, --t2=0.7, --tempDir=temp}
12/05/03 13:44:35 INFO canopy.CanopyDriver: Build Clusters Input: madmagi_out_ma_test/vector/tfidf-vectors/part-r-00000 Out: madmagi_out_ma_test/canopy Measure: org.apache.mahout.common.distance.CosineDistanceMeasure@177d59d4 t1: 0.8 t2: 0.5
12/05/03 13:44:39 INFO input.FileInputFormat: Total input paths to process : 1
12/05/03 13:44:40 INFO mapred.JobClient: Running job: job_201205030840_0073
12/05/03 13:44:41 INFO mapred.JobClient:  map 0% reduce 0%
12/05/03 13:44:54 INFO mapred.JobClient:  map 100% reduce 0%
12/05/03 13:45:05 INFO mapred.JobClient:  map 100% reduce 33%
12/05/03 13:45:07 INFO mapred.JobClient:  map 100% reduce 100%
12/05/03 13:45:11 INFO mapred.JobClient: Job complete: job_201205030840_0073

$ bin/mahout seqdumper -s /user/yuta/madmagi_out_ma_test/canopy/clusters-0-final/part-r-00000
MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 13:10:46 INFO common.AbstractJob: Command line arguments: {--endPhase=2147483647, --seqFile=/user/yuta/madmagi_out_ma_test/canopy/clusters-0-final/part-r-00000, --startPhase=0, --tempDir=temp}
Input Path: /user/yuta/madmagi_out_ma_test/canopy/clusters-0-final/part-r-00000
Key class: class org.apache.hadoop.io.Text Value Class: class org.apache.mahout.clustering.canopy.Canopy
Key: C-0: Value: C-0: {0:0.4339554011821747,1:0.4339554011821747,2:0.811856210231781,3:2.1479697227478027,4:5.765240669250488,5:0.6861437559127808,6:10.023337364196777,7:1.0177156925201416,8:6.868295669555664,9:2.1479697227478027,10:4.653653144836426,
11:2.744575023651123,12:8.564437866210938,13:5.699537754058838,14:4.01262092590332,15:1.4716144800186157,16:4.572004318237305,17:1.3722875118255615,18:4.713962554931641,19:1.708484172821045,20:5.341354846954346,21:2.0584311485290527,

$ bin/mahout clusterdump \
--seqFileDir madmagi_out_ma_test/canopy/clusters-0-final \
--dictionary  madmagi_out_ma_test/vector/dictionary.file-0 \
--dictionaryType sequencefile \
-dm org.apache.mahout.common.distance.CosineDistanceMeasure \
--numWords 100

MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 13:47:14 INFO common.AbstractJob: Command line arguments: {--dictionary=madmagi_out_ma_test/vector/dictionary.file-0, --dictionaryType=sequencefile, --distanceMeasure=org.apache.mahout.common.distance.CosineDistanceMeasure, --endPhase=2147483647, --numWords=100, --outputFormat=TEXT, --seqFileDir=madmagi_out_ma_test/canopy/clusters-0-final, --startPhase=0, --tempDir=temp}
C-0{n=1 c=[10:0.434, 100:0.434, 々:0.812, ぁ:2.148, あ:5.765, ぃ:0.686, い:10.023, ぅ:1.018, う:6.868, ぇ:2.148, え:4.654, お:2.745, か:8.564, が:5.700, き:4.013, ぎ:1.472, く:4.572, ぐ:1.372, け:4.714, げ:1.708, こ:5.341, ご:2.058, さ:5.814, ざ:0.921, し:7.183, じ:3.906, す:4.252, ず:2.081, せ:2.959, ぜ:0.752, そ:5.540, ぞ:0.970, た:8.090, だ:7.548, ち:5.226, っ:8.993, つ:3.319, づ:1.018, て:9.144, で:6.044, と:6.531, ど:4.976, な:10.237, に:7.196, ぬ:0.812, ね:4.852, の:9.206, は:7.084, ば:2.727, ぱ:0.868, ひ:1.302, び:1.106, ふ:1.302, ぶ:1.018, へ:0.921, べ:1.867, ほ:2.604, ぼ:0.686, ぽ:0.531, ま:5.252,
（略）
Top Terms: 
な                                       =>  10.237117767333984
い                                       =>  10.023337364196777
の                                       =>   9.205584526062012
て                                       =>    9.14400863647461
っ                                       =>   8.993457794189453
ん                                       =>   8.597356796264648
か                                       =>   8.564437866210938
た                                       =>   8.089515686035156
だ                                       =>   7.547581672668457
に                                       =>   7.196336269378662
し                                       =>   7.183239936828613
は                                       =>    7.08424711227417
う                                       =>   6.868295669555664
も                                       =>   6.659483432769775
る                                       =>   6.588409423828125
と                                       =>  6.5309929847717285
ら                                       =>   6.296092987060547
っ て                                     =>   6.137056350708008
（略）
    そ う                                     =>  2.5489108562469482
っ と                                     =>  2.5489108562469482
か ち                                     =>  2.5116984844207764
て い                                     =>  2.5116984844207764
魔 法                                     =>  2.5116984844207764
か ち ゃ                                   =>  2.4928841590881348
か ち ゃ ん                                 =>  2.4928841590881348
さ や か ち                                 =>  2.4928841590881348
さ や か ち ゃ                               =>  2.4928841590881348
さ や か ち ゃ ん                             =>  2.4928841590881348</pre>
</div>
<div class="section">
<h5>K-Means</h5>
<p>canopyで抽出したclusterをK-Meansに当てはめます。--numClustersで10と指定していますが、なぜか1個のClusterしか作成されません。※ここは原因を調査中で分かり次第内容を追記します。</p>
<pre class="code" data-lang="" data-unlink>$ bin/mahout kmeans \
--input madmagi_out_ma_test/vector/tfidf-vectors/part-r-00000 \
--output madmagi_out_ma_test/kmeans \
--clusters madmagi_out_ma_test/canopy/clusters-0-final \
--maxIter 40 \
--numClusters 10 \
--convergenceDelta 0.01 \
--clustering \
-dm org.apache.mahout.common.distance.CosineDistanceMeasure

$ bin/mahout clusterdump \
--seqFileDir madmagi_out_ma_test/kmeans/clusters-1-final \
--dictionary madmagi_out_ma_test/vector/dictionary.file-0 \
--pointsDir madmagi_out_ma_test/kmeans/clusteredPoints \
--dictionaryType sequencefile \
-dm org.apache.mahout.common.distance.CosineDistanceMeasure \
--numWords 100

MAHOUT_LOCAL is not set; adding HADOOP_CONF_DIR to classpath.
Running on hadoop, using HADOOP_HOME=/usr/lib/hadoop-0.20
HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
MAHOUT-JOB: /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6-job.jar
12/05/03 14:03:20 INFO common.AbstractJob: Command line arguments: {--dictionary=madmagi_out_ma_test/vector/dictionary.file-0, --dictionaryType=sequencefile, --distanceMeasure=org.apache.mahout.common.distance.CosineDistanceMeasure, --endPhase=2147483647, --numWords=100, --outputFormat=TEXT, --pointsDir=madmagi_out_ma_test/kmeans/clusteredPoints, --seqFileDir=madmagi_out_ma_test/kmeans/clusters-1-final, --startPhase=0, --tempDir=temp}
VL-0{n=1 c=[10:0.434, 100:0.434, 々:0.812, ぁ:2.148, あ:5.765, ぃ:0.686, い:10.023, ぅ:1.018, う:6.868, ぇ:2.148, え:4.654, お:2.745, か:8.564, が:5.700, き:4.013, ぎ:1.472, く:4.572, ぐ:1.372, け:4.714, げ:1.708, こ:5.341, ご:2.058, さ:5.814, ざ:0.921, し:7.183, じ:3.906, す:4.252, ず:2.081, せ:2.959, ぜ:0.752, そ:5.540, ぞ:0.970, た:8.090, だ:7.548, ち:5.226, っ:8.993, つ:3.319, づ:1.018, て:9.144, で:6.044, と:6.531, ど:4.976, な:10.237, に:7.196, ぬ:0.812, ね:4.852, の:9.206, は:7.084, ば:2.727, ぱ:0.868, ひ:1.302, び:1.106, ふ:1.302, ぶ:1.018, へ:0.921, べ:1.867, ほ:2.604, ぼ:0.686, ぽ:0.531, ま:5.252,
（略）

Top Terms: 
な                                       =>  10.237117767333984
い                                       =>  10.023337364196777
の                                       =>   9.205584526062012
て                                       =>    9.14400863647461
っ                                       =>   8.993457794189453
ん                                       =>   8.597356796264648
か                                       =>   8.564437866210938
た                                       =>   8.089515686035156
だ                                       =>   7.547581672668457
に                                       =>   7.196336269378662
し                                       =>   7.183239936828613
は                                       =>    7.08424711227417
う                                       =>   6.868295669555664
も                                       =>   6.659483432769775
る                                       =>   6.588409423828125
と                                       =>  6.5309929847717285
ら                                       =>   6.296092987060547
っ て                                     =>   6.137056350708008
（略）
　　  そ う                                     =>  2.5489108562469482
っ と                                     =>  2.5489108562469482
か ち                                     =>  2.5116984844207764
て い                                     =>  2.5116984844207764
魔 法                                     =>  2.5116984844207764
か ち ゃ                                   =>  2.4928841590881348
か ち ゃ ん                                 =>  2.4928841590881348
さ や か ち                                 =>  2.4928841590881348
さ や か ち ゃ                               =>  2.4928841590881348
さ や か ち ゃ ん                             =>  2.4928841590881348
Weight : [props - optional]:  Point:
1.0 : [distance=0.0]: /ma.txt = [10:0.434, 100:0.434, 々:0.812, ぁ:2.148, あ:5.765, ぃ:0.686, い:10.023, ぅ:1.018, う:6.868, ぇ:2.148, え:4.654, お:2.745, か:8.564, が:5.700, き:4.013, ぎ:1.472, く:4.572, ぐ:1.372, け:4.714, げ:1.708, こ:5.341, ご:2.058, さ:5.814, ざ:0.921, し:7.183, じ:3.906, す:4.252, ず:2.081, せ:2.959, ぜ:0.752, そ:5.540, ぞ:0.970, た:8.090, だ:7.548, ち:5.226, っ:8.993, つ:3.319, づ:1.018, て:9.144, で:6.044, と:6.531, ど:4.976, な:10.237, に:7.196, ぬ:0.812, ね:4.852, の:9.206, は:7.084, ば:2.727, ぱ:0.868, ひ:1.302, び:1.106, ふ:1.302, ぶ:1.018, へ:0.921, べ:1.867, ほ:2.604,</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4>Graph Display</h4>

<blockquote>
    
<div class="section">
<h5>Required JAR</h5>
<p><a href="http://www.java2s.com/Code/Jar/CatalogJar.htm">Jar File Download examples (example source code) Organized by topic</a> <a href="http://b.hatena.ne.jp/entry/www.java2s.com/Code/Jar/CatalogJar.htm"><img src="http://b.hatena.ne.jp/entry/image/http://www.java2s.com/Code/Jar/CatalogJar.htm" alt="はてなブックマーク - Jar File Download examples (example source code) Organized by topic" border="0" /></a><br />
Clustering結果が生のデータだと視覚的に分かりづらいので、<a class="keyword" href="http://d.hatena.ne.jp/keyword/GUI">GUI</a>のGraphを生成します。Graph生成には幾つかJARファイルが必要なので上のサイトから検索してDownLoadします。try and <a class="keyword" href="http://d.hatena.ne.jp/keyword/error">error</a>を繰り返した結果以下のJARが必要ということが分かりました。</p>

<ul>
<li>com.<a class="keyword" href="http://d.hatena.ne.jp/keyword/google">google</a>.common_1.0.0.201004262004.jar</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/google">google</a>-collections-1.0.jar</li>
<li>uncommons-maths-1.2.jar</li>
</ul><pre class="code" data-lang="" data-unlink>$ pwd
/home/yuta/work/src/mahout/mahout-distribution-0.6
$ wget http://www.java2s.com/Code/JarDownload/uncommons/uncommons-maths-1.2.jar.zip
$ wget http://www.java2s.com/Code/JarDownload/com.google/com.google.common_1.0.0.201004262004.jar.zip
$ wget http://www.java2s.com/Code/JarDownload/google-collections/google-collections-1.0.jar.zip
$ unzip *.zip</pre><p>さらに<a class="keyword" href="http://d.hatena.ne.jp/keyword/HADOOP">HADOOP</a>_<a class="keyword" href="http://d.hatena.ne.jp/keyword/CLASSPATH">CLASSPATH</a>をexportしないと<a class="keyword" href="http://d.hatena.ne.jp/keyword/java">java</a> <a class="keyword" href="http://d.hatena.ne.jp/keyword/error">error</a>が出る事から以下のように設定します。.zshrcなどに書いておくと良いと思います。</p>
<pre class="code" data-lang="" data-unlink>export JAVA_HOME=/usr/java/default/
export PATH=$JAVA_HOME/bin:$PATH
export HADOOP_HOME=/usr/lib/hadoop-0.20
export HADOOP_CONF_DIR=/usr/lib/hadoop-0.20/conf/
export PATH=$HADOOP_HOME/bin:$PATH
export MAHOUT_HOME=/home/yuta/work/src/mahout/mahout-distribution-0.6
export HADOOP_CLASSPATH=$MAHOUT_HOME/mahout-math-0.6.jar:$MAHOUT_HOME/mahout-core-0.6.jar:$MAHOUT_HOME/ommons-cli-2.0-mahout.jar:$MAHOUT_HOME/mahout-integration-0.6.jar:$MAHOUT_HOME/google-collections-1.0.jar:$MAHOUT_HOME/uncommons-maths-1.2.jar:$MAHOUT_HOME/com.google.common_1.0.0.201004262004.jar:$MAHOUT_HOME/lib/mahout-collections-1.0.jar</pre>
</div>
<div class="section">
<h5>Sample Graph Image</h5>
<p>JARファイルと<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B4%C4%B6%AD%CA%D1%BF%F4">環境変数</a>の設定が完了したら以下のコマンドを実行するとサンプルのKmeansのグラフ画像が出力されます。</p>
<pre class="code" data-lang="" data-unlink>$ hadoop jar /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6.jar org.apache.mahout.clustering.display.DisplayClustering
$ hadoop jar /home/yuta/work/src/mahout/mahout-distribution-0.6/mahout-examples-0.6.jar \
org.apache.mahout.clustering.display.DisplayKMeans</pre><p><span itemscope itemtype="http://schema.org/Photograph"><a href="http://f.hatena.ne.jp/yutakikuchi/20120503134208" class="hatena-fotolife" itemprop="url"><img src="http://cdn-ak.f.st-hatena.com/images/fotolife/y/yutakikuchi/20120503/20120503134208.png" alt="f:id:yutakikuchi:20120503134208p:image" title="f:id:yutakikuchi:20120503134208p:image" class="hatena-fotolife" itemprop="image"></a></span><br />
<span itemscope itemtype="http://schema.org/Photograph"><a href="http://f.hatena.ne.jp/yutakikuchi/20120503125606" class="hatena-fotolife" itemprop="url"><img src="http://cdn-ak.f.st-hatena.com/images/fotolife/y/yutakikuchi/20120503/20120503125606.png" alt="f:id:yutakikuchi:20120503125606p:image" title="f:id:yutakikuchi:20120503125606p:image" class="hatena-fotolife" itemprop="image"></a></span><br />
</p>

</div>
<div class="section">
<h5>DisplayKMeans.<a class="keyword" href="http://d.hatena.ne.jp/keyword/java">java</a></h5>
<p>mahout-examples-0.6-sources.jarを取得してsampleのClusteringがどうなっているのかを見てみます。どうやらimport org.<a class="keyword" href="http://d.hatena.ne.jp/keyword/apache">apache</a>.mahout.common.RandomUtils;とDisplayClusteringクラスでランダムなSampleデータを取得して表示しているだけのようです。これを応用してMadmagi Wordにも当てはめられればGraph Imageが出力されると思います。この続きは次回行います。</p>
<pre class="code" data-lang="" data-unlink>$ wget http://mirrors.ibiblio.org/maven2/org/apache/mahout/mahout-examples/0.6/mahout-examples-0.6-sources.jar
$ unzip mahout-examples-0.6-sources.jar
$ vi org/apache/mahout/clustering/display/DisplayKMeans.java</pre><pre class="hljs java" data-lang="java" data-unlink><span class="synComment">/*</span>
<span class="synComment"> * Licensed to the Apache Software Foundation (ASF) under one or more</span>
<span class="synComment"> * contributor license agreements.  See the NOTICE file distributed with</span>
<span class="synComment"> * this work for additional information regarding copyright ownership.</span>
<span class="synComment"> * The ASF licenses this file to You under the Apache License, Version 2.0</span>
<span class="synComment"> * (the "License"); you may not use this file except in compliance with</span>
<span class="synComment"> * the License.  You may obtain a copy of the License at</span>
<span class="synComment"> *</span>
<span class="synComment"> *     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="synComment"> *</span>
<span class="synComment"> * Unless required by applicable law or agreed to in writing, software</span>
<span class="synComment"> * distributed under the License is distributed on an "AS IS" BASIS,</span>
<span class="synComment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="synComment"> * See the License for the specific language governing permissions and</span>
<span class="synComment"> * limitations under the License.</span>
<span class="synComment"> */</span>

<span class="synPreProc">package</span> org.apache.mahout.clustering.display;

<span class="synPreProc">import</span> java.awt.Graphics;
<span class="synPreProc">import</span> java.awt.Graphics2D;
<span class="synPreProc">import</span> java.io.IOException;
<span class="synPreProc">import</span> java.util.Collection;
<span class="synPreProc">import</span> java.util.List;

<span class="synPreProc">import</span> com.google.common.collect.Lists;
<span class="synPreProc">import</span> org.apache.hadoop.conf.Configuration;
<span class="synPreProc">import</span> org.apache.hadoop.fs.Path;
<span class="synPreProc">import</span> org.apache.mahout.clustering.Cluster;
<span class="synPreProc">import</span> org.apache.mahout.clustering.ClusterClassifier;
<span class="synPreProc">import</span> org.apache.mahout.clustering.ClusterIterator;
<span class="synPreProc">import</span> org.apache.mahout.clustering.ClusteringPolicy;
<span class="synPreProc">import</span> org.apache.mahout.clustering.KMeansClusteringPolicy;
<span class="synPreProc">import</span> org.apache.mahout.clustering.kmeans.KMeansDriver;
<span class="synPreProc">import</span> org.apache.mahout.clustering.kmeans.RandomSeedGenerator;
<span class="synPreProc">import</span> org.apache.mahout.common.HadoopUtil;
<span class="synPreProc">import</span> org.apache.mahout.common.RandomUtils;
<span class="synPreProc">import</span> org.apache.mahout.common.distance.DistanceMeasure;
<span class="synPreProc">import</span> org.apache.mahout.common.distance.ManhattanDistanceMeasure;
<span class="synPreProc">import</span> org.apache.mahout.math.Vector;

<span class="synType">public</span> <span class="synType">class</span> DisplayKMeans <span class="synType">extends</span> DisplayClustering {

  DisplayKMeans() {
initialize();
<span class="synType">this</span>.setTitle(<span class="synConstant">"k-Means Clusters (>"</span> + (<span class="synType">int</span>) (significance * <span class="synConstant">100</span>) + <span class="synConstant">"% of population)"</span>);
  }
  
  <span class="synType">public</span> <span class="synType">static</span> <span class="synType">void</span> main(String[] args) <span class="synType">throws</span> Exception {
DistanceMeasure measure = <span class="synStatement">new</span> ManhattanDistanceMeasure();
Path samples = <span class="synStatement">new</span> Path(<span class="synConstant">"samples"</span>);
Path output = <span class="synStatement">new</span> Path(<span class="synConstant">"output"</span>);
Configuration conf = <span class="synStatement">new</span> Configuration();
HadoopUtil.delete(conf, samples);
HadoopUtil.delete(conf, output);

RandomUtils.useTestSeed();
DisplayClustering.generateSamples();
writeSampleData(samples);
<span class="synType">boolean</span> runClusterer = <span class="synConstant">false</span>;
<span class="synStatement">if</span> (runClusterer) {
  <span class="synType">int</span> numClusters = <span class="synConstant">3</span>;
  runSequentialKMeansClusterer(conf, samples, output, measure, numClusters);
} <span class="synStatement">else</span> {
  <span class="synType">int</span> maxIterations = <span class="synConstant">10</span>;
  runSequentialKMeansClassifier(conf, samples, output, measure, maxIterations);
}
<span class="synStatement">new</span> DisplayKMeans();
  }
  
  <span class="synType">private</span> <span class="synType">static</span> <span class="synType">void</span> runSequentialKMeansClassifier(Configuration conf,
                                                Path samples,
                                                Path output,
                                                DistanceMeasure measure,
                                                <span class="synType">int</span> numClusters) <span class="synType">throws</span> IOException {
Collection<Vector> points = Lists.newArrayList();
<span class="synStatement">for</span> (<span class="synType">int</span> i = <span class="synConstant">0</span>; i < numClusters; i++) {
  points.add(SAMPLE_DATA.get(i).get());
}
List<Cluster> initialClusters = Lists.newArrayList();
<span class="synType">int</span> id = <span class="synConstant">0</span>;
<span class="synStatement">for</span> (Vector point : points) {
  initialClusters.add(<span class="synStatement">new</span> org.apache.mahout.clustering.kmeans.Cluster(
      point, id++, measure));
}
ClusterClassifier prior = <span class="synStatement">new</span> ClusterClassifier(initialClusters);
Path priorClassifier = <span class="synStatement">new</span> Path(output, <span class="synConstant">"clusters-0"</span>);
writeClassifier(prior, conf, priorClassifier);

<span class="synType">int</span> maxIter = <span class="synConstant">10</span>;
ClusteringPolicy policy = <span class="synStatement">new</span> KMeansClusteringPolicy();
<span class="synStatement">new</span> ClusterIterator(policy).iterateSeq(samples, priorClassifier, output, maxIter);
<span class="synStatement">for</span> (<span class="synType">int</span> i = <span class="synConstant">1</span>; i <= maxIter; i++) {
  ClusterClassifier posterior = readClassifier(conf, <span class="synStatement">new</span> Path(output, <span class="synConstant">"classifier-"</span> + i));
  CLUSTERS.add(posterior.getModels());
}
  }
  
  <span class="synType">private</span> <span class="synType">static</span> <span class="synType">void</span> runSequentialKMeansClusterer(Configuration conf,
                                               Path samples,
                                               Path output,
                                               DistanceMeasure measure,
                                               <span class="synType">int</span> maxIterations)
<span class="synType">throws</span> IOException, InterruptedException, ClassNotFoundException {
Path clusters = RandomSeedGenerator.buildRandom(conf, samples, <span class="synStatement">new</span> Path(
    output, <span class="synConstant">"clusters-0"</span>), <span class="synConstant">3</span>, measure);
<span class="synType">double</span> distanceThreshold = <span class="synConstant">0.001</span>;
KMeansDriver.run(samples, clusters, output, measure, distanceThreshold,
    maxIterations, <span class="synConstant">true</span>, <span class="synConstant">true</span>);
loadClusters(output);
  }
  
  <span class="synComment">// Override the paint() method</span>
  <span class="synPreProc">@Override</span>
  <span class="synType">public</span> <span class="synType">void</span> paint(Graphics g) {
plotSampleData((Graphics2D) g);
plotClusters((Graphics2D) g);
  }
}
</pre>
</div>
</blockquote>

</div>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://yutakikuchi.github.io/post/201205022121/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://yutakikuchi.github.io/post/201205022121/">C&#43;&#43;最速マスター その4</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://yutakikuchi.github.io/post/201205100828/">Hadoop MapReduceのExamplesで分散grep、WordCount、randomwriter、sort、join、数独、円周率計算を試してみる</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://yutakikuchi.github.io/post/201205100828/"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>



  

</div>

</div>
</div>
<script src="https://yutakikuchi.github.io/js/ui.js"></script>
<script src="https://yutakikuchi.github.io/js/menus.js"></script>


<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-20616165-3', 'auto');
    ga('send', 'pageview');
  }
</script>





</body>
</html>

