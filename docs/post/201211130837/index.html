<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link rel="canonical" href="http://yut.hatenablog.com/entry/20121113/1352763461" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.55.4" />

  <title>Mahoutを使ったNaiveBayesによる機械学習 &middot; Y&#39;s note</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://yutakikuchi.github.io/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://yutakikuchi.github.io/css/my.css">
    
  
  
    
        <script src="https://yutakikuchi.github.io/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://yutakikuchi.github.io/">Y's note</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/yutakikuchi_" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://facebook.com/yuta.kikuchi.007" target="_blank"><i class="fa fa-facebook-square fa-fw"></i>Facebook</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/https://www.slideshare.net/yutakikuchi58/" target="_blank"><i class="fa fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/https://www.linkedin.com/in/%E4%BD%91%E5%A4%AA-%E8%8F%8A%E6%B1%A0-36291a44/" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yutakikuchi" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2019. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Mahoutを使ったNaiveBayesによる機械学習</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Nov 13, 08:37</time>
  </div>

  

  

  

</div>

  

<h2 id="機械学習-mahoutを使ったnaivebayesによる機械学習">[機械学習] : Mahoutを使ったNaiveBayesによる機械学習</h2>

<p><div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873115132/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/513gAGruDDL._SL160_.jpg" class="hatena-asin-detail-image" alt="入門 ソーシャルデータ ―データマイニング、分析、可視化のテクニック" title="入門 ソーシャルデータ ―データマイニング、分析、可視化のテクニック"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873115132/yutakikuchi-22/">入門 ソーシャルデータ ―データマイニング、分析、可視化のテクニック</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> Matthew A. Russell,奥野陽（監訳）,佐藤敏紀（監訳）,瀬戸口光宏（監訳）,原川浩一（監訳）,水野貴明（監訳）,長尾高弘</li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%E9%A5%A4%A5%EA%A1%BC%A5%B8%A5%E3%A5%D1%A5%F3">オライリージャパン</a></li><li><span class="hatena-asin-detail-label">発売日:</span> 2011/11/26</li><li><span class="hatena-asin-detail-label">メディア:</span> 大型本</li><li><span class="hatena-asin-detail-label">購入</span>: 18人 <span class="hatena-asin-detail-label">クリック</span>: 779回</li><li><a href="http://d.hatena.ne.jp/asin/4873115132/yutakikuchi-22" target="_blank">この商品を含むブログ (42件) を見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

<div class="section">
<h4>BigDataでの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a></h4>

<blockquote>
    <p>膨大なデータに対して<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>を行いたい時にlocalの端末一台では処理の時間が掛かりすぎてしまいます。学習、モデル作成、予測のそれぞれの処理を高速で行うための一つのSolutionが<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>上で<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>をしてしまうことだと思います。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>上で<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>をするための便利なライブラリとして<a class="keyword" href="http://d.hatena.ne.jp/keyword/JAVA">JAVA</a>ベースのMahoutがあります。この記事ではMahoutによるNaiveBayes分類学習を中心としたMahoutデータの生成と使い方について紹介します。<br />
<a href="http://d.hatena.ne.jp/yutakikuchi/20121015/1350257880">Machine Learning With Hadoop - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20121015/1350257880"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20121015/1350257880" alt="はてなブックマーク - Machine Learning With Hadoop - Yuta.Kikuchiの日記" border="0" /></a></p>

</blockquote>

</div>
<div class="section">
<h4>NLTKによる<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%AC%A4%AB%A4%C1%BD%F1%A4%AD">分かち書き</a></h4>

<blockquote>
    
<div class="section">
<h5>NLTK Install</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a>ライブラリのnltkを利用して<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%AC%A4%AB%A4%C1%BD%F1%A4%AD">分かち書き</a>を行います。nltkのセットアップは非常に簡単で以下のコマンドを実行するだけです。<a href="http://nltk.org/install.html">Installing NLTK ― NLTK 2.0 documentation</a> <a href="http://b.hatena.ne.jp/entry/nltk.org/install.html"><img src="http://b.hatena.ne.jp/entry/image/http://nltk.org/install.html" alt="はてなブックマーク - Installing NLTK ― NLTK 2.0 documentation" border="0" /></a></p>
<pre class="code" data-lang="" data-unlink>$ python -V
Python 2.6.6
$ wget "http://pypi.python.org/packages/2.6/s/setuptools/setuptools-0.6c11-py2.6.egg#md5=bfa92100bd772d5a213eedd356d64086"
$ sudo sh setuptools-0.6c11-py2.6.egg --prefix=/usr/
$ sudo easy_install pip
$ sudo pip install -U numpy
$ sudo pip install -U pyyaml nltk</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a> Install</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>器で有名な<a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a>を<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>から利用できるようにします。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a>本体、<a class="keyword" href="http://d.hatena.ne.jp/keyword/Mecab">Mecab</a>-ipadic、<a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>の3つをinstallします。<a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>のinstallの時に"<a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-config: コマンドが見つかりません"のように怒られたらsetup.pyの<a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-configを<a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>をinstallした時のlocalディレクトリを指定するように修正するとinstallできます。</p>
<pre class="code" data-lang="" data-unlink>// mecab本体
$ wget http://mecab.googlecode.com/files/mecab-0.99.tar.gz
$ tar -xzf mecab-0.99.tar.gz
$ cd mecab-0.99
$ ./configure --with-charset=utf8
$ make && sudo make install

// mecab-ipadic
$ wget http://sourceforge.net/projects/mecab/files/mecab-ipadic/2.7.0-20070801/mecab-ipadic-2.7.0-20070801.tar.gz/download
$ tar -xzf mecab-ipadic-2.7.0-20070801.tar.gz
$ cd mecab-ipadic-2.7.0-20070801
$ ./configure --with-charset=utf8
$ make && sudo make install

// mecab-python
$ wget http://mecab.googlecode.com/files/mecab-python-0.993.tar.gz
$ tar -xzf mecab-python-0.993.tar.gz
$ cd mecab-python-0.993
$ python setup.py build
$ sudo python setup.py install</pre>
</div>
<div class="section">
<h5>libmecab.so.2の読み込み</h5>
<p>上の設定が完了しただけではまだ<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>から<a class="keyword" href="http://d.hatena.ne.jp/keyword/MeCab">MeCab</a>が読み出せません。libmecab.so.2のエラーが出てしまうのでそれを回避するために設定ファイルに/usr/local/libを追記してldconfigの再読み込みを行います。これで<a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>が起動できる準備が整いました。</p>
<pre class="code" data-lang="" data-unlink>$ sudo vim /etc/ld.so.conf.d/lib.conf
/usr/local/lib  //追記

// 再読み込み
$ sudo ldconfig

// mecab-pythonの起動
$ python
Python 2.6.6 (r266:84292, Sep 11 2012, 08:34:23) 
[GCC 4.4.6 20120305 (Red Hat 4.4.6-4)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import MeCab</pre>
</div>
<div class="section">
<h5>データの抽出と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%AC%A4%AB%A4%C1%BD%F1%A4%AD">分かち書き</a></h5>
<p><a href="http://d.hatena.ne.jp/yutakikuchi/20120503/1336031972">Apache Mahout 機械学習Libraryを使って「魔法少女まどか☆マギカ」の台詞をテキストマイニングしてみた - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20120503/1336031972"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20120503/1336031972" alt="はてなブックマーク - Apache Mahout 機械学習Libraryを使って「魔法少女まどか☆マギカ」の台詞をテキストマイニングしてみた - Yuta.Kikuchiの日記" border="0" /></a> ここでも書いたように<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A4%DE%A4%C9%A5%DE%A5%AE">まどマギ</a>の台詞を抽出してテキ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%C8%A5%D5%A5%A1%A5%A4">ストファイ</a>ルに落とします。更にテキ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%C8%A5%D5%A5%A1%A5%A4">ストファイ</a>ルに落としたデータに対して<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%AC%A4%AB%A4%C1%BD%F1%A4%AD">分かち書き</a>を行います。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%AC%A4%AB%A4%C1%BD%F1%A4%AD">分かち書き</a>をした結果をディレクトリ名とファイル名をディレクトリ人物としたパスに保存します。</p>
<pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>

<span class="synPreProc">import</span> os,sys,re,urllib,urllib2

<span class="synStatement">if</span>( os.path.exists( <span class="synConstant">"./data"</span> ) != <span class="synIdentifier">True</span> ) :
   os.mkdir( <span class="synConstant">"./data"</span> )

urls = { <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/131.html'</span> : <span class="synConstant">'madoka.txt'</span>, 
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/57.html'</span>  : <span class="synConstant">'homura.txt'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/123.html'</span> : <span class="synConstant">'sayaka.txt'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/130.html'</span> : <span class="synConstant">'mami.txt'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/132.html'</span> : <span class="synConstant">'kyoko.txt'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/56.html'</span>  : <span class="synConstant">'kyube.txt'</span>
    }
opener = urllib2.build_opener()
ua = <span class="synConstant">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/    534.51.22'</span>
referer = <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/'</span>
opener.addheaders = [( <span class="synConstant">'User-Agent'</span>, ua ),( <span class="synConstant">'Referer'</span>, referer )]
<span class="synStatement">for</span> k,v <span class="synStatement">in</span> urls.iteritems():
f = <span class="synIdentifier">open</span>( <span class="synConstant">'./data/'</span> + v , <span class="synConstant">'w'</span> )
content = opener.<span class="synIdentifier">open</span>( k ).read()
<span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'^「(.*?)」$'</span>, re.M ).search( content ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>: 
    lines = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'^「(.*?)」$'</span>, re.M ).findall( content )
    <span class="synStatement">for</span> line <span class="synStatement">in</span> lines:
        f.write( line + <span class="synConstant">"</span><span class="synSpecial">\n</span><span class="synConstant">"</span> )
f.close()
</pre><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys,os
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> MeCab
mecab = MeCab.Tagger(<span class="synConstant">'-Ochasen'</span>)
names = [ <span class="synConstant">'homura'</span>, <span class="synConstant">'kyoko'</span>, <span class="synConstant">'kyube'</span>, <span class="synConstant">'madoka'</span>, <span class="synConstant">'mami'</span>, <span class="synConstant">'sayaka'</span> ]

<span class="synStatement">for</span> name <span class="synStatement">in</span> names :
<span class="synStatement">if</span>( os.path.exists( name ) != <span class="synIdentifier">True</span> ) :
    os.mkdir( name )
<span class="synIdentifier">file</span> = <span class="synConstant">'./data/'</span> + name + <span class="synConstant">'.txt'</span>
f = <span class="synIdentifier">open</span>( name + <span class="synConstant">'/'</span> + name + <span class="synConstant">'.txt'</span>, <span class="synConstant">'w'</span> )
<span class="synStatement">for</span> line <span class="synStatement">in</span> <span class="synIdentifier">open</span>( <span class="synIdentifier">file</span> ):
    line = line.strip().rstrip()
    p = mecab.parseToNode( line )
    phrases = p.<span class="synIdentifier">next</span>
    <span class="synStatement">while</span> phrases:
        <span class="synStatement">try</span>:
            k = p.surface
            f.write( k + <span class="synConstant">" "</span> )
            p = p.<span class="synIdentifier">next</span>
        <span class="synStatement">except</span> <span class="synType">AttributeError</span>:
            <span class="synStatement">break</span> 
    f.write( <span class="synConstant">"</span><span class="synSpecial">\n</span><span class="synConstant">"</span> )
f.close()
</pre><pre class="code" data-lang="" data-unlink>$ vi madoka/madoka.txt
 あっ … ？  
 ひどい …   
 そんな … あんまり だ よ 、 こんな の って ない よ  
 本当 な の ？  
 私 なんか でも 、 本当に 何 か できる の ？ こんな 結末 を 変え られる の ？  
 夢 オチ … ？  
 おはよう 、 パパ  
 ママ は ？  
 はぁ い  
 おっき ろ 〜！  </pre>
</div>
</blockquote>

</div>
<div class="section">
<h4>Mahout用のデータ生成</h4>

<blockquote>
    
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a>へデータのPUT</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>でデータを扱えるように上で生成した<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>ファイルを<a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a>に全てputします。putするデータは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>ファイルをsplitして1行ずつのファイルに落とします。アップする前に適当なディレクトリを一つ作っておくと良いと思います。/usr/lib/<a class="keyword" href="http://d.hatena.ne.jp/keyword/hadoop">hadoop</a>-0.20/bin/<a class="keyword" href="http://d.hatena.ne.jp/keyword/hadoop">hadoop</a> fsとタイピングするのが面倒なのでalias <a class="keyword" href="http://d.hatena.ne.jp/keyword/hdfs">hdfs</a>="/usr/lib/<a class="keyword" href="http://d.hatena.ne.jp/keyword/hadoop">hadoop</a>-0.20/bin/<a class="keyword" href="http://d.hatena.ne.jp/keyword/hadoop">hadoop</a> fs"としています。</p>
<pre class="code" data-lang="" data-unlink>$ cd homura
$ split -l 1 homura.txt
$ hdfs -mkdir madmagi
$ hdfs -put homura madmagi/
$ hdfs -put kyoko madmagi/
$ hdfs -put kyube madmagi/
$ hdfs -put madka madmagi/
$ hdfs -put madoka madmagi/
$ hdfs -put mami madmagi/
$ hdfs -put sayaka madmagi/
$ hdfs -lsr /user/yuta/madmagi
(略)
-rw-r--r--   1 yuta supergroup        128 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xld
-rw-r--r--   1 yuta supergroup        339 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xle
-rw-r--r--   1 yuta supergroup         58 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xlf
-rw-r--r--   1 yuta supergroup         40 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xlg
-rw-r--r--   1 yuta supergroup        228 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xlh
-rw-r--r--   1 yuta supergroup         98 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xli
-rw-r--r--   1 yuta supergroup        216 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xlj
-rw-r--r--   1 yuta supergroup         10 2012-11-12 23:57 /user/yuta/madmagi/sayaka/xlk</pre>
</div>
<div class="section">
<h5>SequenceFile生成</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>でデータを扱えるように<a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a>にputしたデータをSequenceFileに変換します。変換にはmahoutコマンドのseqdirectoryを利用します。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%B8%BB%FA%A5%B3%A1%BC%A5%C9">文字コード</a>は<a class="keyword" href="http://d.hatena.ne.jp/keyword/UTF-8">UTF-8</a>を指定します。生成したファイルを確認するためにはseqdumperを利用します。seqdumperにて確認するとそれぞれのラベルが付けられたファイルの先頭指定文字を表示してくれます。</p>
<pre class="code" data-lang="" data-unlink>$ mahout seqdirectory  --input madmagi --output madmagi_seq -c UTF-8
$ mahout seqdumper --input madmagi_seq --substring 10
Key: /sayaka/xlc: Value:  あの さあ 、 キ
Key: /sayaka/xld: Value:  まさか あんた 、
Key: /sayaka/xle: Value:  はあ 、 どっち 
Key: /sayaka/xlf: Value:  … 何 か 、 手
Key: /sayaka/xlg: Value:  … うん 。 これ
Key: /sayaka/xlh: Value:  そう だ よ 。 
Key: /sayaka/xli: Value:  それ を 思い出せ
Key: /sayaka/xlj: Value:  まあ 、 そりゃ 
Key: /sayaka/xlk: Value:  うん  </pre>
</div>
<div class="section">
<h5>VectorData生成</h5>
<p>SeqenceFileが生成された後にMahoutでのinputファイルとして利用できるように<a class="keyword" href="http://d.hatena.ne.jp/keyword/Vector">Vector</a>データに変換する必要があります。変換にはseq2sparseを利用します。オプションとして最大のDF値とNGramのサイズを指定しています。生成されたVectorDataを確認するためには先ほどと同様にseqdumperを利用します。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>のデータがIDベースのベクトルデータに変換されている事が確認できます。</p>
<pre class="code" data-lang="" data-unlink>$ mahout seq2sparse --input madmagi_seq --output madmagi_vector --maxDFPercent 40 --maxNGramSize 8 --sequentialAccessVector --namedVector
$ mahout seqdumper --input madmagi_vector/tf-vectors/part-r-00000 --substring 100

Key: /sayaka/xla: Value: /sayaka/xla:{5:2.0,7:2.0,11:2.0,26:1.0,27:1.0,29:1.0,31:2.0,32:2.0,34:3.0,37:1.0,41:1.0,42:1.0,44:1.
Key: /sayaka/xlb: Value: /sayaka/xlb:{3:1.0,11:1.0,23:1.0,31:1.0,34:1.0,37:1.0,47:1.0,118:1.0,841:1.0,842:1.0,844:1.0,845:1.0
Key: /sayaka/xlc: Value: /sayaka/xlc:{3:3.0,5:2.0,9:1.0,12:2.0,13:1.0,17:1.0,21:2.0,27:1.0,29:1.0,31:1.0,35:1.0,37:1.0,38:2.0
Key: /sayaka/xld: Value: /sayaka/xld:{3:2.0,5:1.0,7:2.0,11:2.0,21:1.0,23:1.0,24:1.0,31:1.0,38:1.0,39:2.0,41:2.0,44:1.0,45:1.0
Key: /sayaka/xle: Value: /sayaka/xle:{3:1.0,5:2.0,7:2.0,11:4.0,13:2.0,17:1.0,19:1.0,21:1.0,23:3.0,29:1.0,31:1.0,32:4.0,33:2.0
Key: /sayaka/xlf: Value: /sayaka/xlf:{11:2.0,17:1.0,21:1.0,27:1.0,31:1.0,33:1.0,34:1.0,44:1.0,63:1.0,170:1.0,410:1.0,752:1.0,
Key: /sayaka/xlg: Value: /sayaka/xlg:{5:2.0,7:1.0,19:1.0,38:1.0,67:1.0,71:1.0,75:1.0,978:1.0,992:1.0,1274:1.0,1634:1.0,1635:1
Key: /sayaka/xlh: Value: /sayaka/xlh:{3:1.0,5:1.0,7:2.0,11:2.0,12:1.0,13:1.0,17:1.0,23:1.0,29:1.0,31:4.0,32:4.0,34:4.0,37:1.0
Key: /sayaka/xli: Value: /sayaka/xli:{5:2.0,7:1.0,17:1.0,27:1.0,29:1.0,31:1.0,32:2.0,38:1.0,41:1.0,45:1.0,62:2.0,67:1.0,71:1.
Key: /sayaka/xlj: Value: /sayaka/xlj:{3:1.0,5:7.0,15:2.0,17:1.0,21:1.0,23:2.0,24:1.0,27:1.0,29:1.0,31:1.0,32:1.0,33:1.0,34:3.
Key: /sayaka/xlk: Value: /sayaka/xlk:{7:1.0,75:1.0,1634:1.0}

$ mahout seqdumper --input madmagi_vector/tfidf-vectors/part-r-00000 --substring 100
Key: /homura/homura.txt: Value: /homura/homura.txt:{4:3.386294364929199,76:4.1972246170043945,95:1.6931471824645996,98:1.69314718246
Key: /kyoko/kyoko.txt: Value: /kyoko/kyoko.txt:{0:1.6931471824645996,28:2.932616949081421,78:11.104812622070312,79:11.301372528076
Key: /kyube/kyube.txt: Value: /kyube/kyube.txt:{0:1.6931471824645996,28:2.932616949081421,80:1.6931471824645996,81:2.9326169490814
Key: /madoka/madoka.txt: Value: /madoka/madoka.txt:{4:2.3944716453552246,81:1.6931471824645996,95:2.3944716453552246,97:2.3944716453
Key: /mami/mami.txt: Value: /mami/mami.txt:{88:2.967885971069336,97:2.3944716453552246,105:1.6931471824645996,107:3.634903192520
Key: /sayaka/sayaka.txt: Value: /sayaka/sayaka.txt:{57:3.6349031925201416,90:2.967885971069336,91:2.967885971069336,93:4.69263982772</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4>NaiveBayesによる分類学習</h4>

<blockquote>
    
<div class="section">
<h5>NaiveBayes</h5>
<p>ようやくNaiveBayesの話ができるようになりました。NaiveBayesは教師あり学習の一つで単純<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA">ベイズ</a>分類器とも呼ばれ独立過程と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D9%A5%A4%A5%BA">ベイズ</a>の定理に寄って算出される確率ベースの分類器です。<br />
<a href="http://ja.wikipedia.org/wiki/%E5%8D%98%E7%B4%94%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E%E5%99%A8">単純ベイズ分類器 - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/%E5%8D%98%E7%B4%94%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E%E5%99%A8"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/%E5%8D%98%E7%B4%94%E3%83%99%E3%82%A4%E3%82%BA%E5%88%86%E9%A1%9E%E5%99%A8" alt="はてなブックマーク - 単純ベイズ分類器 - Wikipedia" border="0" /></a><br />
MahoutでNaiveBayesを利用するにはtrainnbとtestnbを使用します。まずはtrainnbにて予測Modelを作成、testnbにてModelからの予測を行い評価します。今回のinputは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A4%DE%A4%C9%A5%DE%A5%AE">まどマギ</a>の台詞ですが、ラベル済みのデータを学習させて未ラベルの評価データから台詞の人物を予測する事を目的としています。</p>

</div>
<div class="section">
<h5>予測Model作成</h5>
<p>inputはtfidfのデータを利用します。生成したデータのoutput先指定とtrainComplementaryというオプションで精度を高めることが出来るようです。生成されたModelはバイナリファイルのようでseqdumperでも中身を確認する事が出来ませんでした。labelindexは登場人物に対して正解ラベルとなる整数値を割り当てています。</p>
<pre class="code" data-lang="" data-unlink>$ mahout trainnb --input madmagi_vector/tfidf-vectors/part-r-00000 --output madmagi_model --extractLabels --labelIndex madmagi_labelindex --trainComplementary

$ mahout seqdumper --input /user/yuta/madmagi_model
Exception in thread "main" java.io.IOException: hdfs://localhost:8020/user/yuta/madmagi_model/naiveBayesModel.bin not a SequenceFile

$ mahout seqdumper --input /user/yuta/madmagi_labelindex
Key: homura: Value: 0
Key: kyoko: Value: 1
Key: kyube: Value: 2
Key: madoka: Value: 3
Key: mami: Value: 4
Key: sayaka: Value: 5</pre>
</div>
<div class="section">
<h5>予測の実行</h5>
<p>生成したModelを利用してデータの予測を行います。ここでのinputはModel生成に利用した学習データと全く同一のものを利用します。学習データと評価データが一致しているので正解率が高くなるのは当然の事で、ここでは1880行中1686行のデータを当てていて、正解率は89.6809%となっています。</p>
<pre class="code" data-lang="" data-unlink>$ mahout testnb --input madmagi_vector/tfidf-vectors/part-r-00000 --output madmagi_test --model madmagi_model --labelIndex madmagi_labelindex
Standard NB Results: =======================================================
Summary
-------------------------------------------------------
Correctly Classified Instances          :       1686       89.6809%
Incorrectly Classified Instances        :        194       10.3191%
Total Classified Instances              :       1880

=======================================================
Confusion Matrix
-------------------------------------------------------
a       b       c       d       e       f       <--Classified as
238     8       7       8       5       8        |  274     a     = homura
3       209     0       8       1       4        |  225     b     = kyoko
5       3       312     5       3       3        |  331     c     = kyube
21      13      2       498     28      24       |  586     d     = madoka
2       0       2       1       158     4        |  167     e     = mami
5       2       1       11      7       271      |  297     f     = sayaka</pre>
</div>
<div class="section">
<h5>学習データと評価データの分離</h5>
<p>予測Modelの正確な精度を確認するために学習データと評価データを分けてtestnbしてみます。データを分けるコマンドとしてsplitがあります。下では50%ずつデータを分割しています。分割したデータに対して予測Modelを作成、評価を行ってみると正解度は50.4634%となりました。以前<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>でも似たような事を試していてその時の精度がイマイチだったので、今回の結果ももっと低いと予測していたんですが、まぁそれなりの結果が出たと言えると思います。<br />
<a href="http://d.hatena.ne.jp/yutakikuchi/20120904/1346715336">Support Vector Machinesを用いた「魔法少女まどか☆マギカ」人物予測モデル - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20120904/1346715336"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20120904/1346715336" alt="はてなブックマーク - Support Vector Machinesを用いた「魔法少女まどか☆マギカ」人物予測モデル - Yuta.Kikuchiの日記" border="0" /></a></p>
<pre class="code" data-lang="" data-unlink>$ mahout split --input madmagi_vector/tfidf-vectors --trainingOutput madmagi_train --testOutput madmagi_output --randomSelectionPct 50 --method sequential --sequenceFiles --overwrite

$ mahout trainnb --input /user/yuta/madmagi_train/part-r-00000 --output madmagi_model --extractLabels --labelIndex madmagi_labelindex --trainComplementary

$ mahout testnb --input /user/yuta/madmagi_output/part-r-00000 --output madmagi_test_output --model madmagi_model --labelIndex madmagi_labelindex

Standard NB Results: =======================================================
Summary
-------------------------------------------------------
Correctly Classified Instances          :        490       50.4634%
Incorrectly Classified Instances        :        481       49.5366%
Total Classified Instances              :        971

=======================================================
Confusion Matrix
-------------------------------------------------------
a       b       c       d       e       f       <--Classified as
46      20      15      13      29      14       |  137     a     = homura
8       61      5       9       12      10       |  105     b     = kyoko
12      9       110     12      25      11       |  179     c     = kyube
36      25      4       165     31      45       |  306     d     = madoka
15      1       4       9       46      12       |  87      e     = mami
22      11      3       39      20      62       |  157     f     = sayaka</pre>
</div>
</blockquote>

</div>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://yutakikuchi.github.io/post/201210290836/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://yutakikuchi.github.io/post/201210290836/">lookコマンドによる二分探索が速すぎて見えない</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://yutakikuchi.github.io/post/201211261210/">3ヶ月間Hadoopを使ってみて学んだ事</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://yutakikuchi.github.io/post/201211261210/"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>



  

</div>

</div>
</div>
<script src="https://yutakikuchi.github.io/js/ui.js"></script>
<script src="https://yutakikuchi.github.io/js/menus.js"></script>


<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-20616165-3', 'auto');
    ga('send', 'pageview');
  }
</script>





</body>
</html>

