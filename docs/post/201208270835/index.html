<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link rel="canonical" href="http://yut.hatenablog.com/entry/20120827/1346024147" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.55.4" />

  <title>R言語でSVM(Support Vector Machine)による分類学習 &middot; Y&#39;s note</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://yutakikuchi.github.io/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/my.css">
    
  
  
    
        <script src="https://yutakikuchi.github.io/blog/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://yutakikuchi.github.io/">Y's note</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/yutakikuchi_" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://facebook.com/yuta.kikuchi.007" target="_blank"><i class="fa fa-facebook-square fa-fw"></i>Facebook</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/https://www.slideshare.net/yutakikuchi58/" target="_blank"><i class="fa fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/https://www.linkedin.com/in/%E4%BD%91%E5%A4%AA-%E8%8F%8A%E6%B1%A0-36291a44/" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yutakikuchi" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2019. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>R言語でSVM(Support Vector Machine)による分類学習</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Aug 27, 08:35</time>
  </div>

  

  

  

</div>

  

<h2 id="機械学習-r言語でsvm-support-vector-machine-による分類学習">[機械学習] : R言語でSVM(Support Vector Machine)による分類学習</h2>

<p><div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4320121341/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/41ZVTpcKy1L._SL160_.jpg" class="hatena-asin-detail-image" alt="サポートベクターマシン入門" title="サポートベクターマシン入門"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4320121341/yutakikuchi-22/">サポートベクターマシン入門</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> ネロクリスティアニーニ,ジョンショー‐<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%A4%A5%E9%A1%BC">テイラー</a>,Nello Cristianini,John Shawe‐Taylor,大北剛</li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B6%A6%CE%A9%BD%D0%C8%C7">共立出版</a></li><li><span class="hatena-asin-detail-label">発売日:</span> 2005/03</li><li><span class="hatena-asin-detail-label">メディア:</span> 単行本</li><li><span class="hatena-asin-detail-label">購入</span>: 8人 <span class="hatena-asin-detail-label">クリック</span>: 135回</li><li><a href="http://d.hatena.ne.jp/asin/4320121341/yutakikuchi-22" target="_blank">この商品を含むブログ (41件) を見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>とは</h4>

<blockquote>
    <p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Support%20Vector%20Machine">Support Vector Machine</a>の略で教師あり学習に分類されます。線形、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>の識別関数があり現在知られている多くの学習モデルの中では最も優れた識別能力があるとされています。いわゆる2値分類を解くための学習モデルであり、線形しきい素子を用いて分類器を構成します。訓練データにおける各データ点と距離が最大になるマージン最大化という基準で線形しきい素子のパラメータを学習させます。シンプルな例は与えられたデータ集合を全て線形に分離する事です。<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A1%BC%A5%CD%A5%EB%A5%C8%A5%EA%A5%C3%A5%AF">カーネルトリック</a>という<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C8%F3%C0%FE%B7%C1">非線形</a>の分離も可能としており、この部分でも優れた性能を発揮する事が分かっています。この記事では<a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>に備わっているデータを利用して<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>による分類学習を行います。途中でNeuralNetwork、NaiveBayesとの比較も簡単に行います。</p>

</blockquote>

</div>
<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>で<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a></h4>

<blockquote>
    
<div class="section">
<h5>設定</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>で<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>を利用するにはkernlabというパッケージを必要とします。最初にinstallします。またlibrary関数でkernlabを読み込みます。</p>
<pre class="code" data-lang="" data-unlink>$ sudo R
> install.packages( "kernlab" )
> library( kernlab )</pre>
</div>
<div class="section">
<h5>学習データ/予測データを作成</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>に標準で入ったテストデータにIrisというものがあります。Irisを辞書で調べてみると以下のようにアヤメのことを差しています。「 アヤメ科アヤメ属の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C3%B1%BB%D2%CD%D5%BF%A2%CA%AA">単子葉植物</a>の総称。アヤメ・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CF%A5%CA%A5%B7%A5%E7%A5%A6%A5%D6">ハナショウブ</a>・<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AB%A5%AD%A5%C4%A5%D0%A5%BF">カキツバタ</a>など。一般には<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B8%A5%E3%A1%BC%A5%DE%A5%F3%A5%A2%A5%A4%A5%EA%A5%B9">ジャーマンアイリス</a>・ダッチアイリスなどの園芸種をいう。」(<a class="keyword" href="http://d.hatena.ne.jp/keyword/Yahoo%21">Yahoo!</a>辞書から引用)。Irisデータは4行のデータであり、蕚片の長さ/幅、花びらの長さ/幅で種別を定義しているデータです。ここでは蕚片の長さ/幅と花びらの長さ/幅を説明変数、種別を目的変数と呼ぶ事にします。トレーニングデータの説明変数を学習させ、評価データの説明変数から目的変数がどれに分類されるかを評価します。まずはIrisデータの50%をトレーニングデータ、残りの50%を予測を行うデータに分類します。Irisのデータは150行のデータなのでそれぞれ75行分のデータが格納されます。</p>
<pre class="code" data-lang="" data-unlink>#irisのデータの行数を取得
> rowdata<-nrow(iris)

#行数からランダムに行番号を抽出
> random_ids<-sample(rowdata,rowdata*0.5)
> random_ids
 [1] 148  35 114   6  26 129  58  92  20 138 147 107 110  41  88  11 137  52 142
[20]  17  38  55 139 132  21   8   4  49 125  12  84  77 101 122  40   1  25  37
[39]  87  83  61 111  18   5   7 113  56  93 109   3  74  82 134 118  33  42 130
[58]  76  70 103 136 116 106  65  19  16  30  75 143  54  98  60 121  45  94

#学習データを作成
> iris_training<-iris[random_ids, ]
> iris_training
Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
148          6.5         3.0          5.2         2.0  virginica
35           4.9         3.1          1.5         0.2     setosa
114          5.7         2.5          5.0         2.0  virginica
6            5.4         3.9          1.7         0.4     setosa
26           5.0         3.0          1.6         0.2     setosa
129          6.4         2.8          5.6         2.1  virginica
58           4.9         2.4          3.3         1.0 versicolor
92           6.1         3.0          4.6         1.4 versicolor
20           5.1         3.8          1.5         0.3     setosa
138          6.4         3.1          5.5         1.8  virginica
147          6.3         2.5          5.0         1.9  virginica

#予測データを作成
> iris_predicting<-iris[-random_ids, ]
> iris_predicting
Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
2            4.9         3.0          1.4         0.2     setosa
9            4.4         2.9          1.4         0.2     setosa
10           4.9         3.1          1.5         0.1     setosa
13           4.8         3.0          1.4         0.1     setosa
14           4.3         3.0          1.1         0.1     setosa
15           5.8         4.0          1.2         0.2     setosa
22           5.1         3.7          1.5         0.4     setosa
23           4.6         3.6          1.0         0.2     setosa
24           5.1         3.3          1.7         0.5     setosa
27           5.0         3.4          1.6         0.4     setosa</pre>
</div>
<div class="section">
<h4>学習および予測</h4>
<p>作成したトレーニングデータを<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>に学習させて、評価データを入れて正解率を見てみます。ksvm関数で学習させたモデルに対して予測データを入れます。予測データの結果と正解をtableで比較します。setosaとversicolorは100%正解しています。virginicaをversicolorを間違えているのが2つ存在しているため、正解率は<span class="deco" style="color:#FF0000;">71/75 = 94%</span>となります。非常に高い正解率と言えます。</p>
<pre class="code" data-lang="" data-unlink>#ksvm関数でトレーニングデータを学習
> iris_svm<-ksvm(Species ~., data=iris_training )
Using automatic sigma estimation (sigest) for RBF or laplace kernel 
> iris_svm
Support Vector Machine object of class "ksvm" 

SV type: C-svc  (classification) 
 parameter : cost C = 1 

Gaussian Radial Basis kernel function. 
 Hyperparameter : sigma =  0.88455572069582 

Number of Support Vectors : 40 

Objective Function Value : -3.8445 -4.3933 -11.5324 
Training error : 0.026667 

#predict関数で予測データを評価
> result_predict<-predict(iris_svm, iris_predicting)
> result_predict
 [1] setosa     setosa     setosa     setosa     setosa     setosa    
 [7] setosa     setosa     setosa     setosa     setosa     setosa    
[13] setosa     setosa     setosa     setosa     setosa     setosa    
[19] setosa     setosa     setosa     setosa     setosa     versicolor
[25] versicolor versicolor versicolor versicolor versicolor versicolor
[31] versicolor versicolor versicolor versicolor virginica  versicolor
[37] versicolor virginica  versicolor versicolor versicolor versicolor
[43] versicolor versicolor versicolor versicolor versicolor versicolor
[49] versicolor versicolor versicolor virginica  virginica  virginica 
[55] virginica  virginica  virginica  virginica  virginica  versicolor
[61] virginica  virginica  virginica  virginica  virginica  virginica 
[67] virginica  versicolor virginica  virginica  virginica  virginica 
[73] virginica  virginica  virginica 
Levels: setosa versicolor virginica

#予測結果と正解との比較
> table(result_predict,iris_predicting$Species)
          
result_predict setosa versicolor virginica
setosa         23          0         0
versicolor      0         26         2
virginica       0          2        22</pre>
<div class="section">
<h5>散布図</h5>
<p>余談になりますが、訓練データを2変数にすると散布図をplotする事ができます。<br />
<span itemscope itemtype="http://schema.org/Photograph"><a href="http://f.hatena.ne.jp/yutakikuchi/20120826022332" class="hatena-fotolife" itemprop="url"><img src="http://cdn-ak.f.st-hatena.com/images/fotolife/y/yutakikuchi/20120826/20120826022332.png" alt="f:id:yutakikuchi:20120826022332p:image" title="f:id:yutakikuchi:20120826022332p:image" class="hatena-fotolife" itemprop="image"></a></span><br />
</p>

</div>
<div class="section">
<h5>NeuralNetworkでの分類</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>のnnetパッケージを利用してNeuralNetworkでも分類学習をしてみます。先に結果を書いてしまいますが、これにより<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>との正解率を測定したかったのですが、75行のデータに対しては全く同じ精度となりました。正解率は<span class="deco" style="color:#FF0000;">71/75 = 94%</span>となります。本格的に精度を検証するには学習データ、予測データともに数を増やさないといけません。</p>
<pre class="code" data-lang="" data-unlink># パッケージインストール
> install.packages( "nnet" )

# nnetパッケージを読み込み
> library( nnet )

# nnet関数でNeuralNetworkに学習させる
> iris_nnet<-nnet(Species ~ ., data = iris_training, size = 2, rang = .1, decay = 5e-4, maxit = 200)

# 未分類のデータを予測する
> result_predict_nnet<-predict(iris_nnet,iris_predicting,type="class")

# 正解と比較
> table(result_predict_nnet,iris_predicting$Species)
               
result_predict_nnet setosa versicolor virginica
     setosa         23          0         0
     versicolor      0         26         2
     virginica       0          2        22</pre>
</div>
<div class="section">
<h5>NaiveBayesでの分類</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>のe1071パッケージを利用してnaiveBayesによる分類学習も行います。正解との比較では<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>、NeuralNetworkよりも悪い結果となりました。正解率は<span class="deco" style="color:#FF0000;">69/75 = 92%</span>となっています。</p>
<pre class="code" data-lang="" data-unlink># e1071パッケージをインストール
> install.packages( "e1071" )

# e1071の読み込み
> library( e1071 )

# naiveBayesによる学習
> iris_nb<-naiveBayes(Species ~ ., data = iris_training)

# 未分類のデータを予測する
> result_predict_nb<-predict(iris_nb,iris_predicting,type="class")

# 正解と比較
> table(result_predict_nb,iris_predicting$Species)
             
result_predict_nb setosa versicolor virginica
   setosa         23          0         0
   versicolor      0         24         2
   virginica       0          4        22</pre>
</div>
</div>
</blockquote>

</div>
<div class="section">
<h4>SAPM判定分類学習</h4>

<blockquote>
    <p>Iris以外にもkernlabパッケージにはSAPMメールのデータがあります。行数が4601あるのでIrisよりも正確な正解率が出そうです。<a class="keyword" href="http://d.hatena.ne.jp/keyword/SPAM">SPAM</a>データを<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>、NeuralNetwork、naiveBayesのそれぞれのModelに掛けて予測結果の評価を行います。</p>

<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a></h5>
<p><span class="deco" style="color:#FF0000;">(1349+783)/(1349+111+58+783) = 92.65%</span>が正解率となりました。</p>
<pre class="code" data-lang="" data-unlink>> library(kernlab)
> data(spam)
> rowdata<-nrow(spam)
> random_ids<-sample(rowdata,rowdata*0.5)

> spam_training<-spam[random_ids,]
> spam_predicting<-spam[-random_ids,]

> spam_svm<-ksvm(type ~., data=spam_training )
> spam_predict<-predict(spam_svm,spam_predicting[,-58])
> table(spam_predict, spam_predicting[,58])

#結果            
spam_predict nonspam spam
 nonspam    1349  111
 spam         58  783</pre>
</div>
<div class="section">
<h5>NeuralNetwork</h5>
<p><span class="deco" style="color:#FF0000;">(1261+877)/(1261+50+113+877) = 92.91%</span>が正解率となりました。</p>
<pre class="code" data-lang="" data-unlink>
> library( nnet )

> spam_nn<-nnet(type ~., data=spam_training,size = 2, rang = .1, decay = 5e-4, maxit = 200 )
> spam_predict<-predict(spam_nn,spam_predicting[,-58],type="class")
> table(spam_predict, spam_predicting[,58])
        
spam_predict nonspam spam
 nonspam    1261   50
 spam        113  877</pre>
</div>
<div class="section">
<h5>NaiveBayes</h5>
<p><span class="deco" style="color:#FF0000;">(758+866)/(758+61+616+866) = 70.57%</span>が正解率となりました。</p>
<pre class="code" data-lang="" data-unlink>> library( e1071 )

> spam_nn<-naiveBayes(type ~., data=spam_training)
> spam_predict<-predict(spam_nn,spam_predicting[,-58],type="class")
> table(spam_predict, spam_predicting[,58])

spam_predict nonspam spam
 nonspam     758   61
 spam        616  866</pre>
</div>
<div class="section">
<h5>考察</h5>
<p>Irisより十分なデータが与えられたケースでも<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>、NeuralNetworkともに精度差分は変わりありませんでしたが、NaiveBayesだけが著しく悪くなっています。<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>とNeuralNetworkの比較ですが、NeuralNetworkは反復学習回数を増やす事により精度を保っていますが、回数を減らすと精度が悪くなります。例えばmaxit = 200から10に変更してみると正解率が(1275+326)/(1275+601+99+326) = 69.57%まで落ちてしまいます。単純には言い切れないと思いますが、学習コストを少なく精度を求める事ができるのは<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>かもしれません。</p>

</div>
</blockquote>

</div>
<div class="section">
<h4>Links</h4>

<blockquote>
    
<ul>
<li><a href="http://ja.wikipedia.org/wiki/サポートベクターマシン">サポートベクターマシン - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/サポートベクターマシン"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/サポートベクターマシン" alt="はてなブックマーク - サポートベクターマシン - Wikipedia" border="0" /></a></li>
<li><a href="http://ja.wikipedia.org/wiki/単純ベイズ分類器">単純ベイズ分類器 - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/単純ベイズ分類器"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/単純ベイズ分類器" alt="はてなブックマーク - 単純ベイズ分類器 - Wikipedia" border="0" /></a></li>
<li><a href="http://ja.wikipedia.org/wiki/ニューラルネットワーク">ニューラルネットワーク - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/ニューラルネットワーク"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/ニューラルネットワーク" alt="はてなブックマーク - ニューラルネットワーク - Wikipedia" border="0" /></a></li>
<li><a href="http://cran.r-project.org/web/packages/kernlab/index.html">CRAN - Package kernlab</a> <a href="http://b.hatena.ne.jp/entry/cran.r-project.org/web/packages/kernlab/index.html"><img src="http://b.hatena.ne.jp/entry/image/http://cran.r-project.org/web/packages/kernlab/index.html" alt="はてなブックマーク - CRAN - Package kernlab" border="0" /></a></li>
<li><a href="http://mjin.doshisha.ac.jp/R/31/31.html">Ｒとカーネル法・サポートベクターマシン</a> <a href="http://b.hatena.ne.jp/entry/mjin.doshisha.ac.jp/R/31/31.html"><img src="http://b.hatena.ne.jp/entry/image/http://mjin.doshisha.ac.jp/R/31/31.html" alt="はてなブックマーク - Ｒとカーネル法・サポートベクターマシン" border="0" /></a></li>
</ul>
</blockquote>

</div>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://yutakikuchi.github.io/post/201207300844/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://yutakikuchi.github.io/post/201207300844/">R言語を用いた自己回帰モデルによる株価予測を試してみた</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://yutakikuchi.github.io/post/201208290841/">10秒で設定可能なlibsvmで機械学習を行う</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://yutakikuchi.github.io/post/201208290841/"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>



  

</div>

</div>
</div>
<script src="https://yutakikuchi.github.io/js/ui.js"></script>
<script src="https://yutakikuchi.github.io/js/menus.js"></script>


<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-20616165-3', 'auto');
    ga('send', 'pageview');
  }
</script>





</body>
</html>

