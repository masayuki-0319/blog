<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link rel="canonical" href="http://yut.hatenablog.com/entry/20120723/1343000686" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.55.4" />

  <title>初めての機械学習理論 &middot; Y&#39;s note</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://yutakikuchi.github.io/blog/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/my.css">
    
  
  
    
        <script src="https://yutakikuchi.github.io/blog/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://yutakikuchi.github.io/blog/">Y's note</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/yutakikuchi_" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://facebook.com/yuta.kikuchi.007" target="_blank"><i class="fa fa-facebook-square fa-fw"></i>Facebook</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/https://www.slideshare.net/yutakikuchi58/" target="_blank"><i class="fa fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/https://www.linkedin.com/in/%E4%BD%91%E5%A4%AA-%E8%8F%8A%E6%B1%A0-36291a44/" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yutakikuchi" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2019. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>初めての機械学習理論</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Jul 23, 08:44</time>
  </div>

  

  

  

</div>

  

<h2 id="機械学習-初めての機械学習理論">[機械学習] : 初めての機械学習理論</h2>

<p><div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274068463/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/51Mtyyx0u4L._SL160_.jpg" class="hatena-asin-detail-image" alt="はじめての機械学習" title="はじめての機械学習"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4274068463/yutakikuchi-22/">はじめての機械学習</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> 小高知宏</li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A1%BC%A5%E0%BC%D2">オーム社</a></li><li><span class="hatena-asin-detail-label">発売日:</span> 2011/04/22</li><li><span class="hatena-asin-detail-label">メディア:</span> 単行本（ソフトカバー）</li><li><span class="hatena-asin-detail-label">購入</span>: 6人 <span class="hatena-asin-detail-label">クリック</span>: 99回</li><li><a href="http://d.hatena.ne.jp/asin/4274068463/yutakikuchi-22" target="_blank">この商品を含むブログ (9件) を見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

<div class="section">
<h4>はじめての<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a></h4>

<blockquote>
    <p>はじめての<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>という本を読んで学んだことをまとめます。自分で理解した言葉としてまとめています。原文とは異なる可能性があります。またその他自分で勉強した内容についても紹介します。</p>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>とは</li>
<li>パラメータ調整による学習</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A2%C7%BC">帰納</a>的学習</li>
<li>教示的学習</li>
<li>進化的手法による規則学習</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>ライブラリ</li>
<li>その他用語</li>
</ul>
</blockquote>

</div>
<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>とは</h4>

<blockquote>
    
<ul>
<li>「生物」以外の「機械」が学習を行う事。</li>
<li>過去のデータやとある局面のデータを学習して新たな局面に当てはまる有効な知識構成を「汎化」と呼ぶ。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>はゲーム研究での適用が始まりで、人口知能と人間の対戦だった。</li>
<li>評価関数の評価値が高くなるようなパラメータ調整が必要。=>パラメータ調整による<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>。</li>
<li>数値だけでなく形などの構造も学習可能で、具体的な事例から一般知識を抽出する学習を「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A2%C7%BC">帰納</a>的学習」と呼ぶ。</li>
<li>与えられた原理や法則から具体的な事例を導く学習を「演鐸的学習」と呼ぶ。</li>
<li>生物集団の進化モデルをベースにした学習を「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%E4%C5%C1%C5%AA%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">遺伝的アルゴリズム</a>」と呼ぶ。</li>
<li>生物の個体が環境との相互作用によって知識を獲得するモデルを「強化学習」と呼ぶ。</li>
<li>強化学習は環境からの報酬に従い、報酬を最大にする事が目的。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C7%A1%BC%A5%BF%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">データマイニング</a>や<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%AD%A5%B9%A5%C8%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">テキストマイニング</a>にも<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>が用いられる。</li>
<li>生物の神経組織の挙動モデルにより情報処理を行う仕組みを「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a>」と呼ぶ。</li>
<li>この本での学習の一覧と概略は以下の通り。</li>
</ul>
<table>
<tr>
<th> 学習 </th>
<th> 概略 </th>
</tr>
<tr>
<td> パラメータ調整学習 </td>
<td> 時系列データから知識抽出 </td>
<td> </td>
</tr>
<tr>
<td> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A2%C7%BC">帰納</a>的学習 </td>
<td> 暗記学習中心 </td>
</tr>
<tr>
<td> 教科学習 </td>
<td> データ分類規則の学習 </td>
</tr>
<tr>
<td> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%E4%C5%C1%C5%AA%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">遺伝的アルゴリズム</a> </td>
<td> 規則的な学習 </td>
</tr>
<tr>
<td> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a> </td>
<td> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>型の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8%A5%EF%A1%BC%A5%AF">ニューラルネットワーク</a> </td>
<td> </td>
</tr>
</table>
</blockquote>

</div>
<div class="section">
<h4>パラメータ調整による学習</h4>

<blockquote>
    
<ul>
<li>パラメータ調整学習は与えられた学習データを自動的に調整。</li>
<li>学習データの数値を数式に決定することを回帰分析という。例として最小二乗法などがある。</li>
<li>時系列データの周期性や規則性を求めるケースに適用できる。</li>
<li>気温の周期性を求める場合、学習データ(真のデータ)、予測結果、予測の真否を○×で表にまとめる等すると評価が分かる。</li>
</ul>
</blockquote>

</div>
<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A2%C7%BC">帰納</a>的学習</h4>

<blockquote>
    
<ul>
<li>Webサイト上のデータを大量に収集する場面には<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%AD%A5%B9%A5%C8%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">テキストマイニング</a>が有効。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%AD%A5%B9%A5%C8%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">テキストマイニング</a>するには<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a>を必要とする。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a>の流れは以下の通り。
<ul>
<li>文抽出</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF">構文解析</a></li>
<li>意味解析</li>
<li>談話理解</li>
</ul></li>
<li>英文は単語がスペースで区切られているので<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>に分解するのは楽。日本語は大変。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B9%BD%CA%B8%B2%F2%C0%CF">構文解析</a>では<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B8%C0%AE%CA%B8%CB%A1">生成文法</a>に基づき文の構造を記号として置き換える。置き換えた内容を名詞や動詞句として判定する。</li>
<li>意味解析は<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>と構文から判断。</li>
<li>談話理解は上の処理を踏まえて文全体で判定。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/n-gram">n-gram</a>というn個の記号や文字の並びから文の特徴を抽出する。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/n-gram">n-gram</a>全体の個数を表にまとめて上位を見ると特徴が分かる。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/n-gram">n-gram</a>の考え方はテキストの特徴を表す指標のtf-idfにも関連する。</li>
<li>英語の場合<a class="keyword" href="http://d.hatena.ne.jp/keyword/n-gram">n-gram</a>は冠詞(the)や接続詞(and)が多くなる。</li>
<li>tf-idfとはある文章中の出現文字列が文章の特徴をどれだけ表しているかを表現する手法。
<ul>
<li>tf = term frequency idf = inverse document frequency</li>
<li>tfはその文章中の出現回数、idfは一般文章全体の割合。idfの値が大きいと出現頻度が少ない事を示す。</li>
</ul></li>
</ul>
</blockquote>

</div>
<div class="section">
<h4>教示学習</h4>

<blockquote>
    
<ul>
<li>教示学習は教師あり学習とも呼ばれる。教師を無しに指示を受けずに学習を進める手法を教師無し学習と呼ぶ。</li>
<li>教師あり学習
<ul>
<li>効率で精密な学習。</li>
<li>教師が正確な学習を教示。</li>
<li>学習データに現れない状況への対応ができない。</li>
<li>学習を汎化することができない。</li>
</ul></li>
<li>教師無し学習
<ul>
<li>学習の汎化や学習データに依存しない学習が可能。</li>
<li>誤った学習をする可能性がある。 </li>
</ul></li>
<li>教示学習の適用例としてはカテゴリ分類がある。人間にどのカテゴリに属するかを示してもらい知識を学習する。</li>
<li>分類知識の例としては電子メールのスパム判定がある。</li>
<li>分類知識は分類システムの動作を決定する知識関数。</li>
<li>知識分類は命題のYes or Noの判断木という知識の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%DA%B9%BD%C2%A4">木構造</a>で表現することができる。</li>
<li>判断木は論理式よりも記述が<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BE%E9%C4%B9%B2%BD">冗長化</a>することがあり、論理式と比較してデータ構造が大きくなってしまう。</li>
<li>他の知識表現としてプロダクションシステムがあり、AならばBというルールを用いた表現。</li>
<li>分類知識の学習は成功しない場合があることを前提にすべき。</li>
<li>判断木の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>
<ul>
<li>学習セットが空ならば終了。</li>
<li>学習セットの要素が全て単一カテゴリに属するならば終了。</li>
<li>学習セットをサブセットに分類する処理を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BA%C6%B5%A2">再帰</a>的に繰り返す。</li>
<li>属性が無く分類が終わっていなければ手続き終了。</li>
</ul></li>
<li>プロダクションシステムではif 条件式 then カテゴリという式を当てはめる。</li>
<li>特定の分類知識を使って学習データをセットを分類した場合、正しく分類された場合と壮麗外の場合を調べる事が可能。得点を与えて評価。</li>
<li>ランダム生成に基づく分類知識獲得<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>
<ul>
<li>学習デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>の読み込み</li>
<li>乱数に寄る分類知識生成</li>
<li>分類知識の評価 </li>
</ul></li>
</ul>
</blockquote>

</div>
<div class="section">
<h4>進化的手法による規則学習</h4>

<blockquote>
    
<ul>
<li>教示的な学習は探索空間が膨大でどのあたりに有用な知識が存在しているかが不明な場合に有効。探索範囲が明確である場合は、系統的な探索を行う方が有利。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%BF%CD%B9%A9%C3%CE%C7%BD">人工知能</a>の研究では縦型、横型、最良優先、最適化経路探索、A<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>、A*<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>などがある。</li>
<li>ランダム探索で一定の方向性を与える方法として<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BE%C6%A4%AD%A4%CA%A4%DE%A4%B7%CB%A1">焼きなまし法</a>というものがあり、ランダムさを示すパラメータを初期値では高く設定し、そのパラメータを少しずつ修正して徐々に効率の良い探索点を探すこと。探索を1点とするのではなく<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>の探索点を同時に調べる粒子群最適化法、蟻の群れの挙動を模擬することで探索を進める蟻コロニー最適化法などがある。</li>
<li>進化的計算のなかでも<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%E4%C5%C1%C5%AA%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">遺伝的アルゴリズム</a>(Genetic Algorithm, GA)は研究が進んでいて、探索空間の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>の探査点を同時に処理して行く。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%E4%C5%C1%C5%AA%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">遺伝的アルゴリズム</a>における評価関数を適応度関数と呼ぶ。選択にはルーレット選択、ランク選択、トーナメント選択など様々な方法がある。</li>
<li>選択された遺伝子は子孫を作る事ができ、複製や一部改変することを交叉(crossover)、突然変異(mutation)がある。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%E4%C5%C1%C5%AA%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">遺伝的アルゴリズム</a>では最良会を求める代わりにまずまずの結果を与える解を素早く求める事を目的としている。</li>
<li>採用する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B0%E4%C5%C1%C5%AA%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">遺伝的アルゴリズム</a>の一般的な方法としてSimple GA(SGA)というものがある。</li>
<li>SGAの処理手順
<ul>
<li>遺伝子プールの初期化</li>
<li>交叉</li>
<li>突然変異</li>
<li>結果の出力</li>
<li>繰り返し</li>
</ul></li>
<li>エリート保存は世代交代で親世代のエリート遺伝子を子供世代にそのまま残すこと。子世代の結果が親世代と比較して低下しないようにする。</li>
</ul>
</blockquote>

</div>
<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a></h4>

<blockquote>
    
<ul>
<li>生物の神経細胞やネットワーク挙動にヒントを得た<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>システム。生物の神経網と明確に区別したい場合は人工神経路網、人工<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>等と呼ぶ事もある。</li>
<li>神経細胞をモデル化したニュールセル(<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%ED%A5%F3">ニューロン</a>、人工<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%ED%A5%F3">ニューロン</a>、ニュール素子)をノートとして用い、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>のニューロセルを結合してネットワークを構成する。</li>
<li>ニューロセルは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>の入力を待ち、それぞれに特定の重み付けをした上で足し合わせをする。足し合わせた結果から<a class="keyword" href="http://d.hatena.ne.jp/keyword/%EF%E7%C3%CD">閾値</a>を引いて値を求める。数式で書くと次のよう。 xは入力、wは重み、vは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%EF%E7%C3%CD">閾値</a>。</li>
</ul><p><img src="http://chart.apis.google.com/chart?cht=tx&chl=u%20%3D%20%5Csum_%7Bi%7Dx_%7Bi%7Dw_%7Bi%7D-v" alt="u = \sum_{i}x_{i}w_{i}-v"/></p>

<ul>
<li>uの値を適当な関数fに適用してニュール素子の出力zを獲得する。fは出力関数。出力関数はステップ関数や<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>のようになる。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%B0%A5%E2%A5%A4%A5%C9%B4%D8%BF%F4">シグモイド関数</a>は以下のように示される。</li>
</ul><p><img src="http://chart.apis.google.com/chart?cht=tx&chl=f%28u%29%20%3D%20%5Cfrac%7B1%7D%7B1%20%2B%20e%5E%7B-u%7D%7D" alt="f(u) = \frac{1}{1 + e^{-u}}"/> </p>

<ul>
<li>ニューロセル単体でも情報処理が可能だが、ニュールセルを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>結合して<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>を構成することで更に高度な情報処理機構を実現することが可能。ネットワークの最終的な出力が計算されることを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%A3%A1%BC%A5%C9%A5%D5%A5%A9%A5%EF%A1%BC%A5%C9">フィードフォワード</a>ネットワーク(Feed Foward Network)または階層的なネットワークと呼ぶ。ニューロセルが自分自身にフィードバックして入力の一部になることをリカレントネットワーク(Recurrent Network)と呼ぶ。リカレントネッワークのうち、ニューロセルが互いに双方向に結合しているものをポップフィールドモデル(Hopfield Model)と呼ぶ。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>はフォードフォワード型のネットワークで特定の形式を持った<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>は3層の階層構造をもった<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>。入力層→中間層への加重や<a class="keyword" href="http://d.hatena.ne.jp/keyword/%EF%E7%C3%CD">閾値</a>は乱数で、中間層→出力層への加重や<a class="keyword" href="http://d.hatena.ne.jp/keyword/%EF%E7%C3%CD">閾値</a>は学習で決まる。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>では入力層から中間層の結合荷重を変更しなくても、中間層から出力層への結合荷重を適切に選ぶことで<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CF%C0%CD%FD%C0%D1">論理積</a>/<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CF%C0%CD%FD%CF%C2">論理和</a>等の動作を行う事ができる。しかし中間層→出力層の調整では<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C7%D3%C2%BE%C5%AA%CF%C0%CD%FD%CF%C2">排他的論理和</a>(XOR)に対応する出力はできない。入力層→中間層の荷重値によっては<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C7%D3%C2%BE%C5%AA%CF%C0%CD%FD%CF%C2">排他的論理和</a>も実現が可能。</li>
<li>学習デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>を与えて出力誤差が小さくなるように結合荷重と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%EF%E7%C3%CD">閾値</a>を調整する。結合荷重と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%EF%E7%C3%CD">閾値</a>の学習にはへブの学習則(Hebbian learning rule)を用いる。へブは頻繁に信号を伝達する<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B7%A5%CA%A5%D7%A5%B9">シナプス</a>の結合がより強化される。正しい結果を与える回路はより結合荷重を大きくして誤った結果を与える回路の結合荷重は小さくする事でネットワークとして学習が可能。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>の学習手続き
<ul>
<li>適当な終了条件まで以下を繰り返す。</li>
<li>学習デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>の中の一つの例として<img src="http://chart.apis.google.com/chart?cht=tx&chl=%28x_%7B1%7D%2Cx_%7B2%7D%2Co_%7B1%7D%29" alt="(x_{1},x_{2},o_{1})"/>について以下を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=%28x_%7B1%7D%2Cx_%7B2%7D%29" alt="(x_{1},x_{2})"/>を用いて中間層の出力<img src="http://chart.apis.google.com/chart?cht=tx&chl=h_%7Bi%7D" alt="h_{i}"/>を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=h_%7Bi%7D" alt="h_{i}"/>を用いて出力層oを計算する。</li>
<li>出力層のニューロセルについて以下を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=%20w_%7Bi%7D%20%3D%20w_%7Bi%7D%20%2B%20%5Calpha%20%2A%20E%20%2A%20o%20%2A%20%281-o%29%20%2A%20h_%7Bi%7D" alt=" w_{i} = w_{i} + \alpha * E * o * (1-o) * h_{i}"/></li>
</ul></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D1%A1%BC%A5%BB%A5%D7%A5%C8%A5%ED%A5%F3">パーセプトロン</a>の線形分離不可問題を回避して階層型の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%CB%A5%E5%A1%BC%A5%E9%A5%EB%A5%CD%A5%C3%A5%C8">ニューラルネット</a>をより幅広い対象について学習を行うためには出力層に加えて中間層の結合荷重を調整する必要がある。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%C3%A5%AF%A5%D7%A5%ED%A5%D1%A5%B2%A1%BC%A5%B7%A5%E7%A5%F3">バックプロパゲーション</a>(back propagation、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%ED%BA%B9%B5%D5%C5%C1%C7%C5">誤差逆伝播</a>)</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%C3%A5%AF%A5%D7%A5%ED%A5%D1%A5%B2%A1%BC%A5%B7%A5%E7%A5%F3">バックプロパゲーション</a>の学習手続き
<ul>
<li>適当な終了条件まで以下を繰り返す。</li>
<li>学習デー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>の中の一つの例として<img src="http://chart.apis.google.com/chart?cht=tx&chl=%28x_%7B1%7D%2Cx_%7B2%7D%2Co_%7B1%7D%29" alt="(x_{1},x_{2},o_{1})"/>について以下を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=%28x_%7B1%7D%2Cx_%7B2%7D%29" alt="(x_{1},x_{2})"/>を用いて中間層の出力<img src="http://chart.apis.google.com/chart?cht=tx&chl=h_%7Bi%7D" alt="h_{i}"/>を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=h_%7Bi%7D" alt="h_{i}"/>を用いて出力層oを計算する。</li>
<li>出力層のニューロセルについて以下を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=%20w_%7Bi%7D%20%3D%20w_%7Bi%7D%20%2B%20%5Calpha%20%2A%20E%20%2A%20o%20%2A%20%281-o%29%20%2A%20h_%7Bi%7D" alt=" w_{i} = w_{i} + \alpha * E * o * (1-o) * h_{i}"/></li>
<li>中間層のj番目のニューロセルについて以下を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=%5Cbigtriangleup_%7Bj%7D%20%3D%20h_%7Bj%7D%20%2A%20%281-h_%7Bj%7D%29%20%2A%20w_%7Bj%7D%20%2A%20E%20%2A%20o%20%2A%20%28%201%20-%20o%20%29" alt="\bigtriangleup_{j} = h_{j} * (1-h_{j}) * w_{j} * E * o * ( 1 - o )"/></li>
<li>中間層j番目のニューロセルのi番目の出力について以下を計算する。</li>
<li><img src="http://chart.apis.google.com/chart?cht=tx&chl=w_%7Bji%7D%20%3D%20w_%7Bji%7D%20%2B%20%5Calpha%20%20%2A%20x_%7Bi%7D%20%2B%20%5Cbigtriangleup_%7Bj%7D%20%20" alt="w_{ji} = w_{ji} + \alpha  * x_{i} + \bigtriangleup_{j}  "/></li>
</ul></li>
</ul>
</blockquote>

</div>
<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>ライブラリ</h4>

<blockquote>
    <p>有名な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>ライブラリを列挙します。</p>

<ul>
<li><a href="http://opencv.jp/">OpenCV.jp</a> <a href="http://b.hatena.ne.jp/entry/opencv.jp/"><img src="http://b.hatena.ne.jp/entry/image/http://opencv.jp/" alt="はてなブックマーク - OpenCV.jp" border="0" /></a></li>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/liblinear/">LIBLINEAR -- A Library for Large Linear Classification</a> <a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/liblinear/"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/liblinear/" alt="はてなブックマーク - LIBLINEAR -- A Library for Large Linear Classification" border="0" /></a></li>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM -- A Library for Support Vector Machines</a> <a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/libsvm/"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/libsvm/" alt="はてなブックマーク - LIBSVM -- A Library for Support Vector Machines" border="0" /></a></li>
<li><a href="http://code.google.com/p/oll/wiki/OllMainJa">OllMainJa - oll - oll: Online-Learning Library - Google Project Hosting</a> <a href="http://b.hatena.ne.jp/entry/code.google.com/p/oll/wiki/OllMainJa"><img src="http://b.hatena.ne.jp/entry/image/http://code.google.com/p/oll/wiki/OllMainJa" alt="はてなブックマーク - OllMainJa - oll - oll: Online-Learning Library - Google Project Hosting" border="0" /></a></li>
<li><a href="http://mahout.apache.org/">Apache Mahout: Scalable machine learning and data mining</a> <a href="http://b.hatena.ne.jp/entry/mahout.apache.org/"><img src="http://b.hatena.ne.jp/entry/image/http://mahout.apache.org/" alt="はてなブックマーク - Apache Mahout: Scalable machine learning and data mining" border="0" /></a></li>
<li><a href="http://www.cs.waikato.ac.nz/ml/weka/">Weka 3 - Data Mining with Open Source Machine Learning Software in Java</a> <a href="http://b.hatena.ne.jp/entry/www.cs.waikato.ac.nz/ml/weka/"><img src="http://b.hatena.ne.jp/entry/image/http://www.cs.waikato.ac.nz/ml/weka/" alt="はてなブックマーク - Weka 3 - Data Mining with Open Source Machine Learning Software in Java" border="0" /></a></li>
<li><a href="http://nltk.org/">Natural Language Toolkit ― NLTK 2.0 documentation</a> <a href="http://b.hatena.ne.jp/entry/nltk.org/"><img src="http://b.hatena.ne.jp/entry/image/http://nltk.org/" alt="はてなブックマーク - Natural Language Toolkit ― NLTK 2.0 documentation" border="0" /></a></li>
</ul>
</blockquote>

</div>
<div class="section">
<h4>その他用語</h4>

<blockquote>
    
<table>
<tr>
<th> 用語 </th>
<th> 意味 </th>
</tr>
<tr>
<td> 学習データ、訓練データ </td>
<td> 機械に学習させるデータ </td>
</tr>
<tr>
<td> 正解データ </td>
<td> 学習した成果を評価するデータ </td>
</tr>
<tr>
<td> 素性/特徴量 </td>
<td> 現象を特徴付けるもの </td>
</tr>
<tr>
<td> ラベル </td>
<td> 学習したデータをどれかのクラスに分類する単位 </td>
</tr>
<tr>
<td> 従属変数(目的変数) </td>
<td> 説明したい変数、注目した変数 </td>
</tr>
<tr>
<td> 独立変数(説明変数) </td>
<td> 説明するために用いられる変数 </td>
</tr>
<tr>
<td> 回帰分析 </td>
<td> 従属変数が独立変数によってどれだけ説明できるかを定量的に測定する事 </td>
</tr>
<tr>
<td> 交差検定 </td>
<td> 標本データをTraningSetとTestSetに分類し、TraningSetで学習をする。TraningSetの評価にTestSetを使う </td>
</tr>
<tr>
<td> マイクロ平均 </td>
<td> Nセットのテストをする場合、テストを合計してから評価値を計算  </td>
</tr>
<tr>
<td> マクロ平均 </td>
<td> Nセットのテストをする場合、各セットを計算してからそれらを平均する計算 </td>
</tr>
<tr>
<td> 正確度(Accuracy) </td>
<td> 値が真値に近いことを示す尺度 </td>
</tr>
<tr>
<td> 精度(Precision) </td>
<td> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>個の値の中でばらつきが少ない尺度 </td>
</tr>
<tr>
<td> 評価関数 </td>
<td> 精度を評価するための関数を利用して数値化する </td>
<td> </td>
</tr>
</table><p>マイクロ平均の式 :  <img src="http://chart.apis.google.com/chart?cht=tx&chl=n_%7Bi%7D" alt="n_{i}"/>回のテストのうち，<img src="http://chart.apis.google.com/chart?cht=tx&chl=x_%7Bi%7D" alt="x_{i}"/>回が正解の場合<br />
<img src="http://chart.apis.google.com/chart?cht=tx&chl=%5Cfrac%7B%20%5Csum_%7Bi%3D0%7D%5ENx_%7Bi%7D%20%7D%7B%20%5Csum_%7Bi%3D0%7D%5ENn_%7Bi%7D%20%7D" alt="\frac{ \sum_{i=0}^Nx_{i} }{ \sum_{i=0}^Nn_{i} }"/> <br />
マクロ平均の式 : <img src="http://chart.apis.google.com/chart?cht=tx&chl=n_%7Bi%7D" alt="n_{i}"/>回のテストのうち，<img src="http://chart.apis.google.com/chart?cht=tx&chl=x_%7Bi%7D" alt="x_{i}"/>回が正解の場合<br />
<img src="http://chart.apis.google.com/chart?cht=tx&chl=%5Cfrac%7B1%7D%7BN%7D%20%5Csum_%7Bi%3D0%7D%5EN%5Cfrac%7Bx_%7Bi%7D%7D%7Bn_%7Bi%7D%7D" alt="\frac{1}{N} \sum_{i=0}^N\frac{x_{i}}{n_{i}}"/> </p>

</blockquote>

</div>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://yutakikuchi.github.io/blog/post/201207170832/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://yutakikuchi.github.io/blog/post/201207170832/">BehaviorTargeting調査レポート</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://yutakikuchi.github.io/blog/post/201207300844/">R言語を用いた自己回帰モデルによる株価予測を試してみた</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://yutakikuchi.github.io/blog/post/201207300844/"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>



  

</div>

</div>
</div>
<script src="https://yutakikuchi.github.io/blog/js/ui.js"></script>
<script src="https://yutakikuchi.github.io/blog/js/menus.js"></script>


<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-20616165-3', 'auto');
    ga('send', 'pageview');
  }
</script>





</body>
</html>

