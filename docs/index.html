<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link rel="canonical" href="http://yut.hatenablog.com" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.55.4" />

  <title>Y&#39;s note</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  
  <link rel="alternate" type="application/rss+xml" title="Y&#39;s note" href="https://yutakikuchi.github.io/blog/index.xml" />
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://yutakikuchi.github.io/blog/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://yutakikuchi.github.io/blog/css/my.css">
    
  
  
    
        <script src="https://yutakikuchi.github.io/blog/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://yutakikuchi.github.io/blog/">Y's note</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://yutakikuchi.github.io/blog/index.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/yutakikuchi_" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://facebook.com/yuta.kikuchi.007" target="_blank"><i class="fa fa-facebook-square fa-fw"></i>Facebook</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/https://www.slideshare.net/yutakikuchi58/" target="_blank"><i class="fa fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/https://www.linkedin.com/in/%E4%BD%91%E5%A4%AA-%E8%8F%8A%E6%B1%A0-36291a44/" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yutakikuchi" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2019. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Y&#39;s note</h1>
  <h2></h2>
</div>

<div class="content">
  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201904292103/">Docker for Macのメモリ制限の調整</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2019 Apr 29, 21:03</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [etc] : Docker for Macのメモリ制限の調整  Get started with Docker Desktop for Mac | Docker Documentation
 Install Docker Desktop for Mac | Docker Documentation
  Memory: By default, Docker Desktop for Mac is set to use 2 GB runtime memory, allocated from the total available memory on your Mac. To increase RAM, set this to a higher number; to decrease it, lower the number.
 Docker for Macを使ってDocker runする際に --memory(-m) ではメモリの制限が指定できない。 Defaultの制限は2Gになっている。下記を実行しても10Gに反映されない
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/blog/post/201904292103/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201809241706/">Kerasでお試しCNN</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Sep 24, 17:06</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [etc] : Kerasでお試しCNN ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装
作者: 斎藤康毅出版社/メーカー: オライリージャパン発売日: 2016/09/24メディア: 単行本（ソフトカバー）この商品を含むブログ (18件) を見る
30分でDeepLearningを実行できるようにお試しするキット。手っ取り早く始めるためにkeras(Tensorflow backend)をinstall。kerasについては下記のページで紹介されている。 尚、下にinstallのlogを残しているがkerasの前にBackendとなるTensorflowをinstallすると良い。
引用 : Kerasは，Pythonで書かれた，TensorFlowまたはCNTK，Theano上で実行可能な高水準のニューラルネットワークライブラリです． Kerasは，迅速な実験を可能にすることに重点を置いて開発されました． アイデアから結果に到達するまでのリードタイムをできるだけ小さくすることが，良い研究をするための鍵になります． Keras Documentation
$ sudo pip install keras Cannot uninstall 'six'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. // sixを再度install $ sudo pip install keras --ignore-installed six Installing collected packages: six, numpy, h5py, keras-applications, scipy, keras-preprocessing, pyyaml, keras Running setup.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/blog/post/201809241706/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201809180049/">tmux : powerlineの表示ズレを解消する</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Sep 18, 00:49</time>
  </div>

  

  

  

</div>

  </header>

  <p>
   [etc] : tmux : powerlineの表示ズレを解消する 表示ズレの解消 
ref : tmux 2.5 以降において East Asian Ambiguous Character を全角文字の幅で表示する &middot; GitHub file-tmux-2-7-fix-diff : https://gist.github.com/z80oolong/e65baf0d590f62fab8f4f7c358cbcc34#file-tmux-2-7-fix-diff
上図のようにtmuxのpowerline行がずっと増え続ける問題を解消する。対応方針としてはpatchを当てる。PC環境はMac、tmuxのversionは2.7を想定。patchは上記gistにversion毎にpatchが用意されている。brew edit tmuxコマンドで下記内容を追記し、brew reinstallにてpatchを適用し再度install。
// コマンドは下記を実行 $ tmux -V tmux 2.7 $ brew edit tmux // 下記を追記 def patches [ "https://gist.githubusercontent.com/z80oolong/e65baf0d590f62fab8f4f7c358cbcc34/raw/d478a099aa5074e932e3323e9b16033e13919cdf/tmux-2.7-fix.diff" ] end $ brew reinstall --build-from-source tmux == Summary 🍺 /usr/local/Cellar/tmux/2.7: 10 files, 705.2KB, built in 29 seconds  
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201809170141/">DeepLearningによる画像解析</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Sep 17, 01:41</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [etc] : DeepLearningによる画像解析 概要 http://www.image-net.org/challenges/LSVRC/ http://www.image-net.org/challenges/LSVRC/2012/
ILSVRC(ImageNet Large Scale Visual Recognition Challenge)はImageNetが毎年主催するコンピュータを利用した画像解析による物体認識・検出のコンペ。2012年にDeepLearningの手法が登場し、物体認識・検出の技術として3位以降のMachineLearningチームとError率で圧倒的な差をつけて優勝したことから注目を集めた。DeepLearningによる画像解析タスクといっても目的が複数存在するため、言葉の定義を下記にまとめる。
 物体認識(Object Recognition・Classification) : 1枚ずつの画像毎に何の物体であるかを認識する。(1枚の画像に対して1つの物体のラベルを付与する。) 物体位置特定(Object Localization) : 1枚の画像の中に物体が何処に映っているかの領域を認識する。 物体検出(Object Detection) : 1枚の画像の中に何が何処に映っているかを検出する。(1枚の画像に対して複数の物体のラベルと領域を認識する。) セグメンテーション(Segmentation)  : 1枚の画像の中に何が何処に映っているかをピクセル単位で分離する。  Object Recognition: which object is depicted in the image? Object detection: where is this object in the image?
Ref : image processing - Object detection versus object recognition - Signal Processing Stack Exchange
画像解析アルゴリズム   DeepLearningの画像解析アルゴリズムは目的により多数あり、それぞれで使用目的が異なる。
 物体認識(Object Recognition・Classification)  VGG(Visual Geometry Group : team)  Visual Geometry Group Home Page 畳み込みとプーリング層で構成される基本的なCNN。層の数でVGG16、VGG19がある。   ResNet(Residual Network)  https://arxiv.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/blog/post/201809170141/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201809090609/">Computer Vision : Visual Importance Mapの研究</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Sep 09, 06:09</time>
  </div>

  

  

  

</div>

  </header>

  <p>
   [etc] : Computer Vision : Visual Importance Mapの研究 Youtube : 
Paper :  
Ref: http://web.mit.edu/zoya/www/docs/predImportance_final.pdf http://www.dgp.toronto.edu/~donovan/layout/designLayout.pdf
MIT・Toronto大・Adobeなど様々な企業において、特定のGraphic Designに対して、どこが人が注目しているかをVisualizationするVisual Importance Mapという仕組みが研究されている。可視化の方法としてはGraphic Designの上にHeat Mapとして注目される領域をAIにより予測してOverlayしている。
一般的なCreative作成においてはGraphic Designerの経験と勘に基づいて作られているが、DesignのAudienceが注目されやすいポイントをVisualizationすることで新しいInsightをDesignerに与える。更にGraphic DesignerがInteractiveにCreativeを操作可能な画面の中で効果を予測しながら編集しリアルタイムに新しい価値を気づくことが可能な環境を提供することで、従来必要としたA/BテストによるAudienceの反応を計測する必要が無く、Operationコストと事前に効果を最大化するための施策を実行できることが魅力となる。

Designの効果の予測はどうやっているのか。PaperによるとAIへの入力となるデータについてはflickrのDesign、Mturkを利用して多人数にAnnotationをさせている。 Amazon Mechanical Turk
Annotationの方法としてはBubble ViewというCreativeをぼやかした状態において、Annotatorがどこをより見たいかを選択してもらう。これよりGround truth(教師データ)を集める。Ground truthデータをFully Convolutional Networks (FCNs)にかけてModelを生成し、新しいデータをModelに適用することでCreative上の注目ポイントを画像のPixelレベルで表示を可能としている。類似のResearchとしてSaliency Mapという人間の脳へのbottom-up性注意を予測するModelがある。(Saliencyの場合は視覚としての刺激を抽出することで、例えば暗い夜に月が明るく照らされると対比によって月の効果を認識する心理学的理論を示す)
Ref : github.com
既にAdobe senseiなどのApplicationでは上のようなGraphic Designの最適化、自動生成の世界が発表されており、今後ますます注目されてくる領域である。 
www.adobe.com
 
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201809080344/">製造業のAI導入</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Sep 08, 03:44</time>
  </div>

  

  

  

</div>

  </header>

  <p>
   [AI] : 製造業のAI導入 Industory4.0、SmartFactory Industory4.0, SmartFactoryという言葉があるように製造業の工場ラインに対してIoT・AIを導入し生産工程をデジタル化する計画がある。生産工程のデジタル化の先に人が担っていた作業を補助する目的でのAI・IoT導入検討が進められている。
https://ja.wikipedia.org/wiki/%E3%82%A4%E3%83%B3%E3%83%80%E3%82%B9%E3%83%88%E3%83%AA%E3%83%BC4.0
製造業といってもIoT・AIの活用検証は多岐にわたる。 1. 製造ライン・プロセスでの検品作業の自動化 2. 製造機器の故障発生をセンサーログデータなどから予測する予防保全 3. 製造ラインを効率化するための生産計画の効率化

引用 : https://www.projectdesign.jp/201704/ai-business-model/003521.php
上記以外にも様々な検証が進んでおり、2030年にはAI活用業界のTopとして名を連ねることが予想されている。製造物に異常が発生したときの予算ロスはビジネス的なインパクトとして非常に大きいので、今後AI導入の注目業界であることは確かである。ただし、現状の製造業はAI導入のための課題はたくさん存在する。下記は製造ラインの異常検知の課題を列挙している。
データ収集の課題  紙などで情報を記録、デジタルデータを保存していないケースが存在する 製造ラインに対してIoTデバイスの設定が物理的に難しく、デジタルデータを収集するのに時間を要する。現状の製造ラインがIoTを導入することを前提とした設計になっていない。 熟練者に依存するタスクが多く、その人でないと判断ができない。また基準化、言語化がされていない。作業者の暗黙知、形式知のそれぞれのナレッジメントとデータが明確化されていない。 検品作業自動化のための異常データが発生する確率が少なく、これからデータを貯めるフェーズだとAI導入に時間が掛かる。 各社のデータ管理ポリシーが強固である。製造ラインのオンプレミスな環境から、クラウドなど外部にデータを預けることはポリシーに反することがある。  AI導入の課題  検品作業の人が担っているプロセスにおいては異常を検知する精度が高い。またAIが出力可能な精度はまだ100%にないため、作業すべてを置き換えることができない。 IoT・AIの両方をセットで新規導入するケースについては、IoTで撮像条件を良い状態にしつつ、AIの精度を上げる必要があるので、対応の時間が長期化するケースが多い。仮に精度問題が発生したときに、初期においてはどちらに原因があるかを都度分解する必要がある。 業務プロセス側のドメインを知らない作業者がAIのモデル運用を続けることで、実運用と乖離した最適化をしてしまうリスクがある。 AIによる異常検知が目的となってしまい、本質的な製造機やパーツが不良となる原因分析の方にフィードバックができない。  新しい動き 一方で最近の取り組みとしては良い材料も多い。工場の老朽化により製造ラインを新しく設計するケースも有り、その場合はIoT・AIの導入を見据えた形でリプレイスが検討されている。また製造ラインの担当者も異常検知が主目的ではなく、異常が発生する原因を特定するための製造物の正しい状態把握をデジタルデータで蓄積し、可視化から分かる機械工学の改善シフトに軸を移そうという動きも見受けられる。
製造業のAI導入の課題はまだまだ山積みではあるが、技術的な取り組みとしては非常にチャレンジングな領域であり、今後もこの方面には継続してトライをしていきたい。
 
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201808121805/">運のコントロール</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Aug 12, 18:05</time>
  </div>

  

  

  

</div>

  </header>

  <p>
   [etc] : 運のコントロール 逆説のスタートアップ思考 (中公新書ラクレ 578)
作者: 馬田隆明出版社/メーカー: 中央公論新社発売日: 2017/03/08メディア: 新書この商品を含むブログ (1件) を見る
馬田隆明さんの逆説のスタートアップを読んだ。アイディア、戦略、プロダクト、運についてそれぞれの章ごとに書かれており、スタートアップに携わる人は一読することをおすすめする。起業の科学などアイディア〜プロダクトについては説明がある他の本もあるが、運についてはなかなか見ることがなかったコンテンツなので、読んでいて非常に面白かった。なお、馬田さんはスタートアップについて様々なコンテンツをslideshareで共有している。
※ 第四章、運についての言及をメモとして共有。ただし、内容は意訳とし記載しています。 「運もある程度コントロール可能である」。①成功している起業家こそ、リスクを嫌う傾向があり、リスクを管理するためのポートフォリオを作成する。スタートアップの一つの行動がリスクであるのだとすると、それ以外の分野では慎重に行動をする。アインシュタインは特許庁に勤めながら相対性理論を、カフカは保険局員として働きながら返信を書き上げた。②成功している起業家はタイミングを伺ってる。一番乗りで市場に入ることが正しくもなく、適切なタイミングまでじっくりと待っている。盛り上がっている市場に焦って参入することにより失敗する確率が高くなっているという報告もある。加熱が過ぎた、もしくは悪い時期に参入している方が成功確率が高くなる。③成功している起業家はチャンスを失うリスクのほうがリスクであると認識をしているので、今あるもののリスクではなく、将来を見て判断をしている。特にチャンスを失うというリスクの方を危惧する傾向がある。
ブラックスワンのように予期せぬリスクが発生する事も当然有り得て、そこの対しての回避戦略がいくつかある。一つの例としては「バーベル戦略」とい言われるもので、ハイリスクな投資を10〜15%、それ以外には健全な投資として85%〜90%を確保しておく。中間な投資は一切持たないという手法であるが、相対的にはミドルなリスクを取っていることになる。ミドルなリスクとして全てを保有していると予期せぬブラックスワンに耐えられず、全てが吹っ飛んでしまう可能性もある。
アンチフラジャイルという脆弱性を逆にうまく活かすことこそがスタートアップである。現実世界にあるボラティリティによる非対称な良いブラックスワンこそがイノベーションであるという説があるように、良いリスクに張ることがスタートアップであるという考え方。
挑戦の量が質を生みだす。 とある事例として、あるグループを量で評価する試験、質で評価する試験を同じ時間で回したときに、最終的には量で評価するグループの方が良い質を生み出せた。量による試行錯誤の回数を増やすことが非常に効果的であることを裏付ける例。アインシュタインは248、ダーウィンは119、フロイトは330の論文を書いている、エジソンは1093の特許、バッハは1000曲以上を作曲、ピカソは2万以上の作品を残しているように、天才も数多くの挑戦をしており、彼らの成功している時期は失敗を重ねていた時期と一致するという内容もあり、如何に試行錯誤が重要であるかが分かる。
以上が意訳内容。運もある程度コントロール可能であるという背景は、失敗のリスクも合わせてコントロールすることで、大きな失敗をする前に成長を持続させるという話。第四章だけでも時間があったら読み返したいと思える内容でした。
 www.slideshare.net
そこに張る勇気逆説のスタートアップ思考 (中公新書ラクレ 578)
作者: 馬田隆明出版社/メーカー: 中央公論新社発売日: 2017/03/08メディア: 新書この商品を含むブログ (1件) を見る
未来を正しく予測すること、どんなに優秀な人物が未来を考えても非常に難しいという事実がある。数多くの発明家や起業家が自分が描く未来へ投資を行い、失敗し続けてきた歴史もある。「未来は予期せぬところからやってくる」Y Comibinatorの設立者でもあるポール・グレアムも未来を予測することの難しさから、未来へのアイディアではなく考える人に注目すべきという話もある。
正しく予測できなかったとしても、現在〜未来を目指す中で「失敗の確率を減らすこと」は可能である。一見ダメそうなアイディアでも、隠れた良いアイディアを見つけることがスタートアップでは重要な要素とされているが、隠れた良いアイディアを実現する際に、検証というプロセスを入れることである程度のリスクを回避することができる。検証は最大の効果としては、その領域に携わる人間に対してアイディアを投げかけてみたり、課題となる一次情報を集めることで、自分のアイディアに対して客観的な感覚を注入することである。
検証されたアイディアに対して実施すべきかどうかの判断に必要なもの、それは経営者としてそこに張る勇気である。小さな市場にまずは目を向けて、そこの独占的なプレイヤーとなること。それを基に次は大きな市場を狙う。小さく成功を作って、大きく展開する。仮にそこで失敗、やり方を変えるためにピボットしても、バッターボックスに立ち続けてバットを振り続ければ、おそらく立ち直れる。そこに張る勇気。これが本当に重要。
 
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201808051306/">RPAとAIの違い</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Aug 05, 13:06</time>
  </div>

  

  

  

</div>

  </header>

  <p>
   [AI] : RPAとAIの違い RPAとAI  RPA = Robotic Process Automation AI = Artificial Intelligence  これらの違いは？ なるほど、言葉の定義だけでは違いが分からん。
RPAとは狭義の意味では、ルールベースをロジックとした人間の作業を簡易化・もしくは自動化する仕組みで、Webツールなどで提供される。狭義の中では人間の作業が全てルールに落として、それをシステムの機能で再現させることである。RPAの定義では人の簡易的な脳を機械にコピーをしていくため、機械が自ら学ぶような世界観は含まれない。RPAを広義に捉えると簡易的なAIも含めて人間の作業をルール化していく仕組みを示すが、AIとの境界面が明確化されないので、ここでは狭義のRPAについて記載している。狭義のRAPにおいては金融系会社などで人の作業を代わりに対応させる実施、例えば伝票への自動入力等が多く進んでいる。
AIは、過去のデータを利用した様々な判断をするための予測をする仕組みを提供する。人間が予測のロジックを事前に提供することで、データからの読み取れる判断ポイントや特徴については機械が解釈をする。例えば写真の中にどのような物体が写っているかを自動的に判別する場合、RPAのように人間が物体を見たときの判断ポイントの全てをルールとして機械に与えるのではなく、それらを機械が自動的に判断するために過去のデータから解釈をしてく。
簡単なまとめ  RPA(Robotic Process Automation) : 人間の作業を機械が解釈可能なルールに落とし、ルールに基づいた作業を機械が自動化するような取り組み。 AI(Artificial Intelligence) : 人によってルール化されないポイントも機械が自動的に解釈し、自動的に物事を判断や予測するための仕組み。  参考URL www.itmedia.co.jp thefinance.jp winactor.com
 
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201808040812/">見えない人工知能を売ることの難しさ</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Aug 04, 08:12</time>
  </div>

  

  

  

</div>

  </header>

  <p>
   [etc] : 見えない人工知能を売ることの難しさ 結果が見えない人工知能 人工知能をCustomerに販売することは難しいとされる。その要因は何か。
一番のポイントはCustomerへの販売を担当するSales担当者も人工知能を開発することにより、Customerの課題が解決できるかが受注のタイミングでは分からないということである。結果が見えないというのは受注のタイミングの話である。
Machine Learning・DeepLearningのどちらの手法を基にしたとしても、Customerの課題に対してデータを集め、人工知能のモデルを作り、その後に評価を行う。このプロセスを踏まえないと、そもそもCustomerが求めるKPIに対して成功・失敗するということが分かりにくい点である。
経験を持った技術者であれば先行研究の内容から特定の課題に対して、どういったデータ量と質、更にはMachine Learning・Deeplearningの手法を採用、モデルのチューニングをすると予測精度◯◯%ぐらいは出るかも、というざっくりした見積もりは可能である。ただし、この経験を持った技術者が人工知能を提供する側にはいたとしても、Customerの中に存在するとは限らない。むしろ存在する可能性は低い。提供側が精度◯◯%出ますのでご安心をという説明が出来たとしても、Customer側は何故そのような結果になるか、という点が理解しづらいはずである。
対して、一般的なWebシステムを開発する場合は、Inputのデータを与えてApplicationのlayerで演算をし、DBに格納・結果の可視化しOutputする一連の流れは、このシステムの業務手続きのフローを明確化したり、結果の出力サンプルをSales担当でもおそらく作成はできるであろうし、そしてこれらの内容を受注の前にイメージの共有がCustomerにでき、おそらく理解も可能なはずである。人工知能のように上記評価プロセスを実施しなくても、結果までがある程度見えてしまうという点が大きい。
最近は人工知能の評価プロセスを回す前、具体的には受注の前のタイミングで簡易的に評価プロセスを回すツールなども多く出てきている。今後これらのニーズは高まっていくであろうが、下記にまとめるように売ることを難しくしている要因全てを解消できるわけではないので、これらは業界の課題としてまだ残り続ける。
難しい要因のまとめ  売ることが難しい要因① : Sales担当者が受注の前にどれほど顧客課題を解決できるかの見積もりが難しい。 売ることが難しい要因② : データを集めて、モデルを構築し、その後に評価を行うプロセスを入れないとプロジェクトの成功・失敗が正確に分からない。 売ることが難しい要因③ : 一般的なシステムと異なり、InputとOutputまでの業務ロジック、更には演算(途中結果を含む)の可視化が難しい。 売ることが難しい要因④ : 人工知能が得意とする、もしくは課題解決可能なものは日々広がりを見せているが、まだまだ人間の能力を大きく超えることが出来ていない。それをCustomerの期待値に合わせて説明するということも難しい。  売る側の人間からのレポートは以上です。
 
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/blog/post/201807230022/">何を問題とし、どのように解くか</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018 Jul 23, 00:22</time>
  </div>

  

  

  

</div>

  </header>

  <p>
   [etc] : 何を問題とし、どのように解くか ビジネスの立場の違う人間同士だと、向き合っている問題が世界情勢、市場、顧客課題詳細など自分が一番解くべき問題についてはレイヤーが異なることが多い。それが故に一緒に問題解決の話をしていても、プロトコルが合わずに、意見の食い違いが発生する。
巷には問題の定義より、課題に対するHowtoのノウハウが溜まっており、方法論ってそんなに重要なんだっけという思いが増してくる。それらにはなぜその問題を解こうとしたのかが書かれていないからだ。重要なのは「何を問題とするか」、その次にどのように解くかの流れである。立場の違う人通しでも、問題の定義がレイヤーごとに明確化され、なぜその問を選定したのかの背景が伝わるだけでも価値があり、そのステップが事前にあれば立場の違う人同士の中でも、意見の食い違いは緩和されるであろう。
 
  </p>

  
</article>

  

  


<nav class="pagination" role="pagination">
  
  <i class="fa fa-chevron-left"></i>
  
  <span>&nbsp;1 / 21&nbsp;</span>
  
  <a href="https://yutakikuchi.github.io/blog/page/2/"><i class="fa fa-chevron-right"></i></a>
  
</nav>



</div>

</div>
</div>
<script src="https://yutakikuchi.github.io/blog/js/ui.js"></script>
<script src="https://yutakikuchi.github.io/blog/js/menus.js"></script>


<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-20616165-3', 'auto');
    ga('send', 'pageview');
  }
</script>





</body>
</html>

