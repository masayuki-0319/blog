<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link rel="canonical" href="http://yut.hatenablog.com" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.55.4" />

  <title>Y&#39;s note</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://yutakikuchi.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  
  <link rel="alternate" type="application/rss+xml" title="Y&#39;s note" href="https://yutakikuchi.github.io/index.xml" />
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://yutakikuchi.github.io/img/favicon.ico" type="image/x-icon" />

  
    
        <link rel="stylesheet" href="https://yutakikuchi.github.io/css/my.css">
    
  
  
    
        <script src="https://yutakikuchi.github.io/js/my.js"></script>
    
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://yutakikuchi.github.io/">Y's note</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://yutakikuchi.github.io/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://yutakikuchi.github.io/index.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/yutakikuchi_" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://facebook.com/yuta.kikuchi.007" target="_blank"><i class="fa fa-facebook-square fa-fw"></i>Facebook</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://slideshare.net/https://www.slideshare.net/yutakikuchi58/" target="_blank"><i class="fa fa-slideshare fa-fw"></i>SlideShare</a>
    </li>
    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://linkedin.com/in/https://www.linkedin.com/in/%E4%BD%91%E5%A4%AA-%E8%8F%8A%E6%B1%A0-36291a44/" target="_blank"><i class="fa fa-linkedin-square fa-fw"></i>LinkedIn</a>
    </li>
    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/yutakikuchi" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2019. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Y&#39;s note</h1>
  <h2></h2>
</div>

<div class="content">
  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201210090830/">線形予測の機械学習ツールliblinearで効果最大化のための最適な定数Cを探る</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Oct 09, 08:30</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [機械学習] : 線形予測の機械学習ツールliblinearで効果最大化のための最適な定数Cを探る Machine Learning for Hackers
作者: Drew Conway,John Myles White出版社/メーカー: Oreilly & Associates Inc発売日: 2012/02/28メディア: ペーパーバック クリック: 63回この商品を含むブログを見る
liblinear   LIBLINEAR -- A Library for Large Linear Classification  10秒で設定可能なlibsvmで機械学習を行う - Yuta.Kikuchiの日記  R言語でSVM(Support Vector Machine)による分類学習 - Yuta.Kikuchiの日記  今日はliblinearを用いた機会学習の話です。今まではSVMを利用するときはkernelオプション付きのR言語のSVM/libsvm/svm-lightを利用していましたが、学習データが多い時に計算時間が何時間も掛かる事に不便を感じていました。そこでSVMのツールについて色々と調べてみたところ、線形予測に特化したliblinearの存在を知りました。公式のDocumentにもlibsvmとliblinearでの線形予測での処理時間が桁違いにliblinearの方が優れていることが記述されています。以下にliblinearの特徴を記述します。
 liblinearはinstanceや特徴が100万桁のデータを線形分離するためのtoolであり以下をサポートしています。  L2正則化の分類  L2-loss linear SVM, L1-loss linear SVM, and logistic regression (LR)  L1正則化の分類  L2-loss linear SVM and logistic regression (LR)  Support Vechtor RegressionのL2正則化  L2-loss linear SVR and L1-loss linear SVR   正則化とはOverfittingを回避するために罰則項を与える事です。種類としてはL1,L2,L1L2の3つが良く利用されるもので精度とスパース性によって異なります。L1は精度が低くスパース性が高い、L2は精度が高くスパース性が低い、L1L2は両方を取り入れ精度を高く保ちながらスパース性を高くすることです。
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201210090830/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201209100835/">そろそろ本気で機械学習の評価方法について学習するよ</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Sep 10, 08:35</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [機械学習] : そろそろ本気で機械学習の評価方法について学習するよ Machine Learning for Hackers
作者: Drew Conway,John Myles White出版社/メーカー: Oreilly & Associates Inc発売日: 2012/02/28メディア: ペーパーバック クリック: 63回この商品を含むブログを見る
機械学習の評価方法について学習  機械学習初心者ですが最近業務で本格的に触り始めています。少し前までSmartPhoneのWebAppliを作ることを専門職としていたので機械学習の領域は未知な事が非常に多く、用語の意味ですら十分に理解できていません。今日は機械学習の評価方法を中心に学習(勉強)した内容を記録して行きます。例えばPrecision/Accuracy/Recallの言葉の違いやROC曲線,AUC評価などの技法といったものが話の中心になります。初心者視点で書いていますので専門性がありません。間違い等ありましたらご指摘ください。また以前にもはじめての機械学習という本のサマリーを書いたのでそちらも参照していただけると嬉しいです。
初めての機械学習理論 - Yuta.Kikuchiの日記 
  用語定義  初めに慣れない用語が多いので、その意味を定義します。
   用語   意味     K-Fold Cross-Validation   標本をK子に分割してK-1個を学習データ、1個を評価データとして扱い、K回検定を行い推定の平均を得る     Leave-One-Out Cross-Validation   標本から1つの事例を取り出して評価データとし、残りを学習データとする。全事例が1回は評価となるように検定を繰り返す。    Accuracy   正解率のこと。予測結果全体と、答えがどれぐらい一致しているかを判断する指標。計算式は下記を参照。     Precision   適合率のこと。予測を正と判断した中で、答えも正のもの。計算式は下記を参照。     Recall  再現率のこと。答えが正の中で、予測が正とされたもの。計算式は下記を参照。       F-measure   F値のこと。予測精度の評価指標。PresicionとRecallの調和平均。計算式は下記を参照。     ROC曲線   Receiver Operating Characteristicのこと。縦軸にTrue Positive、横軸にFalse Positiveの割合を2次元プロットして点を線で連結した曲線     AUC   Area Under the Curveのこと。ROC曲線の曲線よりしたの面積。分類器の精度評価に使う。    マイクロ平均   Nセットのテストをする場合、テストを合計してから評価値を計算。計算式は下記を参照。     マクロ平均   Nセットのテストをする場合、各セットを計算してからそれらを平均する計算。計算式は下記を参照。     True Positive   正しくPositiveと判断。予測が正解しているのでOK。     False Positive   誤ってPositiveと判断。予測が不正解なのでNG。     False Negative  誤ってNegativeと判断。予測が不正解なのでNG。     True Negative   正しくNegativeと判断。予測が正解しているのでOK。       -   事実が1   事実が-1     予測が1   True Positive(TP)   False Positive(FP)     予測が-1   False Negative(FN)   True Negative(TN)   AccuracyとPrecisionは相関関係になり、PresicionとRecallは逆相関の関係になるのが一般的です。PresicionとRecallともに予測が正しい事の指標ですが、数式で表すと分母が予測ベースか事実ベースかが異なります。どっちだっけという判断が非常に難しいです。
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201209100835/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201209070848/">joinコマンドが便利過ぎて生きるのが辛い</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Sep 07, 08:48</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [Linux] : joinコマンドが便利過ぎて生きるのが辛い Linuxシステムプログラミング
作者: Robert Love,ロバートラブ,千住治郎出版社/メーカー: オライリージャパン発売日: 2008/04/16メディア: 大型本購入: 5人 クリック: 181回この商品を含むブログ (29件) を見る
結合  Unix/Linuxの標準コマンドで2つのファイルの共通keyで連結することができます。共通keyでの結合にはjoinコマンドを利用します。joinによりSQLのinner joinに近いことがコマンドだけで出来てしまいます。今までテキスト処理をコマンドで行う事が少なかったのでjoinの活用方法を知りませんでしたが、今回調べた内容を記録します。似たコマンドとしてpasteというものもあり、こちらは同じ行数の内容を単純に結合します。そちらについても簡単に紹介します。
  join  join前にsort joinコマンドを利用する場合は2つのファイルがそれぞれ結合するフィールドでsortしておく必要があります。sortしないで実行すると期待通りの結果が得られません。
 joinコマンドオプション    オプション   役割     -1 n   File1のn番目のフィールドを用いてjoinする     -2 n   File2のn番目のフィールドを用いてjoinする     -a File   ファイルにあるペアにならなかった行を通常の出力に追加     -e string   入力にFieldがなかった場合はそれに対応する出力フィールドをstringにする     -i, --inore-case   キーを比較する時に英大文字小文字の違いを無視     -j n   -1 n ,-2 nと同じ     -o Field-list   出力のフォーマットにField-listを用いる       -t char   入力/出力フィールド区切り文字にcharを指定     -v File   ペアにならなかった行だけを出力       先頭カラムでjoin $ cat AA.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201209070848/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201209040835/">Support Vector Machinesを用いた「魔法少女まどか☆マギカ」人物予測モデル</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Sep 04, 08:35</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [自然言語処理] : Support Vector Machinesを用いた「魔法少女まどか☆マギカ」人物予測モデル 言語処理のための機械学習入門 (自然言語処理シリーズ)
作者: 高村大也,奥村学出版社/メーカー: コロナ社発売日: 2010/07メディア: 単行本購入: 13人 クリック: 235回この商品を含むブログ (39件) を見る
人物予測モデル  記事のタイトルがだいぶ固い内容になっていまいましたがやりたい事はとても簡単です。過去に発せられたまど☆マギ台詞の形態素を学習し、予測モデルを作成します。その後に未分類の形態素のデータセットを与えた時にどれだけ人物のラベル付けが正しく行われたかを評価します。予測モデルの対象となる人物は鹿目まどか/暁美ほむら/美樹さやか/キュゥべえ/佐倉杏子/巴マミの合計6名です。機械学習にはSVMを利用します。先に実験の結果をお伝えしておくと、台詞の形態素ベクトルでは十分なマルチラベリングができていません。それでもこの記事が気になる方は読み進めてください。処理手順の詳細は以下の通りです。
 まど☆マギ台詞の収集。 発言者の1行台詞を形態素解析し、形態素IDと形態素出現回数をベクトル化。 TrainデータとPredictデータを分離する。 SVMを利用したTrainデータの学習。Model作成。 Kfold-Cross-Validation実施。Modelの評価。    まど☆マギ台詞の収集  魔法少女まどか☆マギカ　WIKI - ネタバレ考察/台詞集 
上のWIKIの台詞を利用させてもらっています。※承諾は得ていません。
Pythonコードで各登場人物の台詞を取得します。Webページのスクレイピングによる抽出です。実行すると各登場人物ファイルにデータを落とし込みます。
#!/usr/bin/env python # -*- coding: utf-8 -*- import sys,re,urllib,urllib2 urls = { 'http://www22.atwiki.jp/madoka-magica/pages/131.html' : 'madoka.txt', 'http://www22.atwiki.jp/madoka-magica/pages/57.html' : 'homura.txt', 'http://www22.atwiki.jp/madoka-magica/pages/123.html' : 'sayaka.txt', 'http://www22.atwiki.jp/madoka-magica/pages/130.html' : 'mami.txt', 'http://www22.atwiki.jp/madoka-magica/pages/132.html' : 'kyoko.txt', 'http://www22.atwiki.jp/madoka-magica/pages/56.html' : 'kyube.txt' } opener = urllib2.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201209040835/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201208290841/">10秒で設定可能なlibsvmで機械学習を行う</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Aug 29, 08:41</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [機械学習] : 10秒で設定可能なlibsvmで機械学習を行う Support Vector Machines (Information Science and Statistics)
作者: Ingo Steinwart,Andreas Christmann出版社/メーカー: Springer発売日: 2008/08/29メディア: ハードカバー クリック: 17回この商品を含むブログを見る
libsvm   LIBSVM -- A Library for Support Vector Machines  R言語でSVM(Support Vector Machine)による分類学習 - Yuta.Kikuchiの日記  前回RでのSVMを簡単に紹介しましたが、今日はlibsvmを利用したirisの分類学習を行いたいと思います。libsvmは導入がめちゃくちゃ簡単なところが売りだと思います。zipをlibsvmサイトからdownloadして展開してgmakeで設定完了です。
設定 $ wget "http://www.csie.ntu.edu.tw/~cjlin/cgi-bin/libsvm.cgi?+http://www.csie.ntu.edu.tw/~cjlin/libsvm+zip" $ unzip libsvm-3.12.zip $ cd libsvm-3.12 $ gmake $ ls -rw-r--r-- 1 yuta yuta 1497 1月 31 2012 COPYRIGHT -rw-r--r-- 1 yuta yuta 72186 4月 1 07:17 FAQ.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201208290841/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201208270835/">R言語でSVM(Support Vector Machine)による分類学習</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Aug 27, 08:35</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [機械学習] : R言語でSVM(Support Vector Machine)による分類学習 サポートベクターマシン入門
作者: ネロクリスティアニーニ,ジョンショー‐テイラー,Nello Cristianini,John Shawe‐Taylor,大北剛出版社/メーカー: 共立出版発売日: 2005/03メディア: 単行本購入: 8人 クリック: 135回この商品を含むブログ (41件) を見る
SVMとは  Support Vector Machineの略で教師あり学習に分類されます。線形、非線形の識別関数があり現在知られている多くの学習モデルの中では最も優れた識別能力があるとされています。いわゆる2値分類を解くための学習モデルであり、線形しきい素子を用いて分類器を構成します。訓練データにおける各データ点と距離が最大になるマージン最大化という基準で線形しきい素子のパラメータを学習させます。シンプルな例は与えられたデータ集合を全て線形に分離する事です。SVMはカーネルトリックという非線形の分離も可能としており、この部分でも優れた性能を発揮する事が分かっています。この記事ではR言語に備わっているデータを利用してSVMによる分類学習を行います。途中でNeuralNetwork、NaiveBayesとの比較も簡単に行います。
  R言語でSVM  設定 R言語でSVMを利用するにはkernlabというパッケージを必要とします。最初にinstallします。またlibrary関数でkernlabを読み込みます。
$ sudo R  install.packages( "kernlab" )  library( kernlab )  学習データ/予測データを作成 R言語に標準で入ったテストデータにIrisというものがあります。Irisを辞書で調べてみると以下のようにアヤメのことを差しています。「 アヤメ科アヤメ属の単子葉植物の総称。アヤメ・ハナショウブ・カキツバタなど。一般にはジャーマンアイリス・ダッチアイリスなどの園芸種をいう。」(Yahoo!辞書から引用)。Irisデータは4行のデータであり、蕚片の長さ/幅、花びらの長さ/幅で種別を定義しているデータです。ここでは蕚片の長さ/幅と花びらの長さ/幅を説明変数、種別を目的変数と呼ぶ事にします。トレーニングデータの説明変数を学習させ、評価データの説明変数から目的変数がどれに分類されるかを評価します。まずはIrisデータの50%をトレーニングデータ、残りの50%を予測を行うデータに分類します。Irisのデータは150行のデータなのでそれぞれ75行分のデータが格納されます。
#irisのデータの行数を取得  rowdatarandom_idsrandom_ids [1] 148 35 114 6 26 129 58 92 20 138 147 107 110 41 88 11 137 52 142 [20] 17 38 55 139 132 21 8 4 49 125 12 84 77 101 122 40 1 25 37 [39] 87 83 61 111 18 5 7 113 56 93 109 3 74 82 134 118 33 42 130 [58] 76 70 103 136 116 106 65 19 16 30 75 143 54 98 60 121 45 94 #学習データを作成  iris_trainingiris_training Sepal.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201208270835/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201207300844/">R言語を用いた自己回帰モデルによる株価予測を試してみた</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Jul 30, 08:44</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [機械学習] : R言語を用いた自己回帰モデルによる株価予測を試してみた 一番売れてる株の雑誌ZAiが作った「株」入門 改訂版
作者: ダイヤモンド・ザイ編集部出版社/メーカー: ダイヤモンド社発売日: 2009/03/27メディア: 単行本購入: 5人 クリック: 71回この商品を含むブログ (13件) を見る
株価予測  欧州の経済不安により円高/日本株安が深刻になっています。トレーダーとしてはこのBigWaveを見過ごす訳にはいかないですが、「もうはまだなり、まだはもうなり」という言葉があるように投資のタイミングは非常に難しいものです。ここでは投資理論を語るのではなく、機械学習で株価を予測する事を試してみます。今回採用する予測Modelは自己回帰Model(AR)です。ARは時系列データ解析によく用いられます。AR処理はR言語のar関数を用います。
  AR(AutoRegressive)Model  ARModel - 自己回帰モデル ARModelは時系列解析に利用されます。時間と一緒に変動する値に対してARModelを適用し、時系列データに隠れた何かしらの情報を導きだす事を目的としています。AR(p)モデルは次のような式で定義されます。
ここでは時刻tで得られた時系列、はモデルパラメータ、は定数項、は誤差項となります。定数項は単純化式では削除されることが多いようです。数式から分かるようにが過去のデータに依存していおり、これが回帰と呼ばれる原因になっています。
自己回帰移動平均モデル - Wikipedia 
 MAModel - 移動平均モデル MAModelは時系列データの平滑化を行う手法です。誤差による平滑化が行われます。MA(q)は次のような式で定義されます。
ここでは時刻tで得られた時系列、は誤差項、はモデルパラメータとなります。
移動平均 - Wikipedia 
 ARMAModel - 自己回帰移動平均モデル ARMAModelはARModelとMAModelを組み合わせたモデルです。ARMA(p,q)は以下の数式で定義できます。
 その他 ここでは詳しく紹介しませんが、その他ARIMA、ARFIMA、ARCH/GARCHなどの時系列解析Modelが存在します。
ARCHモデル - Wikipedia 
   R言語でのARModel練習  UKgas R言語に標準で入っているイギリスの1960年〜1986年の四半期毎のガス使用量のデータでARModelの予測練習をしてみます。UKgasのデータは次のものです。また時系列データをplotしてみます。
 UKgas Qtr1 Qtr2 Qtr3 Qtr4 1960 160.1 129.7 84.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201207300844/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201207230844/">初めての機械学習理論</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Jul 23, 08:44</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [機械学習] : 初めての機械学習理論 はじめての機械学習
作者: 小高知宏出版社/メーカー: オーム社発売日: 2011/04/22メディア: 単行本（ソフトカバー）購入: 6人 クリック: 99回この商品を含むブログ (9件) を見る
はじめての機械学習  はじめての機械学習という本を読んで学んだことをまとめます。自分で理解した言葉としてまとめています。原文とは異なる可能性があります。またその他自分で勉強した内容についても紹介します。
 機械学習とは パラメータ調整による学習 帰納的学習 教示的学習 進化的手法による規則学習 ニューラルネット 機械学習ライブラリ その他用語    機械学習とは   「生物」以外の「機械」が学習を行う事。 過去のデータやとある局面のデータを学習して新たな局面に当てはまる有効な知識構成を「汎化」と呼ぶ。 機械学習はゲーム研究での適用が始まりで、人口知能と人間の対戦だった。 評価関数の評価値が高くなるようなパラメータ調整が必要。=パラメータ調整による機械学習。 数値だけでなく形などの構造も学習可能で、具体的な事例から一般知識を抽出する学習を「帰納的学習」と呼ぶ。 与えられた原理や法則から具体的な事例を導く学習を「演鐸的学習」と呼ぶ。 生物集団の進化モデルをベースにした学習を「遺伝的アルゴリズム」と呼ぶ。 生物の個体が環境との相互作用によって知識を獲得するモデルを「強化学習」と呼ぶ。 強化学習は環境からの報酬に従い、報酬を最大にする事が目的。 データマイニングやテキストマイニングにも機械学習が用いられる。 生物の神経組織の挙動モデルにより情報処理を行う仕組みを「ニューラルネットワーク」と呼ぶ。 この本での学習の一覧と概略は以下の通り。     学習   概略     パラメータ調整学習   時系列データから知識抽出       帰納的学習   暗記学習中心     教科学習   データ分類規則の学習     遺伝的アルゴリズム   規則的な学習     ニューラルネット   パーセプトロン型のニューラルネットワーク        パラメータ調整による学習   パラメータ調整学習は与えられた学習データを自動的に調整。 学習データの数値を数式に決定することを回帰分析という。例として最小二乗法などがある。 時系列データの周期性や規則性を求めるケースに適用できる。 気温の周期性を求める場合、学習データ(真のデータ)、予測結果、予測の真否を○×で表にまとめる等すると評価が分かる。    帰納的学習   Webサイト上のデータを大量に収集する場面にはテキストマイニングが有効。 テキストマイニングするには自然言語処理を必要とする。自然言語処理の流れは以下の通り。  文抽出 形態素解析 構文解析 意味解析 談話理解  英文は単語がスペースで区切られているので形態素に分解するのは楽。日本語は大変。 構文解析では生成文法に基づき文の構造を記号として置き換える。置き換えた内容を名詞や動詞句として判定する。 意味解析は形態素と構文から判断。 談話理解は上の処理を踏まえて文全体で判定。 n-gramというn個の記号や文字の並びから文の特徴を抽出する。 n-gram全体の個数を表にまとめて上位を見ると特徴が分かる。 n-gramの考え方はテキストの特徴を表す指標のtf-idfにも関連する。 英語の場合n-gramは冠詞(the)や接続詞(and)が多くなる。 tf-idfとはある文章中の出現文字列が文章の特徴をどれだけ表しているかを表現する手法。  tf = term frequency idf = inverse document frequency tfはその文章中の出現回数、idfは一般文章全体の割合。idfの値が大きいと出現頻度が少ない事を示す。     教示学習   教示学習は教師あり学習とも呼ばれる。教師を無しに指示を受けずに学習を進める手法を教師無し学習と呼ぶ。 教師あり学習  効率で精密な学習。 教師が正確な学習を教示。 学習データに現れない状況への対応ができない。 学習を汎化することができない。  教師無し学習  学習の汎化や学習データに依存しない学習が可能。 誤った学習をする可能性がある。   教示学習の適用例としてはカテゴリ分類がある。人間にどのカテゴリに属するかを示してもらい知識を学習する。 分類知識の例としては電子メールのスパム判定がある。 分類知識は分類システムの動作を決定する知識関数。 知識分類は命題のYes or Noの判断木という知識の木構造で表現することができる。 判断木は論理式よりも記述が冗長化することがあり、論理式と比較してデータ構造が大きくなってしまう。 他の知識表現としてプロダクションシステムがあり、AならばBというルールを用いた表現。 分類知識の学習は成功しない場合があることを前提にすべき。 判断木の機械学習アルゴリズム  学習セットが空ならば終了。 学習セットの要素が全て単一カテゴリに属するならば終了。 学習セットをサブセットに分類する処理を再帰的に繰り返す。 属性が無く分類が終わっていなければ手続き終了。  プロダクションシステムではif 条件式 then カテゴリという式を当てはめる。 特定の分類知識を使って学習データをセットを分類した場合、正しく分類された場合と壮麗外の場合を調べる事が可能。得点を与えて評価。 ランダム生成に基づく分類知識獲得アルゴリズム  学習データセットの読み込み 乱数に寄る分類知識生成 分類知識の評価      進化的手法による規則学習   教示的な学習は探索空間が膨大でどのあたりに有用な知識が存在しているかが不明な場合に有効。探索範囲が明確である場合は、系統的な探索を行う方が有利。 人工知能の研究では縦型、横型、最良優先、最適化経路探索、Aアルゴリズム、A*アルゴリズムなどがある。 ランダム探索で一定の方向性を与える方法として焼きなまし法というものがあり、ランダムさを示すパラメータを初期値では高く設定し、そのパラメータを少しずつ修正して徐々に効率の良い探索点を探すこと。探索を1点とするのではなく複数の探索点を同時に調べる粒子群最適化法、蟻の群れの挙動を模擬することで探索を進める蟻コロニー最適化法などがある。 進化的計算のなかでも遺伝的アルゴリズム(Genetic Algorithm, GA)は研究が進んでいて、探索空間の複数の探査点を同時に処理して行く。 遺伝的アルゴリズムにおける評価関数を適応度関数と呼ぶ。選択にはルーレット選択、ランク選択、トーナメント選択など様々な方法がある。 選択された遺伝子は子孫を作る事ができ、複製や一部改変することを交叉(crossover)、突然変異(mutation)がある。 遺伝的アルゴリズムでは最良会を求める代わりにまずまずの結果を与える解を素早く求める事を目的としている。 採用する遺伝的アルゴリズムの一般的な方法としてSimple GA(SGA)というものがある。 SGAの処理手順  遺伝子プールの初期化 交叉 突然変異 結果の出力 繰り返し  エリート保存は世代交代で親世代のエリート遺伝子を子供世代にそのまま残すこと。子世代の結果が親世代と比較して低下しないようにする。    ニューラルネット   生物の神経細胞やネットワーク挙動にヒントを得た機械学習システム。生物の神経網と明確に区別したい場合は人工神経路網、人工ニューラルネット等と呼ぶ事もある。 神経細胞をモデル化したニュールセル(ニューロン、人工ニューロン、ニュール素子)をノートとして用い、複数のニューロセルを結合してネットワークを構成する。 ニューロセルは複数の入力を待ち、それぞれに特定の重み付けをした上で足し合わせをする。足し合わせた結果から閾値を引いて値を求める。数式で書くと次のよう。 xは入力、wは重み、vは閾値。  uの値を適当な関数fに適用してニュール素子の出力zを獲得する。fは出力関数。出力関数はステップ関数やシグモイド関数のようになる。シグモイド関数は以下のように示される。  ニューロセル単体でも情報処理が可能だが、ニュールセルを複数結合してニューラルネットを構成することで更に高度な情報処理機構を実現することが可能。ネットワークの最終的な出力が計算されることをフィードフォワードネットワーク(Feed Foward Network)または階層的なネットワークと呼ぶ。ニューロセルが自分自身にフィードバックして入力の一部になることをリカレントネットワーク(Recurrent Network)と呼ぶ。リカレントネッワークのうち、ニューロセルが互いに双方向に結合しているものをポップフィールドモデル(Hopfield Model)と呼ぶ。 パーセプトロンはフォードフォワード型のネットワークで特定の形式を持ったニューラルネット。パーセプトロンは3層の階層構造をもったニューラルネット。入力層→中間層への加重や閾値は乱数で、中間層→出力層への加重や閾値は学習で決まる。 パーセプトロンでは入力層から中間層の結合荷重を変更しなくても、中間層から出力層への結合荷重を適切に選ぶことで論理積/論理和等の動作を行う事ができる。しかし中間層→出力層の調整では排他的論理和(XOR)に対応する出力はできない。入力層→中間層の荷重値によっては排他的論理和も実現が可能。 学習データセットを与えて出力誤差が小さくなるように結合荷重と閾値を調整する。結合荷重と閾値の学習にはへブの学習則(Hebbian learning rule)を用いる。へブは頻繁に信号を伝達するシナプスの結合がより強化される。正しい結果を与える回路はより結合荷重を大きくして誤った結果を与える回路の結合荷重は小さくする事でネットワークとして学習が可能。 パーセプトロンの学習手続き  適当な終了条件まで以下を繰り返す。 学習データセットの中の一つの例としてについて以下を計算する。 を用いて中間層の出力を計算する。 を用いて出力層oを計算する。 出力層のニューロセルについて以下を計算する。   パーセプトロンの線形分離不可問題を回避して階層型のニューラルネットをより幅広い対象について学習を行うためには出力層に加えて中間層の結合荷重を調整する必要がある。バックプロパゲーション(back propagation、誤差逆伝播) バックプロパゲーションの学習手続き  適当な終了条件まで以下を繰り返す。 学習データセットの中の一つの例としてについて以下を計算する。 を用いて中間層の出力を計算する。 を用いて出力層oを計算する。 出力層のニューロセルについて以下を計算する。  中間層のj番目のニューロセルについて以下を計算する。  中間層j番目のニューロセルのi番目の出力について以下を計算する。      機械学習ライブラリ  有名な機械学習ライブラリを列挙します。
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201207230844/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201207170832/">BehaviorTargeting調査レポート</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Jul 17, 08:32</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [AD] : BehaviorTargeting調査レポート 行動ターゲティング広告 ページビュー神話の終焉
作者: 渡辺健太郎出版社/メーカー: インプレスジャパン発売日: 2007/12/01メディア: 単行本（ソフトカバー）購入: 2人 クリック: 66回この商品を含むブログ (7件) を見る
Index   BehaviorTargetingとは WebにおけるBehaviorTargeting MicroAdによる詳しい説明 海外のResearch Introduction to Computational Advertising Google Twitter FaceBook Yahoo NHN/livedoor Amoad その他ターゲティングに関する情報    BehaviorTargetingとは   BT広告とは【ビヘイビアターゲティング広告】 - 意味/解説/説明/定義 ： IT用語辞典  BehaviorTargetingとはユーザの行動から趣味指向を分析しそれにあったTargetingを行うことです。もう少し詳しく説明するとユーザの過去のWebサイト閲覧や滞在時間、動画/音楽の視聴、検索キーワード入力、広告クリック、GPSなどの現在地情報、ID登録時の年代性別、Web以外でのクレジットカード決済などのデータを基にユーザの顕在/潜在ニーズを推定し、それに見合った商品や広告の提案を行う事です。AmazonのAffinity Item(関連商品)やGoogleAdsenseもBehaviorTargetingによる商品と言えます。今日はBehaviorTargetingについて海外でのResearchや日本国内企業のTargeting手法に着いて調査した内容をまとめたいと思います。
  WebにおけるBehaviorTargeting   インタレスト カテゴリやユーザー属性カテゴリはどのように判別するのですか？ - AdSense ヘルプ  Ads Preferences Manager - Google 一般的にはWebにアクセスするブラウザのCookieと過去の行動から推定された趣味指向/興味カテゴリを紐付ける手法が用いられます。当然の事ながらCookieベースの手法なのでユーザ自身がCookieを削除してしまうと趣味指向/興味カテゴリとの紐付けも解除されます。後でも詳細を説明しますがGoogleAdsenseはユーザ自信が自分が興味を持っているカテゴリを編集することができ、Cookieに対して新たに編集内容を保存をします。ここでユーザに正確な情報を設定してもらえれば推定というよりは確定要素としてTargetingが可能です。
  MicroAdによる詳しい説明  MicroAdの行動ターゲティング特集の説明が素晴らしく詳しいので今回参考にさせていただきました。コンテンツの内容は広告主をメインとしているようです。
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201207170832/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="https://yutakikuchi.github.io/post/201207110838/">JSONを見やすく表示するにはPythonの-mjson.toolを使うと良いよ</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2012 Jul 11, 08:38</time>
  </div>

  

  

  

</div>

  </header>

  <p>
  [javascript] : JSONを見やすく表示するにはPythonの-mjson.toolを使うと良いよ Python クックブック 第2版
作者: Alex Martelli,Anna Martelli Ravenscroft,David Ascher,鴨澤眞夫,當山仁健,吉田聡,吉宗貞紀出版社/メーカー: オライリー・ジャパン発売日: 2007/06/26メディア: 大型本購入: 11人 クリック: 423回この商品を含むブログ (85件) を見る
JSONを見やすく表示する  WebツールやExtension  JSONLint - The JSON Validator.  Online JavaScript beautifier  JSON整形サービス  Chrome ウェブストア - JSONView  {"Compile":["C","C++","Objective-C"],"Script":["JavaScript","PHP","Perl","Python"]}JSONはJavaScriptのObjectを文字列化したもので、1行にまとまってしまうため非常に見づらいです。「JSON 整形」というキーワードでぐぐると上のようにWebサービスからChrome/FirefoxのExtensionなどが出てきます。今回はサーバサイドでJSONをechoする処理を書いていて、ツールを用いる事無く簡単に見やすくする方法を調べていたのですが、Pythonの-mjson.toolを使うとコマンドライン上で整形できることがわかりました。
 Python pretty-print-json  linux - How to pretty-print JSON script? - Stack Overflow  Stack Overflowに How to pretty-print JSON script?というコラムがあり、そこでPythonの-mjson.toolを指定する方法を知りました。例えば以下のようなPerlコードがあって、実行処理に対してパイプ(|)でpython -mjson.toolを指定するだけで整形してくれます。下では生のJSON文字列と整形した内容を比較していますが、見やすさは歴然だと思います。特にHashを表す{}と配列を表す[]がそれぞれ分かりやすいかと。
#!/usr/bin/perl use strict; use warnings; use JSON; my %array = (); push( @{$array{Script}}, ( 'JavaScript', 'PHP', 'Perl', 'Python' ) ); push( @{$array{Compile}}, ( 'C', 'C++', 'Objective-C' ) ); print encode_json( \%array ); $ perl echo_json.
  </p>

  
  <footer>
    <a href="https://yutakikuchi.github.io/post/201207110838/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  

  


<nav class="pagination" role="pagination">
  
  <a href="https://yutakikuchi.github.io/page/10/"><i class="fa fa-chevron-left"></i></a>
  
  <span>&nbsp;11 / 21&nbsp;</span>
  
  <a href="https://yutakikuchi.github.io/page/12/"><i class="fa fa-chevron-right"></i></a>
  
</nav>



</div>

</div>
</div>
<script src="https://yutakikuchi.github.io/js/ui.js"></script>
<script src="https://yutakikuchi.github.io/js/menus.js"></script>


<script>
  
  if (window.location.hostname != "localhost") {
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-20616165-3', 'auto');
    ga('send', 'pageview');
  }
</script>





</body>
</html>

