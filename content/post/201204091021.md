
---
title: "Hadoop HDFS SHELL TIPS"
date: 2012-04-09T10:21:16+00:00
category : [Hadoop]
canonicalurl: http://yut.hatenablog.com/entry/20120409/1333934476
---

## [Hadoop] : Hadoop HDFS SHELL TIPS


<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a> Articles</h4>

<blockquote>
    <p>今まで<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>関連で紹介した記事は以下のものです。それぞれ<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>については紹介したのですが、<a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a>の操作については記述していなかったので今回まとめてみました。</p>

<ul>
<li><a href="http://d.hatena.ne.jp/yutakikuchi/20111205/1323041424">CentOSでHadoopを使ってみる - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20111205/1323041424"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20111205/1323041424" alt="はてなブックマーク - CentOSでHadoopを使ってみる - Yuta.Kikuchiの日記" border="0" /></a></li>
<li><a href="http://d.hatena.ne.jp/yutakikuchi/20111219/1324251034">Hadoopをより便利に使う！HiveでのMapReduceまとめ - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20111219/1324251034"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20111219/1324251034" alt="はてなブックマーク - Hadoopをより便利に使う！HiveでのMapReduceまとめ - Yuta.Kikuchiの日記" border="0" /></a></li>
<li><a href="http://d.hatena.ne.jp/yutakikuchi/20120403/1333409284">「魔法少女まどか☆マギカ」の台詞をJavaScriptでMapReduceしてGoogle Chart APIでグラフ出力したよ！ - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20120403/1333409284"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20120403/1333409284" alt="はてなブックマーク - 「魔法少女まどか☆マギカ」の台詞をJavaScriptでMapReduceしてGoogle Chart APIでグラフ出力したよ！ - Yuta.Kikuchiの日記" border="0" /></a></li>
</ul>
</blockquote>

</div>
<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a> SHELL</h4>

<blockquote>
    <p><a href="http://hadoop.apache.org/common/docs/r0.20.0/hdfs_shell.html">HDFS File System Shell Guide</a> <a href="http://b.hatena.ne.jp/entry/hadoop.apache.org/common/docs/r0.20.0/hdfs_shell.html"><img src="http://b.hatena.ne.jp/entry/image/http://hadoop.apache.org/common/docs/r0.20.0/hdfs_shell.html" alt="はてなブックマーク - HDFS File System Shell Guide" border="0" /></a></p>

<ul>
<li>cat </li>
<li>chgrp</li>
<li>chmod</li>
<li>chown</li>
<li>copyFromLocal</li>
<li>copyToLocal</li>
<li>count</li>
<li>cp</li>
<li>du</li>
<li>dus </li>
<li>expunge</li>
<li>get </li>
<li>getmerge</li>
<li>ls</li>
<li>lsr </li>
<li>mkdir</li>
<li>moveFromLocal</li>
<li>moveToLocal</li>
<li>mv</li>
<li>put </li>
<li>rm</li>
<li>rmr </li>
<li>setrep</li>
<li>stat</li>
<li>tail</li>
<li>test</li>
<li>text</li>
<li>touchz</li>
</ul>
</blockquote>

</div>
<div class="section">
<h4>OverViews</h4>

<blockquote>
    
<blockquote>
    <p>The FileSystem (FS) shell is invoked by bin/<a class="keyword" href="http://d.hatena.ne.jp/keyword/hadoop">hadoop</a> fs <args>. All FS shell commands take path URIs as arguments. The URI format is scheme://autority/path. For HDFS the scheme is hdfs, and for the local filesystem the scheme is file. The scheme and authority are optional. If not specified, the default scheme specified in the configuration is used. An HDFS file or directory such as /parent/child can be specified as hdfs://namenodehost/parent/child or simply as /parent/child (given that your configuration is set to point to hdfs://namenodehost). Most of the commands in FS shell behave like corresponding Unix commands. Differences are described with each of the commands. Error information is sent to stderr and the output is sent to stdout</p>

</blockquote>

<ul>
<li>FileSystemは bin/hadoop fs <コマンド引数>によって起動されます。全てのFS ShellコマンドはURIsを引数として用います。URIのフォーマットはscheme://autority/pathです。HDFSにとってschemeはhdfsであり、全てのlocal filesystemにとってschemaはファイルです。schemeとauthorityはオプションであり、指定されなくても設定上のdefaultのschemeが設定されます。HDFSのファイルやディレクトリで例えば/parent/childのようなものはhdfs://namenodehost/parent/childやシンプルに/parent/child(hdfs://namenodehostを設定で与えている事)として指定する事が可能です。ほとんどのFS ShellコマンドはUnixCommandsと似合った形で動作します。差異はそれぞれのコマンドの箇所に記述します。Error情報は標準エラーと標準出力の両方に送られます。</li>
<li>HDFS SHELLの多くのコマンドに共通して言える事は成功時に0を返し、errorでは-1を返します。</li>
</ul>
</blockquote>

</div>
<div class="section">
<h4>HDFS SHELL Commands</h4>

<blockquote>
    
<ul>
<li>基本的にはHDFS上のファイルおよびローカルのファイルに対する操作コマンドです。参照系/更新系のコマンドがあります。</li>
<li>hadoop fs と毎回コマンドとして打つのが面倒なので<span class="deco" style="color:#FF0000;">alias hdfs='hadoop fs'</span>などとするとキータイプが短くて済みます。</li>
<li>似た動作をするコマンドが複数あるのでどれか一つを覚えると良いと思います。例えば<span class="deco" style="color:#FF0000;">copyFromLocalはputとほぼ同義です。</span></li>
<li>下で実際に実行したデータについては <a href="http://d.hatena.ne.jp/yutakikuchi/20120403/1333409284">「魔法少女まどか☆マギカ」の台詞をJavaScriptでMapReduceしてGoogle Chart APIでグラフ出力したよ！ - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20120403/1333409284"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20120403/1333409284" alt="はてなブックマーク - 「魔法少女まどか☆マギカ」の台詞をJavaScriptでMapReduceしてGoogle Chart APIでグラフ出力したよ！ - Yuta.Kikuchiの日記" border="0" /></a> ここで用いた内容です。</li>
</ul>
<div class="section">
<h5>enviroment</h5>

<blockquote>
    <pre class="code" data-lang="" data-unlink>$ hadoop version 
Hadoop 0.20.2-cdh3u3
Compiled by root on Tue Mar 20 13:45:46 PDT 2012</pre>
</blockquote>

</div>
<div class="section">
<h5>hadoop fs</h5>

<blockquote>
    <p>Usage一覧が表示されます。</p>
<pre class="code" data-lang="" data-unlink>$ hadoop fs
Usage: java FsShell
       [-ls <path>]
       [-lsr <path>]
       [-df [<path>]]
       [-du <path>]
       [-dus <path>]
       [-count[-q] <path>]
       [-mv <src> <dst>]
       [-cp <src> <dst>]
       [-rm [-skipTrash] <path>]
       [-rmr [-skipTrash] <path>]
       [-expunge]
       [-put <localsrc> ... <dst>]
       [-copyFromLocal <localsrc> ... <dst>]
       [-moveFromLocal <localsrc> ... <dst>]
       [-get [-ignoreCrc] [-crc] <src> <localdst>]
       [-getmerge <src> <localdst> [addnl]]
       [-cat <src>]
       [-text <src>]
       [-copyToLocal [-ignoreCrc] [-crc] <src> <localdst>]
       [-moveToLocal [-crc] <src> <localdst>]
       [-mkdir <path>]
       [-setrep [-R] [-w] <rep> <path/file>]
       [-touchz <path>]
       [-test -[ezd] <path>]
       [-stat [format] <path>]
       [-tail [-f] <file>]
       [-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
       [-chown [-R] [OWNER][:[GROUP]] PATH...]
       [-chgrp [-R] GROUP PATH...]
       [-help [cmd]]

Generic options supported are
-conf <configuration file>     specify an application configuration file
-D <property=value>            use value for given property
-fs <local|namenode:port>      specify a namenode
-jt <local|jobtracker:port>    specify a job tracker
-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster
-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.
-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.

The general command line syntax is
bin/hadoop command [genericOptions] [commandOptions]</pre>
</blockquote>

</div>
<div class="section">
<h5>cat</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -cat URI [URI …]</li>
<li>標準出力へのコピーです。</li>
</ul>
<pre>$ hdfs -cat hdfs://localhost/user/yuta/madmagi_in/ma.txt
 ん っ ん … あっ … ！ あっ … ！ ひどい … 仕方 ない よ 。 彼女 一 人 で は 荷 が 重 すぎ た でも 、 彼女 も 覚悟 の 上 だろ 
</pre>
</blockquote>

</div>
<div class="section">
<h5>chgrp</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -chgrp [-R] GROUP URI [URI …]</li>
<li>fileに対してgroupの割り当てを変更します。-Rを指定すると再帰的にgroupを変更します。実行ユーザはfileのownerやsuper-userを指定しなければなりません。その他の情報は<a href="http://hadoop.apache.org/common/docs/r0.20.0/hdfs_permissions_guide.html">http://hadoop.apache.org/common/docs/r0.20.0/hdfs_permissions_guide.html</a>に記載しています。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -chgrp yuta hdfs://localhost/user/yuta/localfiles/empty.txt
$ hdfs -lsr hdfs://localhost/user/yuta/localfiles                   
-rw-r--r--   1 yuta yuta                0 2012-04-08 10:33 /user/yuta/localfiles/empty.txt
-rw-r--r--   1 yuta supergroup          0 2012-04-08 10:32 /user/yuta/localfiles/test.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>chmod</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -chmod [-R] <MODE[,MODE]... | OCTALMODE> URI [URI …]</li>
<li>permissionを変更します。-Rを指定すると再帰的に変更をします。実行ユーザはfileのownerかsuper-userが指定しなければなりません。その他の情報は<a href="http://hadoop.apache.org/common/docs/r0.20.0/hdfs_permissions_guide.html">http://hadoop.apache.org/common/docs/r0.20.0/hdfs_permissions_guide.html</a>に記載しています。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -chmod 777 hdfs://localhost/user/yuta/localfiles/empty.txt
$ hdfs -lsr hdfs://localhost/user/yuta/localfiles                
-rw-rw-rw-   1 yuta yuta                0 2012-04-08 10:33 /user/yuta/localfiles/empty.txt
-rw-r--r--   1 yuta supergroup          0 2012-04-08 10:32 /user/yuta/localfiles/test.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>chown</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -chown [-R] [OWNER][:[GROUP]] URI [URI ]</li>
<li>ファイルのownerを変更します。-Rを指定すると再帰的に変更をします。実行ユーザはfileのownerかsuper-userが指定しなければなりません。その他の情報は<a href="http://hadoop.apache.org/common/docs/r0.20.0/hdfs_permissions_guide.html">http://hadoop.apache.org/common/docs/r0.20.0/hdfs_permissions_guide.html</a>に記載しています。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -chown -R superuser hdfs://localhost/user/yuta/localfiles/</pre>
</blockquote>

</div>
<div class="section">
<h5>copyFromLocal</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -copyFromLocal <localsrc> URI</li>
<li>putコマンドと良く似ていてHDFS上にファイルを配置します。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -copyFromLocal localfiles hdfs://localhost/user/yuta/
$ hdfs -lsr hdfs://localhost/user/yuta/                     
drwxr-xr-x   - yuta supergroup          0 2012-04-08 10:47 /user/yuta/localfiles
-rw-r--r--   1 yuta supergroup          0 2012-04-08 10:47 /user/yuta/localfiles/test.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>copyToLocal</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -copyToLocal [-ignorecrc] [-crc] URI <localdst></li>
<li>getコマンドと良く似ていてHDSF上からファイルをコピーします。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -copyToLocal hdfs://localhost/user/yuta/remotefiles remotefiles
$ ls remotefiles 
合計 20
drwxr-xr-x 2 yuta yuta 4096  4月  8 10:49 .
drwxrwxrwx 8 yuta yuta 4096  4月  8 10:49 ..
-rw-r--r-- 1 yuta yuta    0  4月  8 10:49 test.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>count</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -count [-q] <paths></li>
<li>指定パス上でパターンにマッチしたディレクトリやファイル,byte数等をカウントします。出力カラムはDIR_COUNT, FILE_COUNT, CONTENT_SIZE FILE_NAMEです。-qを付けると出力カラムが以下のようになります。QUOTA, REMAINING_QUATA, SPACE_QUOTA, REMAINING_SPACE_QUOTA, DIR_COUNT, FILE_COUNT, CONTENT_SIZE, FILE_NAME</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -count hdfs://localhost/user/yuta/madmagi_in/      
       1            2             205706 hdfs://localhost/user/yuta/madmagi_in</pre>
</blockquote>

</div>
<div class="section">
<h5>cp</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -cp URI [URI …] <dest></li>
<li>元ファイルから対象ファイルにコピーします。コピー先にディレクトリを指定すれば複数の元ファイルを指定できます。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -cp hdfs://localhost/user/yuta/madmagi_in/ma.txt hdfs://localhost/user/yuta/madmagi_in/ma2.txt
$ hdfs -ls hdfs://localhost/user/yuta/madmagi_in/       
Found 3 items
-rw-r--r--   1 yuta supergroup     104440 2012-03-26 01:16 /user/yuta/madmagi_in/ma.txt
-rw-r--r--   1 yuta supergroup     104440 2012-04-08 09:51 /user/yuta/madmagi_in/ma2.txt
-rw-r--r--   1 yuta supergroup     101266 2012-03-26 01:16 /user/yuta/madmagi_in/word.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>du</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -du URI [URI …]</li>
<li>ディレクトリに含まれるファイルのサイズを表示します。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -du 
Found 3 items
205706      hdfs://localhost/user/yuta/madmagi_in
89841       hdfs://localhost/user/yuta/madmagi_out_ma
124927      hdfs://localhost/user/yuta/madmagi_out_word</pre>
</blockquote>

</div>
<div class="section">
<h5>dus</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -dus <args></li>
<li>fileサイズのサマリーを表示します。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -dus
hdfs://localhost/user/yuta	420474</pre>
</blockquote>

</div>
<div class="section">
<h5>expunge</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -expunge</li>
<li>空を消します。その他の情報は<a href="http://hadoop.apache.org/common/docs/r0.20.0/hdfs_design.html">http://hadoop.apache.org/common/docs/r0.20.0/hdfs_design.html</a> に記載されています。</li>
<li><span class="deco" style="color:#FF0000;">このコマンドは実行結果が確認できていません。</span></li>
</ul><pre class="code" data-lang="" data-unlink>$hdfs -expunge</pre>
</blockquote>

</div>
<div class="section">
<h5>get</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -get [-ignorecrc] [-crc] <src> <localdst> </li>
<li>localにファイルをコピーします。-iginorecrcでCRCchecksum確認を無視してコピーします。CRCを利用したい場合は-crcと指定します。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -get hdfs://localhost/user/yuta/madmagi_in copylocal
$ ls -1 copylocal                                       
合計 236
drwxr-xr-x 2 yuta yuta   4096  4月  8 09:03 .
drwxrwxrwx 6 yuta yuta   4096  4月  8 09:03 ..
-rw-r--r-- 1 yuta yuta 104440  4月  8 09:03 ma.txt
-rw-r--r-- 1 yuta yuta 101266  4月  8 09:03 word.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>getmerge</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -getmerge <src> <localdst> [addnl]</li>
<li>ファイルをmergeして出力します。addnlを指定するとそれぞれのファイルの末尾に新しい行ラインを追加する事ができます。</li>
<li><span class="deco" style="color:#FF0000;">下の実行結果がうまく確認できていません。</span></li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -getmerge hdfs://localhost/user/yuta/madmagi_in/word.txt copylocal/test.txt addnl</pre>
</blockquote>

</div>
<div class="section">
<h5>ls</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -ls <args></li>
<li>以下のフォーマットに従ったファイルに関する出力を行います。permissions number_of_replicas userid groupid filesize modification_date modification_time filename。ディレクトリの場合は以下のフォーマットに従いリストで返します。permissions userid groupid modification_date modification_time dirname。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -ls hdfs://localhost/user/yuta/madmagi_in/                               
Found 2 items
-rw-r--r--   1 yuta supergroup     104440 2012-03-26 01:16 /user/yuta/madmagi_in/ma.txt
-rw-r--r--   1 yuta supergroup     101266 2012-03-26 01:16 /user/yuta/madmagi_in/word.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>lsr</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -lsr <args></li>
<li>lsの再帰的版です。unixのls -Rと似ています。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -lsr hdfs://localhost/user/yuta/            
drwxr-xr-x   - yuta supergroup          0 2012-03-26 01:17 /user/yuta/madmagi_in
-rw-r--r--   1 yuta supergroup     104440 2012-03-26 01:16 /user/yuta/madmagi_in/ma.txt
-rw-r--r--   1 yuta supergroup     101266 2012-03-26 01:16 /user/yuta/madmagi_in/word.txt
drwxr-xr-x   - yuta supergroup          0 2012-03-26 02:11 /user/yuta/madmagi_out_ma
-rw-r--r--   1 yuta supergroup          0 2012-03-26 02:11 /user/yuta/madmagi_out_ma/_SUCCESS
drwxr-xr-x   - yuta supergroup          0 2012-03-26 02:10 /user/yuta/madmagi_out_ma/_logs
drwxr-xr-x   - yuta supergroup          0 2012-03-26 02:10 /user/yuta/madmagi_out_ma/_logs/history
-rw-r--r--   1 yuta supergroup      50482 2012-03-26 02:10 /user/yuta/madmagi_out_ma/_logs/history/localhost_1332691893518_job_201203260111_0018_conf.xml
-rw-r--r--   1 yuta supergroup      15065 2012-03-26 02:10 /user/yuta/madmagi_out_ma/_logs/history/localhost_1332691893518_job_201203260111_0018_yuta_streamjob2162462095464428994.jar</pre>
</blockquote>

</div>
<div class="section">
<h5>mkdir</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -mkdir <paths></li>
<li>URIのパスに対してディレクトリを作成します。これはunixのmkdir -pの動作に似ています。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -mkdir parent/child
$ hdfs -lsr 
drwxr-xr-x   - yuta supergroup          0 2012-04-08 09:28 /user/yuta/parent
drwxr-xr-x   - yuta supergroup          0 2012-04-08 09:28 /user/yuta/parent/child</pre>
</blockquote>

</div>
<div class="section">
<h5>moveFromLocal</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -moveFromLocal <localsrc> <dst></li>
<li>putコマンドと良く似ていてローカルファイルをHDFS上に移動させます。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -moveFromLocal localfiles hdfs://localhost/user/yuta/
$ hdfs -lsr                                                 
drwxr-xr-x   - yuta supergroup          0 2012-04-08 10:54 /user/yuta/localfiles
-rw-r--r--   1 yuta supergroup          0 2012-04-08 10:54 /user/yuta/localfiles/test.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>moveToLocal</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -moveToLocal [-crc] <src> <dst></li>
<li>また実装が済んでいないというメッセージが表示されます。</li>
<li><span class="deco" style="color:#FF0000;">このコマンドは実行結果が確認できていません。</span></li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -moveToLocal hdfs://localhost/user/yuta/localfiles localfiles
Option '-moveToLocal' is not implemented yet.</pre>
</blockquote>

</div>
<div class="section">
<h5>mv</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -mv URI [URI …] <dest></li>
<li>fileを目的の箇所に移動させます。ディレクトリに対して複数のファイルを指定する事が可能です。filesystemをまたぐような移動は許可されていません。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -mv hdfs://localhost/user/yuta/madmagi_in/ma2.txt hdfs://localhost/user/yuta/madmagi_in/ma_test.txt
$ hdfs -ls hdfs://localhost/user/yuta/madmagi_in/ 
Found 3 items
-rw-r--r--   1 yuta supergroup     104440 2012-03-26 01:16 /user/yuta/madmagi_in/ma.txt
-rw-r--r--   1 yuta supergroup     104440 2012-04-08 09:51 /user/yuta/madmagi_in/ma_test.txt
-rw-r--r--   1 yuta supergroup     101266 2012-03-26 01:16 /user/yuta/madmagi_in/word.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>put</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -put <localsrc> ... <dst></li>
<li>単体や複数のファイルをHDFS上にコピーします。また標準入力からinputしてHDFS上のファイルに書き込む事が出来ます。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -put localfiles hdfs://localhost/user/yuta/
$ hdfs -lsr hdfs://localhost/user/yuta/localfiles
-rw-r--r--   1 yuta supergroup          0 2012-04-08 10:32 /user/yuta/localfiles/test.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>rm</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -rm URI [URI …]</li>
<li>引数に与えられたファイルを削除します。空じゃないディレクトリやファイルを削除するだけです。再帰的な削除を行うにはrmrを使います。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -rm hdfs://localhost/user/yuta/madmagi_in/0byte.txt 
Deleted hdfs://localhost/user/yuta/madmagi_in/0byte.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>rmr</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -rmr URI [URI …]</li>
<li>再帰的に削除します。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -rmr hdfs://localhost/user/yuta/parent      
Deleted hdfs://localhost/user/yuta/parent</pre>
</blockquote>

</div>
<div class="section">
<h5>setrep</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -setrep [-R] <path></li>
<li>ファイルのレプリケーション要素を変更します。-Rを付ける事で再帰的に変更が出来ます。</li>
<li><span class="deco" style="color:#FF0000;">このコマンドは実行結果が確認できていません。</span></li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -setrep -w 3 -R  hdfs://localhost/user/yuta/parent/child</pre>
</blockquote>

</div>
<div class="section">
<h5>stat</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -stat URI [URI …]</li>
<li>パスのstatus情報を表示します。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -stat hdfs://localhost/user/yuta/madmagi_in/
2012-04-08 00:54:03</pre>
</blockquote>

</div>
<div class="section">
<h5>tail</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -tail [-f] URI</li>
<li>標準出力の最後のkilobyteを表示します。unixコマンドと同じように-fオプションを使う事ができます。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -tail  hdfs://localhost/user/yuta/madmagi_in/ma.txt 
し ふうん ―― やっぱり 理解 でき ない なあ 、 人間 の 価値 観 は 今夜 は つくづく 瘴気 が 濃い ね 魔 獣 ども も 、 次 から 次 へ と 湧い て くる ―― 幾ら 倒し て も キリ が ない ボヤい た って 仕方 ない わ 。 さあ 、 行く わ よ がんばっ て </pre>
</blockquote>

</div>
<div class="section">
<h5>test</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -test -[ezd] URI</li>
<li>-e:ファイルが存在するかチェック、-z:ファイルが0バイトかチェック、-d:パスがディレクトリかチェック</li>
<li><span class="deco" style="color:#FF0000;">このコマンドは実行結果が確認できていません。</span></li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -test -z  hdfs://localhost/user/yuta/madmagi_in/ma.txt</pre>
</blockquote>

</div>
<div class="section">
<h5>text</h5>

<blockquote>
    
<ul>
<li>使い方:hadoop fs -text <src> </li>
<li>textモードにして出力します。zipやTextRecordInputStreamの形式を許可しています。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -text hdfs://localhost/user/yuta/madmagi_in/ma.txt    
12/04/08 10:19:25 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
12/04/08 10:19:25 WARN snappy.LoadSnappy: Snappy native library not loaded
 ん っ ん … あっ … ！ あっ … ！ ひどい … 仕方 ない よ 。 彼女 一 人 で は 荷 が 重 すぎ た でも 、 彼女 も 覚悟 の 上 だろ</pre>
</blockquote>

</div>
<div class="section">
<h5>touchz</h5>

<blockquote>
    
<ul>
<li>使い方: hadoop fs -touchz URI [URI …] </li>
<li>0バイトのファイルを作成します。</li>
</ul><pre class="code" data-lang="" data-unlink>$ hdfs -touchz hdfs://localhost/user/yuta/madmagi_in/0byte.txt 
$ hdfs -ls hdfs://localhost/user/yuta/madmagi_in/       
Found 4 items
-rw-r--r--   1 yuta supergroup          0 2012-04-08 10:16 /user/yuta/madmagi_in/0byte.txt
-rw-r--r--   1 yuta supergroup     104440 2012-03-26 01:16 /user/yuta/madmagi_in/ma.txt
-rw-r--r--   1 yuta supergroup     104440 2012-04-08 09:51 /user/yuta/madmagi_in/ma_test.txt
-rw-r--r--   1 yuta supergroup     101266 2012-03-26 01:16 /user/yuta/madmagi_in/word.txt</pre>
</blockquote>

</div>
</blockquote>

</div>

