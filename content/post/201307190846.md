
---
title: "アダルトフィルタ実装に向けたA○女優リストの自動抽出 + α"
date: 2013-07-19T08:46:28+00:00
category : [programming]
canonicalurl: http://yut.hatenablog.com/entry/20130719/1374191188
---

## [programming] : アダルトフィルタ実装に向けたA○女優リストの自動抽出 + α


<div class="section">
<h4>アダルトフィルタ実装に向けて</h4>

<blockquote>
    <p>エロデータサイエンティストの<a href='https://twitter.com/yutakikuc'>@yutakikuc</a>です。<br />
今日はSystemで使うアダルトフィルタの辞書データ作成を目的としていた事が、予想外な方向に突き進んでしまった事をお話します。</p><br />
<p>アダルトフィルタの良くある活用例としてはユーザーが投稿する内容に卑猥単語が含まれている場合は登録を弾くことです。アダルトフィルタの辞書データを作成/運用することは実は結構大変だったりします。なぜならば人目で1語ずつ卑猥か否かを判断したり、自分で判断できない際どい単語は<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google%C0%E8%C0%B8">Google先生</a>に聞きながらだったり..当然新語が増えればアダルトフィルタ辞書の運用コストも膨れるからです。</p><br />
<p>そこで作成/運用のコストを大幅に下げるために辞書の更新を自動化したいと考えます。例えば新しいA○女優がデビューした場合、名前をアダルトフィルタの辞書に自動登録するようなものです。今日はそれを<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>で実装し、最終的にはLTSV形式のデータで出力します。</p><br />
<p><a href="http://ltsv.org/">Labeled Tab-separated Values (LTSV)</a> <a href="http://b.hatena.ne.jp/entry/ltsv.org/"><img src="http://b.hatena.ne.jp/entry/image/http://ltsv.org/" alt="はてなブックマーク - Labeled Tab-separated Values (LTSV)" border="0" /></a></p>

</blockquote>

</div>
<div class="section">
<h4>サンプルコード</h4>

<blockquote>
    <p><a href="http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7">A○女優一覧 - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7" alt="はてなブックマーク - A○女優一覧 - Wikipedia" border="0" /></a><br />
データソースは<a class="keyword" href="http://d.hatena.ne.jp/keyword/Wikipedia">Wikipedia</a>に乗っている日本のA○女優一覧になります。上のURL以下を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EC%A5%A4%A5%D4%A5%F3%A5%B0">スクレイピング</a>する事で名前のリストを抽出します。今回のアダルトフィルタに必要となるデータ項目は名前ですが、折角なのでVital Statistics(Three Size)、Bra Sizeも<span class="deco" style="font-weight:bold;font-style:italic;">ついでのついでのついでに</span>取得します。保存するLTSVのフォーマットは以下のように定義します。</p>
<pre class="code" data-lang="" data-unlink>Name:<Value> <Tab> Bust:<Value> <Tab> Waist:<Value> <Tab> Hip:<Value> <Tab> Bra:<Value></pre><p><br />
以下が<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EC%A5%A4%A5%D4%A5%F3%A5%B0">スクレイピング</a>を行う<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>コードです。更新データが直ぐに欲しい場合はCron等で定期的に実行してください。※時間が無くて10分ぐらいで書いたコードなので汚いです。</p>
<pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synComment"># アダルトフィルタのデータ抽出</span>

<span class="synPreProc">import</span> sys,re,urllib,urllib2
f = <span class="synIdentifier">open</span>( <span class="synConstant">'av.txt'</span>, <span class="synConstant">'w'</span> )
opener = urllib2.build_opener()
ua = <span class="synConstant">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/    534.51.22'</span>
referer = <span class="synConstant">'http://www.yahoo.co.jp/'</span>
opener.addheaders = [( <span class="synConstant">'User-Agent'</span>, ua ),( <span class="synConstant">'Referer'</span>, referer )]
urls = []
baseurls = [ <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%81%82%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%81%8B%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%81%95%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%81%9F%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%81%AA%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%81%AF%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%81%BE%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%82%84%E8%A1%8C"</span>,
        <span class="synConstant">"http://ja.wikipedia.org/wiki/AV%E5%A5%B3%E5%84%AA%E4%B8%80%E8%A6%A7_%E3%82%89%E3%83%BB%E3%82%8F%E8%A1%8C"</span> ]
<span class="synStatement">for</span> burl <span class="synStatement">in</span> baseurls:
   <span class="synStatement">try</span>:
  content = opener.<span class="synIdentifier">open</span>( burl ).read()
  <span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<li><a href="(/wiki/.*?)">.*?</li>'</span>, re.M ).search( content ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
     tmp_urls = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<li><a href="(/wiki/.*?)".*?</li>'</span>, re.M ).findall( content )
     urls = urls + tmp_urls
   <span class="synStatement">except</span> <span class="synType">Exception</span>, e:
  <span class="synIdentifier">print</span> e
  <span class="synStatement">continue</span>

<span class="synComment">#dedupe</span>
urls = <span class="synIdentifier">sorted</span>(<span class="synIdentifier">set</span>(urls), key=urls.index)

<span class="synStatement">for</span> url <span class="synStatement">in</span> urls:
   url = <span class="synConstant">"http://ja.wikipedia.org"</span> + url
   nodes = []
   vs = []
   p = re.<span class="synIdentifier">compile</span>(<span class="synConstant">r'<.*?>'</span>)
   <span class="synStatement">try</span>: 
  content = opener.<span class="synIdentifier">open</span>( url ).read()
  <span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<caption.*?>(.|\n)*?<big><b>(.*?)</b></big></caption>'</span>, re.M ).search( content ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
     tmp = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<caption.*?>(.|\n)*?<big><b>(.*?)</b></big></caption>'</span>, re.M ).search( content ).group(<span class="synConstant">2</span>)
     nodes.append( <span class="synConstant">"Name:"</span> + tmp.replace( <span class="synConstant">' '</span>, <span class="synConstant">''</span> ) )
  <span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<th valign="top" style="font-weight:normal" nowrap="nowrap">.*?スリーサイズ.*?</th>'</span>, re.M ).search( content ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
     tmp  = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<th valign="top" style="font-weight:normal" nowrap="nowrap">.*?スリーサイズ.*?</th>(.|\n)*?<td nowrap="nowrap">(.*?)</td>'</span>, re.M ).search( content ).group(<span class="synConstant">2</span>)
     tmp = tmp.replace( <span class="synConstant">' '</span>, <span class="synConstant">''</span> )
     tmp = tmp.replace( <span class="synConstant">'cm'</span>, <span class="synConstant">''</span> )
     vs = tmp.split( <span class="synConstant">'-'</span> )
     nodes.append( <span class="synConstant">"Bust:"</span> + p.sub( <span class="synConstant">''</span>, vs[<span class="synConstant">0</span>] ) )
     nodes.append( <span class="synConstant">"Waist:"</span> + p.sub( <span class="synConstant">''</span>, vs[<span class="synConstant">1</span>] ) )
     nodes.append( <span class="synConstant">"Hip:"</span> + p.sub( <span class="synConstant">''</span>, vs[<span class="synConstant">2</span>] ) )
  <span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<th valign="top" style="font-weight:normal">.*?ブラのサイズ.*?</th>'</span>, re.M ).search( content ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
     tmp  = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<th valign="top" style="font-weight:normal">.*?ブラのサイズ.*?</th>(.|\n)*?<td>(.*?)</td>'</span>, re.M ).search( content ).group(<span class="synConstant">2</span>)
     nodes.append( <span class="synConstant">"Bra:"</span> + p.sub( <span class="synConstant">''</span>, tmp ) )
  <span class="synStatement">if</span> <span class="synIdentifier">len</span>(nodes) == <span class="synConstant">0</span>:
     <span class="synStatement">continue</span>
  res = <span class="synConstant">"</span><span class="synSpecial">\t</span><span class="synConstant">"</span>.join( nodes ) + <span class="synConstant">"</span><span class="synSpecial">\n</span><span class="synConstant">"</span>
  f.write( res )
   <span class="synStatement">except</span> <span class="synType">Exception</span>, e:
  <span class="synIdentifier">print</span> e
  <span class="synStatement">continue</span>
f.close()
</pre>
</blockquote>

</div>
<div class="section">
<h4>抽出データ</h4>

<blockquote>
    <p>上の<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>コードを実行すると以下のようなエロTSVデータ、もといLTSVデータを抽出する事ができます。抽出して気づいたのですが、元データが統一フォーマットで書かれていないので、後で抽出コードを書き換えて奇麗なデータを生成するようにします。やってはいけない事だと思いますが、<a class="keyword" href="http://d.hatena.ne.jp/keyword/github">github</a>にも抽出したデータを上げておきます。※データの利用は全て自己責任でお願いします。<br />
それにしても皆さん凄いサイズですね...。どこが？って..、いや、アレがですよ、アレが。</p>
<pre class="code" data-lang="" data-unlink>Name:瑠川リナ	Bust:81	Waist:57	Hip:83	Bra:D65
Name:☆LUNA☆	Bust:83	Waist:57	Hip:82	Bra:D-65
Name:RUMIKA	Bust:82	Waist:60	Hip:85	Bra:C
Name:麗花	Bust:88	Waist:58	Hip:87	Bra:E
Name:Reo.	Bust:92	Waist:60	Hip:87	Bra:G
Name:麗奈	Bust:88	Waist:60	Hip:85	Bra:D
Name:れのん	Bust:85	Waist:56	Hip:82	Bra:E
Name:若瀬千夏	Bust:87	Waist:53	Hip:80
Name:若瀬七海	Bust:85	Waist:58	Hip:85	Bra:D-70
Name:若槻朱音	Bust:83	Waist:58	Hip:83	Bra:C-70
Name:若月樹里	Bust:86	Waist:58	Hip:83	Bra:E
Name:若槻尚美	Bust:88	Waist:60	Hip:86	Bra:F-65
Name:若菜	Bust:89	Waist:60	Hip:88	Bra:D-75
Name:若菜亜衣	Bust:85	Waist:57	Hip:86
Name:若菜すず	Bust:83	Waist:58	Hip:90	Bra:B-65
Name:若菜瀬奈	Bust:84	Waist:58	Hip:83
Name:若葉かおり	Bust:86	Waist:53	Hip:80	Bra:E
Name:若林樹里	Bust:83	Waist:58	Hip:83	Bra:D
Name:若林美保	Bust:90	Waist:58	Hip:88	Bra:F
Name:若宮莉那	Bust:92	Waist:59	Hip:86	Bra:I
Name:和久井由菜	Bust:84	Waist:56	Hip:85	Bra:C
Name:わさび	Bust:83	Waist:58	Hip:83	Bra:C
Name:渡瀬晶	Bust:88	Waist:60	Hip:86	Bra:D70
Name:渡瀬安奈	Bust:70	Waist:56	Hip:73	Bra:B-65
Name:渡瀬澪	Bust:100	Waist:60	Hip:87	Bra:G
Name:渡瀬ミク	Bust:80	Waist:55	Hip:80
Name:渡瀬りえ	Bust:87	Waist:63	Hip:86	Bra:D-75
Name:渡辺なつき	Bust:86	Waist:56	Hip:84	Bra:E
Name:渡辺美名子	Bust:80	Waist:60	Hip:85	Bra:C
Name:渡辺弓絵	Bust:90	Waist:62	Hip:92	Bra:Fカップ</pre><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/github">github</a>のURLは以下です。<br />
<a href="https://github.com/yutakikuchi/Data/blob/master/ero.tsv">Data/ero.tsv at master · yutakikuchi/Data</a> <a href="http://b.hatena.ne.jp/entry/s/github.com/yutakikuchi/Data/blob/master/ero.tsv"><img src="http://b.hatena.ne.jp/entry/image/https://github.com/yutakikuchi/Data/blob/master/ero.tsv" alt="はてなブックマーク - Data/ero.tsv at master · yutakikuchi/Data" border="0" /></a></p>

</blockquote>

</div>
<div class="section">
<h4>優秀なデータサイエンティストの皆さんへ</h4>

<blockquote>
    <p>最初はアダルトフィルタ実装に向けたデータ準備を目的としていたのですが、途中から話が可笑しくなって何かの傾向分析ができそうなデータ抽出に成功しました。このデータから何か面白い方向性の研究に話を膨らませてくれる事を多いに期待します。</p>

</blockquote>

</div>

