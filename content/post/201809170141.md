
---
title: "DeepLearningによる画像解析"
date: 2018-09-17T01:41:15+00:00
category : [etc]
canonicalurl: http://yut.hatenablog.com/entry/2018/09/17/014115
---

## [etc] : DeepLearningによる画像解析

<blockquote><h3>概要</h3>

<p><a href="http://www.image-net.org/challenges/LSVRC/">http://www.image-net.org/challenges/LSVRC/</a>
<a href="http://www.image-net.org/challenges/LSVRC/2012/">http://www.image-net.org/challenges/LSVRC/2012/</a></p>

<p>ILSVRC(ImageNet Large Scale Visual Recognition Challenge)はImageNetが毎年主催するコンピュータを利用した画像解析による物体認識・検出のコンペ。2012年にDeepLearningの手法が登場し、物体認識・検出の技術として3位以降のMachineLearningチームとError率で圧倒的な差をつけて優勝したことから注目を集めた。DeepLearningによる画像解析タスクといっても目的が複数存在するため、言葉の定義を下記にまとめる。</p>

<ul>
<li><b>物体認識(Object Recognition・Classification) </b>: 1枚ずつの画像毎に何の物体であるかを認識する。(1枚の画像に対して1つの物体のラベルを付与する。)</li>
<li><b>物体位置特定(Object Localization)</b> : 1枚の画像の中に物体が何処に映っているかの領域を認識する。</li>
<li><b>物体検出(Object Detection) </b>: 1枚の画像の中に何が何処に映っているかを検出する。(1枚の画像に対して複数の物体のラベルと領域を認識する。)</li>
<li><b>セグメンテーション(Segmentation) </b> : 1枚の画像の中に何が何処に映っているかを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D4%A5%AF%A5%BB%A5%EB">ピクセル</a>単位で分離する。</li>
</ul>


<p><i>Object Recognition: which object is depicted in the image? <br>
Object detection: where is this object in the image?</i></p>

<p>Ref :
<a href="https://dsp.stackexchange.com/questions/12940/object-detection-versus-object-recognition">image processing - Object detection versus object recognition - Signal Processing Stack Exchange</a></p>

<h3>画像解析<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a></h3>

<p><span itemscope itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/y/yutakikuchi/20180916/20180916233821.png" alt="f:id:yutakikuchi:20180916233821p:plain:w450" title="f:id:yutakikuchi:20180916233821p:plain:w450" class="hatena-fotolife" style="width:450px" itemprop="image"></span>
<span itemscope itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/y/yutakikuchi/20180917/20180917013315.png" alt="f:id:yutakikuchi:20180917013315p:plain:w450" title="f:id:yutakikuchi:20180917013315p:plain:w450" class="hatena-fotolife" style="width:450px" itemprop="image"></span>
DeepLearningの画像解析<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>は目的により多数あり、それぞれで使用目的が異なる。</p>

<ul>
<li>物体認識(Object Recognition・Classification)

<ul>
<li>VGG(Visual Geometry Group : team)

<ul>
<li><a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/">Visual Geometry Group Home Page</a></li>
<li>畳み込みとプーリング層で構成される基本的なCNN。層の数でVGG16、VGG19がある。</li>
</ul>
</li>
<li>ResNet(Residual Network)

<ul>
<li><a href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a></li>
<li>層を深くしすぎると性能劣化が起こる点を解消し、深くすることによって精度を改善する。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Microsoft">Microsoft</a>のチームによって開発。</li>
</ul>
</li>
<li>GoogLeNet(Inception-V1)

<ul>
<li><a href="https://www.tensorflow.org/hub/modules/google/imagenet/inception_v1/classification/1">https://www.tensorflow.org/hub/modules/google/imagenet/inception_v1/classification/1</a></li>
<li>基本構造はCNN、縦と横の両方にネットワークを広げる。横方向の幅をInception構造と呼ぶ。名前の通り<a class="keyword" href="http://d.hatena.ne.jp/keyword/Google">Google</a>(<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A4%A5%F3%A5%BF%A1%BC%A5%F3">インターン</a>)が開発。Inception-V4など新しいVersionもある。</li>
</ul>
</li>
</ul>
</li>
<li>物体検出(Object Detection)

<ul>
<li>YOLO(You only look once)

<ul>
<li><a href="https://pjreddie.com/darknet/yolo/">YOLO: Real-Time Object Detection</a></li>
<li>RealTimeに物体を検出する。その他の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>と比較して処理速度が速いとされる。ただし、物体の検出ができるのは2個までのように制限がある。</li>
</ul>
</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/SSD">SSD</a>(Single Shot MultiBox Detector)

<ul>
<li><a href="https://arxiv.org/pdf/1512.02325.pdf">https://arxiv.org/pdf/1512.02325.pdf</a></li>
<li>YOLOと同様にRealTimeに物体を検出するが、多クラスの物体検出も可能としている。</li>
</ul>
</li>
</ul>
</li>
</ul>


<p>Ref :
<a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/object_localization_and_detection.html">Object Localization and Detection &middot; Artificial Inteligence</a>
<a href="http://blog.qure.ai/notes/semantic-segmentation-deep-learning-review">A 2017 Guide to Semantic Segmentation with Deep Learning</a></p>

<h3>物体認識の精度比較</h3>

<p><span itemscope itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/y/yutakikuchi/20180917/20180917011720.png" alt="f:id:yutakikuchi:20180917011720p:plain:w450" title="f:id:yutakikuchi:20180917011720p:plain:w450" class="hatena-fotolife" style="width:450px" itemprop="image"></span>
左図はCNNベースの物体認識(Object Recognition・Classification)の精度比較グラフ(縦軸精度)であり、後発の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%A2%A5%EB%A5%B4%A5%EA%A5%BA%A5%E0">アルゴリズム</a>ほど精度が高い様子が分かる。右図は精度(縦軸)、学習速度(横軸)、メモリ使用量(円の大きさ)を示している。一般的には精度が高くなれば学習速度が遅くなる。精度、学習速度・メモリ使用量はそれぞれtrade offの関係となるようだ。</p>

<p>Ref :
<a href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/object_localization_and_detection.html">Object Localization and Detection &middot; Artificial Inteligence</a>
<a href="https://arxiv.org/pdf/1605.07678.pdf">https://arxiv.org/pdf/1605.07678.pdf</a></p></blockquote>


