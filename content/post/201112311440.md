
---
title: "「魔法少女まどか☆マギカ」の台詞をNLTK(Natural Language Toolkit)で解析する"
date: 2011-12-31T14:40:04+00:00
category : [Python]
canonicalurl: http://yut.hatenablog.com/entry/20111231/1325310004
---

## [Python] : 「魔法少女まどか☆マギカ」の台詞をNLTK(Natural Language Toolkit)で解析する


<div class="section">
<h4><span class="deco" style="font-weight:bold;font-size:large;">目次</span></h4>

<blockquote>
    
<ol>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%CB%E2%CB%A1%BE%AF%BD%F7%A4%DE%A4%C9%A4%AB%A1%F9%A5%DE%A5%AE%A5%AB">魔法少女まどか☆マギカ</a></li>
<li>NLTK</li>
<li>NLTK<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a></li>
<li>まど☆マギ台詞単語解析</li>
<li>まど☆マギ台詞<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a></li>
</ol>
</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;font-size:large;"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%CB%E2%CB%A1%BE%AF%BD%F7%A4%DE%A4%C9%A4%AB%A1%F9%A5%DE%A5%AE%A5%AB">魔法少女まどか☆マギカ</a></span></h4>

<blockquote>
    <p><iframe width="560" height="315" src="http://www.youtube.com/embed/k-M8BkFTbpw" frameborder="0" allowfullscreen></iframe><br />
NLTK練習の題材として2011年の大ヒットアニメ？「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CB%E2%CB%A1%BE%AF%BD%F7%A4%DE%A4%C9%A4%AB%A1%F9%A5%DE%A5%AE%A5%AB">魔法少女まどか☆マギカ</a>」の台詞を用いる。通称まど☆マギで知られる本作品であるが、第15回<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%B8%B2%BD%C4%A3%A5%E1%A5%C7%A5%A3%A5%A2%B7%DD%BD%D1%BA%D7">文化庁メディア芸術祭</a>アニメーション<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C9%F4%CC%E7">部門</a>大賞、既に映画かも決まっておりテレビシリーズの総集編前後編と完全新作の全3作品の製作が予定されている。いわゆるダークファンタジーの世界観で台詞の中にも絶望を彷彿させるマイナス思考な台詞が多いように思う。事前の予想では「いやだ」とか「助けて」などの台詞が頻繁に使われていると考えたが、それらをNLTKを用いて検証してみる。この記事の前半はNLTKの設定、後半がまど☆マギの台詞を単語/<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>の両面で解析している。尚使用するサンプルコードは全て<a class="keyword" href="http://d.hatena.ne.jp/keyword/github">github</a>に挙げているので、そちらを参照して欲しい。<a href="https://github.com/yutakikuchi/NLTK/tree/master/madmagi">https://github.com/yutakikuchi/NLTK/tree/master/madmagi</a></p>

</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;font-size:large;">NLTK</span></h4>

<blockquote>
    
<div class="section">
<h5>NLTKとは</h5>

<ul>
<li>NLTKとはNatural Language Toolkitの略。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>で書かれた<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC%BD%E8%CD%FD">自然言語処理</a>ToolKit。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C6%A5%AD%A5%B9%A5%C8%A5%DE%A5%A4%A5%CB%A5%F3%A5%B0">テキストマイニング</a>等が可能。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Windows">Windows</a>/<a class="keyword" href="http://d.hatena.ne.jp/keyword/MacOS">MacOS</a>/<a class="keyword" href="http://d.hatena.ne.jp/keyword/Linux">Linux</a>上で動作させる事ができる。</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Linux">Linux</a>の場合Python2.4x,2.5x,2.6xを必要とする。</li>
<li>インストールする際にはPyAMLが必要で、解析結果をグラフ化するようにNumPyやmatplotlibを一緒に使うと良い。</li>
</ul>
</div>
<div class="section">
<h5>NLTKのインストール</h5>

<ul>
<li><a href="http://www.nltk.org/download">http://www.nltk.org/download</a> 公式ドキュメントに書いてある内容を実行する。尚今回のインストール実行環境は<a class="keyword" href="http://d.hatena.ne.jp/keyword/CentOS">CentOS</a> release 5.7 (Final)とする。</li>
<li>始めに入れておくと後で嵌らないpkgは次のもの</li>
</ul><pre class="code" data-lang="" data-unlink>$ sudo yum install gcc-c++ kernel-devel ncurses-devel glibc glibc-devel  glib-devel glib2-devel gtk2-devel tk tk-devel tcl tcl-devel tkinter freetype freetype-devel libpng libpng-devel</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>のversion確認</h5>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>のversionが2.4x <= <a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a> <= 2.6xとなっていなければ<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>のインストールを行う必要がある。</li>
</ul><pre class="code" data-lang="" data-unlink>$ python -V
Python 2.4.3</pre>
</div>
<div class="section">
<h5>PyYAML install</h5>
<pre class="code" data-lang="" data-unlink>$ wget 'http://pyyaml.org/download/pyyaml/PyYAML-3.09.tar.gz'
$ tar -xzf PyYAML-3.09.tar.gz
$ cd PyYAML-3.09
$ sudo python setup.py install</pre>
</div>
<div class="section">
<h5>NLTK install</h5>
<pre class="code" data-lang="" data-unlink>$ wget 'http://nltk.googlecode.com/files/nltk-2.0.1rc1.tar.gz'
$ tar -xzf nltk-2.0.1rc1.tar.gz
$ cd nltk-2.0.1rc1
$ sudo python setup.py install</pre>
</div>
<div class="section">
<h5>numpy install</h5>
<pre class="code" data-lang="" data-unlink>$ wget 'http://prdownloads.sourceforge.net/numpy/numpy-1.5.1.tar.gz'
$ tar -xzf numpy-1.5.1.tar.gz
$ cd numpy-1.5.1
$ sudo python setup.py install</pre><p><span class="deco" style="font-weight:bold;">SystemError: Cannot compile '<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>.h'. Perhaps you need to install <a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>-dev|<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>-devel.</span>と怒られてしまうので、<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>-develを入れる。<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>-develのインストール完了後にサイドnumpyをインストールする。</p>

</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>-devel install</h5>
<pre class="code" data-lang="" data-unlink>$ sudo yum install python-devel</pre>
</div>
<div class="section">
<h5>matplotlib install</h5>
<pre class="code" data-lang="" data-unlink>$ wget 'http://prdownloads.sourceforge.net/matplotlib/matplotlib-1.0.1.tar.gz'
$ tar -xzf matplotlib-1.0.1.tar.gz
$ cd matplotlib-1.0.1
$ sudo python setup.py install</pre><p><span class="deco" style="font-weight:bold;">ft2build.h: そのようなファイルやディレクトリはありませ/<a class="keyword" href="http://d.hatena.ne.jp/keyword/png">png</a>.h: そのようなファイルやディレクトリはありません</span>とインストール中に怒られるので、<a class="keyword" href="http://d.hatena.ne.jp/keyword/freetype">freetype</a>-devel,<a class="keyword" href="http://d.hatena.ne.jp/keyword/freetype">freetype</a>,libpng,libpng-develを入れる。インストル後再度matplotlibを入れる。</p>

</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/freetype">freetype</a>/<a class="keyword" href="http://d.hatena.ne.jp/keyword/freetype">freetype</a>-devel install</h5>
<pre class="code" data-lang="" data-unlink>$ yum install freetype freetype-devel libpng libpng-devel</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/MeCab">MeCab</a>のinstall</h5>

<ul>
<li>代表的な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C4%A1%BC%A5%EB">ツール</a>の<a class="keyword" href="http://d.hatena.ne.jp/keyword/MeCab">MeCab</a>をinstallする。</li>
</ul><pre class="code" data-lang="" data-unlink>$ wget http://mecab.googlecode.com/files/mecab-0.99.tar.gz
$ tar -xzf mecab-0.99.tar.gz
$ cd mecab-0.99
$ ./configure --with-charset=utf8
$ make && sudo make install</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-ipadicのinstall</h5>
<pre class="code" data-lang="" data-unlink>$ wget http://sourceforge.net/projects/mecab/files/mecab-ipadic/2.7.0-20070801/mecab-ipadic-2.7.0-20070801.tar.gz/download
$ tar -xzf mecab-ipadic-2.7.0-20070801.tar.gz
$ ./configure --with-charset=utf8
$ make && sudo make install</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>のinstall</h5>

<ul>
<li><span class="deco" style="color:#FF0000;">※<a class="keyword" href="http://d.hatena.ne.jp/keyword/MeCab">MeCab</a>本体とバージョンをそろえないと<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A5%F3%A5%D1%A5%A4%A5%EB">コンパイル</a>時にエラーが出る。</span></li>
</ul><pre class="code" data-lang="" data-unlink>$ wget http://sourceforge.net/projects/mecab/files/mecab-python/0.99/mecab-python-0.989.tar.gz/download
$ tar -xzf mecab-python-0.99.tar.gz
$ python setup.py build
$ sudo python setup.py install</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/mecab">mecab</a>-<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>の起動</h5>
<pre class="code" data-lang="" data-unlink>$ Python 2.6.6 (r266:84292, Dec 25 2011, 11:27:19) 
[GCC 4.1.2 20080704 (Red Hat 4.1.2-51)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import MeCab
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "MeCab.py", line 25, in <module>
_MeCab = swig_import_helper()
  File "MeCab.py", line 17, in swig_import_helper
import _MeCab
ImportError: libmecab.so.2: cannot open shared object file: No such file or directory</pre>
<ul>
<li>エラーが出てしまう。原因はlibmecab.so.2のファイルが/usr/local/lib/libmecab.so.2のパスに設置されているからlibとして読み込めていない。</li>
<li>このエラーを解決するためには/etc/ld.so.conf.d/lib.confというファイルを作成して以下の一行を加える。</li>
</ul><pre class="code" data-lang="" data-unlink>/usr/local/lib</pre>
<ul>
<li>設定の内容を反映するにはldconfigコマンドを実行する。</li>
</ul><pre class="code" data-lang="" data-unlink>$ sudo ldconfig</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/swig">swig</a>のinstall</h5>

<ul>
<li>JUMANで必要な<a class="keyword" href="http://d.hatena.ne.jp/keyword/swig">swig</a>を先に入れておく。</li>
</ul><pre class="code" data-lang="" data-unlink>$ wget 'http://prdownloads.sourceforge.net/swig/swig-2.0.0.tar.gz'
$ tar -xzf swig-2.0.0.tar.gz
$ cd swig-2.0.0
$ ./configure --prefix=/usr/local/swig-py26/ --with-python=/usr/local/bin/python2.6
$ make && sudo make install </pre>
</div>
<div class="section">
<h5>JUMAN/cJumanのinstall</h5>
<pre class="code" data-lang="" data-unlink>$ wget 'http://nlp.ist.i.kyoto-u.ac.jp/DLcounter/lime.cgi?down=http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/juman/juman-6.0.tar.gz&name=juman-6.0.tar.gz'
$ tar -xzf juman-6.0.tar.gz
$ cd juman-6.0
$ CFLAGS=-fPIC ./configure
$ make && sudo make install
$ cd lib
$ wget 'http://app-dist.khlog.net/software/python-cjuman/cJuman.i'
$ /usr/local/swig-py26/bin/swig -python cJuman.i
$ gcc -c cJuman_wrap.c -fPIC -I/usr/local/include/python2.6
$ gcc -shared *.o -o _cJuman.so
$ sudo install -m 644  _cJuman.so cJuman.py /usr/local/lib/python2.6/site-packages/</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;font-size:large;">NLTK<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a></span></h4>

<blockquote>
    
<div class="section">
<h5>代表的な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>の種類</h5>

<ul>
<li>平文<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>(通常のテキスト) 
<ul>
<li>ただの平文テキスト。</li>
</ul></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>済み<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>(タグ付き<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>)
<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>が済んでいる平文テキスト。</li>
<li>NLTKでは<a class="keyword" href="http://d.hatena.ne.jp/keyword/JEITA">JEITA</a>という<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>が用意されている。</li>
</ul></li>
<li>依存構造解析済み<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>(ブログ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>)
<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>、構文、格・省略・照応、評判情報を含んだブログ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>。</li>
<li>NLTKでは<a class="keyword" href="http://d.hatena.ne.jp/keyword/KNB">KNB</a>という<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>が用意されている。</li>
</ul></li>
</ul>
</div>
<div class="section">
<h5>NLTKでの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>ダウンロード</h5>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A5%DE%A5%F3%A5%C9%A5%E9%A5%A4%A5%F3">コマンドライン</a>で以下を実行する。</li>
<li>最新のNLTK<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>では<a class="keyword" href="http://d.hatena.ne.jp/keyword/jeita">jeita</a>がダウンロードできない様子。</li>
</ul><pre class="hljs python" data-lang="python" data-unlink>$ python
Python <span class="synConstant">2.6</span>.<span class="synConstant">6</span> (r266:<span class="synConstant">84292</span>, Dec <span class="synConstant">25</span> <span class="synConstant">2011</span>, <span class="synConstant">11</span>:<span class="synConstant">27</span>:<span class="synConstant">19</span>) 
[GCC <span class="synConstant">4.1</span>.<span class="synConstant">2</span> <span class="synConstant">20080704</span> (Red Hat <span class="synConstant">4.1</span>.<span class="synConstant">2</span>-<span class="synConstant">51</span>)] on linux2
Type <span class="synConstant">"help"</span>, <span class="synConstant">"copyright"</span>, <span class="synConstant">"credits"</span> <span class="synStatement">or</span> <span class="synConstant">"license"</span> <span class="synStatement">for</span> more information.
>>> <span class="synPreProc">import</span> nltk
>>> nltk.download()
NLTK Downloader
---------------------------------------------------------------------------
d) Download      l) List      c) Config      h) Help      q) Quit
---------------------------------------------------------------------------
Downloader> d
Download which package (l=<span class="synIdentifier">list</span>; x=cancel)?
  Identifier> knbc
  usr/local/lib/python2.<span class="synConstant">6</span>/site-packages/nltk/__init__.py:<span class="synConstant">658</span>: <span class="synType">DeprecationWarning</span>: <span class="synIdentifier">object</span>.__new__() takes no parameters
Downloading package <span class="synConstant">'knbc'</span> to /home/yuta/nltk_data...
</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/KNB">KNB</a>ファイルデータ</h5>

<ul>
<li>以下のコマンドで中身を見てみる。</li>
</ul><pre class="code" data-lang="" data-unlink>$ nkf corpora/knbc/corpus1/KN001_Keitai_1/KN001_Keitai_1-1-1-01</pre>
<ul>
<li>結果</li>
</ul><pre class="code" data-lang="" data-unlink># S-ID:KN001_Keitai_1-1-1-01 KNP:2008/02/25 SCORE:-12.47259 MOD:2009/02/01
* 1D <BGH:携帯/けいたい><文節内><係:文節内><文頭><サ変><括弧始><引用内文頭><体言><名詞項候補><先行詞候補><非用言格解析:動><態:未定><正規化代表表記:携帯/けいたい><C用;【不特定:人】;ガ;-1;-1;9.999:(文外)><C用;【電話】;ヲ;0;1;9.999:KN001_Keitai_1-1-1-01(同一文):1タグ>
［ ［ ［ 特殊 1 括弧始 3 * 0 * 0 NIL <文頭><記英数カ><英記号><記号><括弧始><括弧><接頭><非独立接頭辞><タグ単位始><文節始>
携帯 けいたい 携帯 名詞 6 サ変名詞 2 * 0 * 0 "カテゴリ:人工物-その他:抽象物 ドメイン:家庭・暮らし 代表表記:携帯/けいたい" <カテゴリ:人工物-その他:抽象物><ドメイン:家庭・暮らし><代表表記:携帯/けいたい><正規化代表表記:携帯/けいたい><漢字><かな漢字><名詞相当語><サ変><自立><内容語><意味有>
+ 5D <BGH:電話/でんわ><文節内><係:文節内><補文ト><サ変><括弧終><引用内文末><体言><名詞項候補><先行詞候補><非用言格解析:動><態:未定><正規化代表表記:電話/でんわ><C用;【携帯】;修飾;0;0;9.999:KN001_Keitai_1-1-1-01(同一文):0タグ>
電話 でんわ 電話 名詞 6 サ変名詞 2 * 0 * 0 "補文ト カテゴリ:人工物-その他 ドメイン:家庭・暮らし 代表表記:電話/でんわ" <補文ト><カテゴリ:人工物-その他><ドメイン:家庭・暮らし><代表表記:電話/でんわ><正規化代表表記:電話/でんわ><漢字><かな漢字><名詞相当語><サ変><自立><複合←><内容語><意味有><タグ単位始>
］ ］ ］ 特殊 1 括弧終 4 * 0 * 0 NIL <記英数カ><英記号><記号><括弧終><括弧><述語区切><付属><複合←>
* 3D <文節内><係:文節内><サ変><体言><名詞項候補><先行詞候補><非用言格解析:動><態:未定><正規化代表表記:プリペイドカード/プリペイドカード></pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/KNB">KNB</a>の単語ごとの出力</h5>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/KNB">KNB</a>のタグ付けデータを単語ごとに出力する。</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys 
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> re,pprint,nltk
<span class="synPreProc">from</span> nltk.corpus.reader <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.corpus.reader.util <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.corpus.util <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.text <span class="synPreProc">import</span> Text

<span class="synStatement">def</span> <span class="synIdentifier">pp</span>(obj):
pp = pprint.PrettyPrinter(indent=<span class="synConstant">4</span>, width=<span class="synConstant">160</span>)
<span class="synIdentifier">str</span> = pp.pformat(obj)
<span class="synStatement">return</span> re.sub(<span class="synConstant">r"\\u([0-9a-f]{4})"</span>, <span class="synStatement">lambda</span> x: <span class="synIdentifier">unichr</span>(<span class="synIdentifier">int</span>(<span class="synConstant">"0x"</span>+x.group(<span class="synConstant">1</span>),<span class="synConstant">16</span>)), <span class="synIdentifier">str</span>)

<span class="synStatement">def</span> <span class="synIdentifier">_knbc_fileids_sort</span>(x):
cells = x.split(<span class="synConstant">'-'</span>)
<span class="synStatement">return</span> (cells[<span class="synConstant">0</span>], <span class="synIdentifier">int</span>(cells[<span class="synConstant">1</span>]), <span class="synIdentifier">int</span>(cells[<span class="synConstant">2</span>]), <span class="synIdentifier">int</span>(cells[<span class="synConstant">3</span>]))

root = nltk.data.find(<span class="synConstant">'corpora/knbc/corpus1'</span>)
fileids = [f <span class="synStatement">for</span> f <span class="synStatement">in</span> find_corpus_fileids(FileSystemPathPointer(root), <span class="synConstant">".*"</span>) <span class="synStatement">if</span> re.search(<span class="synConstant">r"\d\-\d\-[\d]+\-[\d]+"</span>, f)] 
knbc = LazyCorpusLoader(<span class="synConstant">'knbc/corpus1'</span>, KNBCorpusReader, <span class="synIdentifier">sorted</span>(fileids, key=_knbc_fileids_sort), encoding=<span class="synConstant">'euc-jp'</span>)
<span class="synIdentifier">print</span> <span class="synConstant">'/'</span>.join( knbc.words()[:<span class="synConstant">100</span>] )
</pre>
<ul>
<li>結果</li>
</ul><pre class="code" data-lang="" data-unlink>［/携帯/電話/］/プリペイド/カード/携帯/布教/。/もはや/’/今さら/’/だ/が/、/と/いう/接頭句/で/始める/しか/ない/ほど/今さら/だ/が/、/私/は/プリペイド/携帯/を/ずっと/使って/いる/。/犯罪/に/用い/られる/など/に/より/かなり/イメージ/を/悪化/さ/せて/しまった/プリペイド/携帯/だ/が/、/一/ユーザー/と/して/は/、/かなり/使いで/が/ある/。/かつて/は/このような/話/を/友人/に/振って/も/、/「/携帯/電話/の/料金/は/親/が/払って/いる/から/別に/．．．/」/と/いう/にべもない/答え/が/返って/くる/ばかりだった/が
(布教/。</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%B8%A4%EA%BC%F5%A4%B1">係り受け</a>関係を表現した<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%DA%B9%BD%C2%A4">木構造</a></h5>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%B8%A4%EA%BC%F5%A4%B1">係り受け</a>関係を表現した<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CC%DA%B9%BD%C2%A4">木構造</a>にアクセスするには上のコードに以下の内容を追加する。</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synIdentifier">print</span> <span class="synConstant">'</span><span class="synSpecial">\n\n</span><span class="synConstant">'</span>.join( <span class="synConstant">'%s'</span> % tree <span class="synStatement">for</span> tree <span class="synStatement">in</span> knbc.parsed_sents()[<span class="synConstant">0</span>:<span class="synConstant">2</span>] )
</pre>
<ul>
<li>結果</li>
</ul><pre class="code" data-lang="" data-unlink>  (電話/］ ［/携帯)
  (携帯 (カード プリペイド)))

(使って/いる/。
  (今さら/だ/が/、
(ほど
  (始める/しか/ない
    もはや
    (接頭句/で (いう ’/今さら/’/だ/が/、/と)))))
  私/は
  (携帯/を プリペイド)
  ずっと)</pre>
</div>
<div class="section">
<h5>単語と品詞のタプルを表示する</h5>

<ul>
<li>以下を上のコードに追加する</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synIdentifier">print</span> <span class="synConstant">'</span><span class="synSpecial">\n</span><span class="synConstant">'</span>.join( <span class="synConstant">' '</span>.join(<span class="synConstant">"%s/%s"</span>%(w[<span class="synConstant">0</span>], w[<span class="synConstant">1</span>].split(<span class="synConstant">' '</span>)[<span class="synConstant">2</span>]) <span class="synStatement">for</span> w <span class="synStatement">in</span> sent) <span class="synStatement">for</span> sent <span class="synStatement">in</span> knbc.tagged_sents()[<span class="synConstant">0</span>:<span class="synConstant">20</span>] )
</pre>
<ul>
<li>結果</li>
</ul><pre class="code" data-lang="" data-unlink>［/特殊 携帯/名詞 電話/名詞 ］/特殊 プリペイド/名詞 カード/名詞 携帯/名詞 布教/名詞 。/特殊
もはや/副詞 ’/特殊 今さら/副詞 ’/特殊 だ/判定詞 が/助詞 、/特殊 と/助詞 いう/動詞 接頭句/名詞 で/助詞 始める/動詞 しか/助詞 ない/形容詞 ほど/名詞 今さら/副詞 だ/判定詞 が/助詞 、/特殊 私/名詞 は/助詞 プリペイド/名詞 携帯/名詞 を/助詞 ずっと/副詞 使って/動詞 いる/接尾辞 。/特殊</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;"><span class="deco" style="font-size:large;"><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A4%DE%A4%C9%A4%AB%A1%F9%A5%DE%A5%AE%A5%AB">まどか☆マギカ</a>の台詞を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EC%A5%A4%A5%D4%A5%F3%A5%B0">スクレイピング</a></span></span></h4>

<blockquote>
    <p>NLTKの設定の説明が長過ぎたが、以下からがこの記事の本題。</p>

<div class="section">
<h5>台詞</h5>

<ul>
<li><a href="http://www22.atwiki.jp/madoka-magica/">http://www22.atwiki.jp/madoka-magica/</a>　に各話の一部分だけが公開されている。このURLから台詞のデータだけを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EC%A5%A4%A5%D4%A5%F3%A5%B0">スクレイピング</a>する。　</li>
</ul>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EC%A5%A4%A5%D4%A5%F3%A5%B0">スクレイピング</a>コード</h5>
<pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>

<span class="synPreProc">import</span> sys,re,urllib,urllib2
urls = ( <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/170.html'</span>, 
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/175.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/179.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/180.html'</span>,
     <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/pages/200.html'</span>,
     )
f = <span class="synIdentifier">open</span>( <span class="synConstant">'./madmagi.txt'</span>, <span class="synConstant">'w'</span> )
opener = urllib2.build_opener()
ua = <span class="synConstant">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_6_8) AppleWebKit/534.51.22 (KHTML, like Gecko) Version/5.1.1 Safari/    534.51.22'</span>
referer = <span class="synConstant">'http://www22.atwiki.jp/madoka-magica/'</span>
opener.addheaders = [( <span class="synConstant">'User-Agent'</span>, ua ),( <span class="synConstant">'Referer'</span>, referer )]
<span class="synStatement">for</span> url <span class="synStatement">in</span> urls:
content = opener.<span class="synIdentifier">open</span>( url ).read()
<span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<div class="contents".*?>((.|\n)*?)</div>'</span>, re.M ).search( content ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
    data = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'<div class="contents".*?>((.|\n)*?)</div>'</span>, re.M ).search( content ).group()
    <span class="synStatement">if</span> re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'「(.*?)」'</span>, re.M ).search( data ) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>: 
        lines = re.<span class="synIdentifier">compile</span>( <span class="synConstant">r'「(.*?)」'</span>, re.M ).findall( data )
        <span class="synStatement">for</span> line <span class="synStatement">in</span> lines:
            f.write( line + <span class="synConstant">"</span><span class="synSpecial">\n</span><span class="synConstant">"</span> )
f.close()
</pre>
</div>
<div class="section">
<h5>抽出サンプル</h5>

<ul>
<li>抽出したデータを後で利用するためmadmagi.txtとして保存する。</li>
</ul><pre class="code" data-lang="" data-unlink>んっん…あっ…！
あっ…！
ひどい…
仕方ないよ。彼女一人では荷が重すぎた
でも、彼女も覚悟の上だろう
そんな…あんまりだよ、こんなのってないよ
諦めたらそれまでだ
でも、君なら運命を変えられる
避けようのない滅びも、嘆きも、全て君が覆せばいい
そのための力が、君には備わっているんだから
本当なの？
私なんかでも、本当に何かできるの？こんな結末を変えられるの？
もちろんさ。だから僕と契約して、魔法少女になってよ！
私は巴マミ
あなたたちと同じ、見滝原中の３年生
そして
キュゥべえと契約した、魔法少女よ
はあーはぁ。うん
やあ
はい、これ
うわぁ…。いつも本当にありがとう。さやかはレアなＣＤを見つける天才だね
あっはは、そんな、運がいいだけだよ。きっと
この人の演奏は本当にすごいんだ。さやかも聴いてみる？
う、い、いいのかな？
本当はスピーカーで聴かせたいんだけど、病院だしね
ええぇー…
あっ
あら、上条君のお見舞い？
（略）</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;font-size:large;">まど☆マギ台詞単語解析</span></h4>

<blockquote>
    
<ul>
<li>以下ではまど☆マギの平文<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>を利用する。</li>
</ul>
<div class="section">
<h5>文字数抽出</h5>

<ul>
<li>上でスクレイプしたデータをmadmagi.txtとして保存する。</li>
<li>nltk.RegexpTokenizerを利用してテキストから<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%B5%AC%C9%BD%B8%BD">正規表現</a>で単語を抽出する。</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys 
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> nltk
<span class="synPreProc">from</span> nltk.corpus.reader <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.corpus.reader.util <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.text <span class="synPreProc">import</span> Text

jp_sent_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'[^　「」！？。]*[！？。]'</span>)
jp_chartype_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'([ぁ-んー]+|[ァ-ンー]+|[</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+|[^ぁ-んァ-ンー</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+)'</span>)
data = PlaintextCorpusReader( <span class="synConstant">'./'</span>, <span class="synConstant">r'madmagi.txt'</span>,
                          encoding=<span class="synConstant">'utf-8'</span>,
                          para_block_reader=read_line_block,
                          sent_tokenizer=jp_sent_tokenizer,
                          word_tokenizer=jp_chartype_tokenizer )
context =  data.raw()
phrases = nltk.word_tokenize( context )
<span class="synIdentifier">print</span> <span class="synConstant">'文字数:'</span> + <span class="synIdentifier">str</span>(<span class="synIdentifier">len</span>(phrases)) 
</pre>
<ul>
<li>実行結果</li>
</ul><pre class="code" data-lang="" data-unlink>文字数:3320</pre>
</div>
<div class="section">
<h5>文脈を抽出</h5>

<ul>
<li>テキスト中のトークンを列挙する。</li>
<li>上のコードに以下を追加する。トークンごとに'/'でデータを区切って表示する。</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synIdentifier">print</span> <span class="synConstant">'トークン数:'</span> + <span class="synIdentifier">str</span>(<span class="synIdentifier">len</span>(data.words()))
<span class="synIdentifier">print</span> <span class="synConstant">'/'</span> . join( data.words()[<span class="synConstant">0</span>:<span class="synIdentifier">len</span>(data.words())] )
</pre>
<ul>
<li>結果 
<ul>
<li>トークンの区切りが微妙（<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>ではない）で統計にはそのまま利用できなさそう。 </li>
</ul></li>
</ul><pre class="code" data-lang="" data-unlink>トークン数:1483
んっん/…/あっ/…！
/あっ/…！
/ひどい/…
/仕方/ないよ/。/彼女一人/では/荷/が/重/すぎた/
/でも/、/彼女/も/覚悟/の/上/だろう/
/そんな/…/あんまりだよ/、/こんなのってないよ/
/諦/めたらそれまでだ/
/でも/、/君/なら/運命/を/変/えられる/
/避/けようのない/滅/びも/、/嘆/きも/、/全/て/君/が/覆/せばいい/
/そのための/力/が/、/君/には/備/わっているんだから/
/本当/なの/？
/私/なんかでも/、/本当/に/何/かできるの/？/こんな/結末/を/変/えられるの/？
/もちろんさ/。/だから/僕/と/契約/して/、/魔法少女/になってよ/！
/私/は/巴/マミ/
/あなたたちと/同/じ/、/見滝原中/の/３/年生/
(略)</pre>
</div>
<div class="section">
<h5>解析した単語をまとめて昇順に並べる</h5>

<ul>
<li>key(単語)、value(個数)型の辞書を作成する。</li>
<li>サンプルコード</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> nltk
<span class="synPreProc">from</span> nltk.corpus.reader <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.corpus.reader.util <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.text <span class="synPreProc">import</span> Text

jp_sent_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'[^　「」！？。]*[！？。]'</span>)
jp_chartype_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'([ぁ-んー]+|[ァ-ンー]+|[</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+|[^ぁ-んァ-ンー</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+)'</span>)
data = PlaintextCorpusReader( <span class="synConstant">'./'</span>, <span class="synConstant">r'madmagi.txt'</span>,
                          encoding=<span class="synConstant">'utf-8'</span>,
                          para_block_reader=read_line_block,
                          sent_tokenizer=jp_sent_tokenizer,
                          word_tokenizer=jp_chartype_tokenizer )

node = {}
<span class="synStatement">for</span> i <span class="synStatement">in</span> data.words():
<span class="synStatement">if</span> node.get(i) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
    node[i] = node[i] + <span class="synConstant">1</span>
<span class="synStatement">else</span>:
    node[i] = <span class="synConstant">1</span>
<span class="synStatement">for</span> k,v <span class="synStatement">in</span> <span class="synIdentifier">sorted</span>( node.items(), key=<span class="synStatement">lambda</span> x:x[<span class="synConstant">1</span>] ):
<span class="synIdentifier">print</span> <span class="synConstant">'word:'</span>+ k, <span class="synConstant">' count:'</span> + <span class="synIdentifier">str</span>(v)
</pre>
<ul>
<li>結果
<ul>
<li>トークンの区切りが微妙であるが、「ほむらちゃん」や「死」、「<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CB%E2%CB%A1%BE%AF%BD%F7">魔法少女</a>」という言葉が特徴的と言える。</li>
</ul></li>
</ul><pre class="code" data-lang="" data-unlink>word:ほむらちゃん  count:5
word:守  count:5
word:……  count:6
word:う  count:6
word:うん  count:6
word:あ  count:6
word:死  count:6
word:して  count:6
word:だから  count:6
word:な  count:6
word:魔法少女  count:7
word:君  count:7
word:そんな  count:7
word:い  count:7
word:何  count:8
word:…。  count:8
word:え  count:8
word:本当  count:8
word:暁美  count:9
word:！  count:9
word:に  count:11
word:が  count:11
word:鹿目  count:11
word:は  count:11
word:さん  count:12
word:を  count:14
word:の  count:14
word:！  count:16
word:…  count:23
word:？  count:23
word:？  count:26
word:私  count:27
word:…  count:30
word:。  count:49
word:  count:83
word:、  count:141</pre>
</div>
<div class="section">
<h5>単語の個数をグラフにplotする</h5>

<ul>
<li>matplotlibを利用する。plotした結果を画像として保存する。サンプルコードは次の通り</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> nltk
<span class="synPreProc">from</span> nltk.corpus.reader <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.corpus.reader.util <span class="synPreProc">import</span> *
<span class="synPreProc">from</span> nltk.text <span class="synPreProc">import</span> Text

<span class="synPreProc">import</span> matplotlib.pyplot <span class="synStatement">as</span> plt
<span class="synPreProc">from</span> pylab <span class="synPreProc">import</span> *
<span class="synPreProc">import</span> matplotlib.font_manager <span class="synStatement">as</span> fm

jp_sent_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'[^　「」！？。]*[！？。]'</span>)
jp_chartype_tokenizer = nltk.RegexpTokenizer(<span class="synConstant">u'([ぁ-んー]+|[ァ-ンー]+|[</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+|[^ぁ-んァ-ンー</span><span class="synSpecial">\u4e00</span><span class="synConstant">-</span><span class="synSpecial">\u9FFF</span><span class="synConstant">]+)'</span>)
data = PlaintextCorpusReader( <span class="synConstant">'./'</span>, <span class="synConstant">r'madmagi.txt'</span>,
                          encoding=<span class="synConstant">'utf-8'</span>,
                          para_block_reader=read_line_block,
                          sent_tokenizer=jp_sent_tokenizer,
                          word_tokenizer=jp_chartype_tokenizer )
fdist = nltk.FreqDist(data.words())
fp = fm.FontProperties(fname=<span class="synConstant">'/home/yuta/.fonts/IPAfont00303/ipag.ttf'</span>) 
xlabel( <span class="synConstant">u'単語'</span>, size=<span class="synConstant">'20'</span>, fontproperties=fp )
ylabel( <span class="synConstant">u'個数'</span>, size=<span class="synConstant">'20'</span>, fontproperties=fp )
title( <span class="synConstant">u'魔法少女まどか☆マギカの単語数plot'</span>, size=<span class="synConstant">'20'</span>, fontproperties=fp )
fdist.plot()
savefig( <span class="synConstant">'madmagi_plot.png'</span> )
</pre>
<ul>
<li>保存した画像
<ul>
<li>x軸の単語数が潰れてしまっているし、おそらく文字化けしているとも思われる。。</li>
</ul></li>
</ul><p><span itemscope itemtype="http://schema.org/Photograph"><a href="http://f.hatena.ne.jp/yutakikuchi/20111231134203" class="hatena-fotolife" itemprop="url"><img src="http://cdn-ak.f.st-hatena.com/images/fotolife/y/yutakikuchi/20111231/20111231134203.png" alt="f:id:yutakikuchi:20111231134203p:image:h400:w550" title="f:id:yutakikuchi:20111231134203p:image:h400:w550" class="hatena-fotolife" style="height:400px;width:550px" itemprop="image"></a></span><br />
</p>

</div>
<div class="section">
<h5>検索</h5>

<ul>
<li>テキスト中の単語を検索する。</li>
<li>上の<a class="keyword" href="http://d.hatena.ne.jp/keyword/python">python</a>コードに以下を追加する。サンプルでは'魔'という単語を検索する例。</li>
</ul><pre class="hljs python" data-lang="python" data-unlink>context_p = Text( p.encode( <span class="synConstant">'utf-8'</span>) <span class="synStatement">for</span> p <span class="synStatement">in</span> context )
result = context_p.concordance( <span class="synConstant">'魔'</span> )
<span class="synIdentifier">print</span> result
</pre>
<ul>
<li>結果</li>
</ul><pre class="code" data-lang="" data-unlink>か ら 僕 と 契 約 し て 、 魔 法 少 女 に な っ て よ ！  
と 契 約 し た 、 魔 法 少 女 よ  
 は あ ー は ぁ  
ち は …   
 彼 女 た ち は 、 魔 法 少 女 。 魔 女 を 狩 る ウ 縺ち は 、 魔 法 少 女 。 魔 女 を 狩 る 者 た ち さ  
 い
た り も す る け れ ど 、 魔 女 を や っ つ け れ ば 、   そ れ で も 、 私 は 魔 法 少 女 だ か ら 。 み ん し か っ た 。 あ な た が 魔 女 に 襲 わ れ た 時 、 間  自 慢 な の   だ か ら 、 魔 法 少 女 に な っ て 、 本  あ 鹿 目 さ ん 、 私 も 魔 法 少 女 に な っ た ん だ  ？ ソ ウ ル ジ ェ ム が 魔 女 を 産 む な ら 、 み ん い … ？ う ん …    私 、 魔 女 に は な り た く な い ら 、 僕 と 契 約 し て 、 魔 法 少 女 に な っ て よ ！</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;"><span class="deco" style="font-size:large;">まど☆マギの台詞<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a></span></span></h4>

<blockquote>
    
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/MeCab">MeCab</a>を利用して☆マギ台詞の平文<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>する</h5>

<ul>
<li>サンプルコード</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> MeCab
mecab = MeCab.Tagger(<span class="synConstant">'-Ochasen'</span>)
data = <span class="synIdentifier">open</span>( <span class="synConstant">'./madmagi.txt'</span> ).read()
<span class="synIdentifier">print</span> mecab.parse( data )
</pre>
<ul>
<li>結果</li>
</ul><pre class="code" data-lang="" data-unlink>ん	ン	ん	名詞-非自立-一般		
っ	ッ	く	動詞-非自立	五段・カ行促音便	連用タ接続
ん	ン	ん	助動詞	不変化型	基本形
…	…	…	記号-一般		
あっ	アッ	あっ	感動詞		
…	…	…	記号-一般		
！	！	！	記号-一般		
あっ	アッ	あっ	感動詞		
…	…	…	記号-一般		
！	！	！	記号-一般		
ひどい	ヒドイ	ひどい	形容詞-自立	形容詞・アウオ段	基本形
…	…	…	記号-一般		
仕方	シカタ	仕方	名詞-ナイ形容詞語幹		
ない	ナイ	ない	助動詞	特殊・ナイ	基本形
よ	ヨ	よ	助詞-終助詞		
。	。	。	記号-句点</pre>
<ul>
<li>上のコードを単語に対する素性を表示するように書き換える。</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> MeCab
mecab = MeCab.Tagger(<span class="synConstant">'-Ochasen'</span>)

data = <span class="synIdentifier">open</span>( <span class="synConstant">'./madmagi.txt'</span> ).read()

node = mecab.parseToNode( data )
phrases = node.<span class="synIdentifier">next</span>
<span class="synStatement">while</span> phrases:
<span class="synIdentifier">print</span> node.surface, node.feature
node = node.<span class="synIdentifier">next</span>
</pre>
<ul>
<li>結果</li>
</ul><pre class="code" data-lang="" data-unlink>ん 名詞,非自立,一般,*,*,*,ん,ン,ン
っ 動詞,非自立,*,*,五段・カ行促音便,連用タ接続,く,ッ,ッ
ん 助動詞,*,*,*,不変化型,基本形,ん,ン,ン
… 記号,一般,*,*,*,*,…,…,…
あっ 感動詞,*,*,*,*,*,あっ,アッ,アッ
… 記号,一般,*,*,*,*,…,…,…
！ 記号,一般,*,*,*,*,！,！,！
あっ 感動詞,*,*,*,*,*,あっ,アッ,アッ
… 記号,一般,*,*,*,*,…,…,…
！ 記号,一般,*,*,*,*,！,！,！
ひどい 形容詞,自立,*,*,形容詞・アウオ段,基本形,ひどい,ヒドイ,ヒドイ
… 記号,一般,*,*,*,*,…,…,…
仕方 名詞,ナイ形容詞語幹,*,*,*,*,仕方,シカタ,シカタ</pre>
</div>
<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/MeCab">MeCab</a>の結果をまとめて昇順に並べる</h5>

<ul>
<li>key(単語)、value(個数)型の辞書を作成する。以下はサンプルコード</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> MeCab
mecab = MeCab.Tagger(<span class="synConstant">'-Ochasen'</span>)

data = <span class="synIdentifier">open</span>( <span class="synConstant">'./madmagi.txt'</span> ).read()

node = mecab.parseToNode( data )
phrases = node.<span class="synIdentifier">next</span>
<span class="synIdentifier">dict</span> = {}
<span class="synStatement">while</span> phrases:
<span class="synStatement">try</span>:
    k = node.surface
    node = node.<span class="synIdentifier">next</span>
    <span class="synStatement">if</span> <span class="synIdentifier">dict</span>.get(k) <span class="synStatement">is</span> <span class="synStatement">not</span> <span class="synIdentifier">None</span>:
        <span class="synIdentifier">dict</span>[k] = <span class="synIdentifier">dict</span>[k] + <span class="synConstant">1</span>
    <span class="synStatement">else</span>:
        <span class="synIdentifier">dict</span>[k] = <span class="synConstant">1</span>
<span class="synStatement">except</span> <span class="synType">AttributeError</span>:
   <span class="synStatement">break</span> 

<span class="synStatement">for</span> k,v <span class="synStatement">in</span> <span class="synIdentifier">sorted</span>( <span class="synIdentifier">dict</span>.items(), key=<span class="synStatement">lambda</span> x:x[<span class="synConstant">1</span>] ):
<span class="synIdentifier">print</span> <span class="synConstant">'word:'</span>+ k, <span class="synConstant">' count:'</span> + <span class="synIdentifier">str</span>(v)
</pre>
<ul>
<li>結果
<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/MeCab">MeCab</a>の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>でも「魔法」、「少女」、「暁美」などが特徴的な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>として抽出されている。</li>
</ul></li>
</ul><pre class="code" data-lang="" data-unlink>word:さやか  count:6
word:彼女  count:6
word:それ  count:7
word:少女  count:7
word:その  count:7
word:そう  count:7
word:魔法  count:7
word:君  count:8
word:暁美  count:9
word:あっ  count:9
word:あ  count:9
word:こんな  count:10
word:あなた  count:10
word:こと  count:10
word:なっ  count:10
word:そんな  count:10
word:いい  count:11
word:何  count:11
word:鹿目  count:11
word:じゃ  count:12
word:むら  count:13
word:ちゃん  count:13
word:か  count:13
word:う  count:13
word:から  count:13
word:ほ  count:14
word:と  count:14
word:って  count:17
word:え  count:18
word:が  count:18
word:を  count:19
word:し  count:21
word:さん  count:23
word:も  count:23
word:な  count:23
word:で  count:24
word:ん  count:25
word:ね  count:26
word:私  count:28
word:た  count:34
word:ない  count:34
word:に  count:40
word:よ  count:42
word:は  count:42
word:だ  count:43
word:！  count:47
word:て  count:52
ord:だ  count:43
word:！  count:47
word:て  count:52
word:の  count:54
word:。  count:60
word:？  count:62
word:…  count:91
word:、  count:141</pre>
</div>
<div class="section">
<h5>JUMANを利用して☆マギ台詞の平文<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B3%A1%BC%A5%D1%A5%B9">コーパス</a>を<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7%B2%F2%C0%CF">形態素解析</a>する</h5>

<ul>
<li>コード</li>
</ul><pre class="hljs python" data-lang="python" data-unlink><span class="synComment">#!/usr/bin/env python</span>
<span class="synComment"># -*- coding: utf-8 -*-</span>
<span class="synPreProc">import</span> sys 
<span class="synIdentifier">reload</span>(sys)
sys.setdefaultencoding(<span class="synConstant">'utf-8'</span>)

<span class="synPreProc">import</span> cJuman 
cJuman.init([<span class="synConstant">'-B'</span>, <span class="synConstant">'-e2'</span>])

<span class="synComment">#JUMANはEUC-JPにしか対応していない</span>
data = <span class="synIdentifier">open</span>( <span class="synConstant">'./madmagi-euc.txt'</span>, ).readlines()
<span class="synIdentifier">print</span> cJuman.parse_opt(data, cJuman.SKIP_NO_RESULT).decode( <span class="synConstant">'euc-jp'</span> )
</pre>
<ul>
<li>出力結果</li>
</ul><pre class="code" data-lang="" data-unlink>もちろん もちろん もちろん 副詞 8 * 0 * 0 * 0 "代表表記:もちろん/もちろん"
さ さ さ 助詞 9 終助詞 4 * 0 * 0 NIL
。 。 。 特殊 1 句点 1 * 0 * 0 NIL
だから だから だから 接続詞 10 * 0 * 0 * 0 "代表表記:だから/だから"
、 、 、 特殊 1 読点 2 * 0 * 0 NIL
僕 ぼく 僕 名詞 6 普通名詞 1 * 0 * 0 "代表表記:僕/ぼく 漢字読み:音 カテゴリ:人"
と と と 助詞 9 格助詞 1 * 0 * 0 NIL
契約 けいやく 契約 名詞 6 サ変名詞 2 * 0 * 0 "代表表記:契約/けいやく カテゴリ:抽象物 ドメイン:ビジネス"
して して する 動詞 2 * 0 サ変動詞 16 タ系連用テ形 14 "代表表記:する/する 付属動詞候補（基本） 自他動詞:自:成る/なる"
、 、 、 特殊 1 読点 2 * 0 * 0 NIL
魔法 まほう 魔法 名詞 6 普通名詞 1 * 0 * 0 "代表表記:魔法/まほう カテゴリ:抽象物"
少女 しょうじょ 少女 名詞 6 普通名詞 1 * 0 * 0 "代表表記:少女/しょうじょ カテゴリ:人"
に に に 助詞 9 格助詞 1 * 0 * 0 NIL
なって なって なる 動詞 2 * 0 子音動詞ラ行 10 タ系連用テ形 14 "代表表記:成る/なる 自他動詞:他:成す/なす;他:する/する"
@ なって なって なる 動詞 2 * 0 子音動詞ラ行 10 タ系連用テ形 14 "代表表記:鳴る/なる 自他動詞:他:鳴らす/ならす"
よ よ る 接尾辞 14 動詞性接尾辞 7 母音動詞 1 省略意志形 5 "代表表記:る/る"
@ よ よ る 接尾辞 14 動詞性接尾辞 7 母音動詞 1 文語命令形 18 "代表表記:る/る"
！ ！ ！ 特殊 1 記号 5 * 0 * 0 NIL</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;font-size:large;">まとめ</span></h4>

<blockquote>
    
<ul>
<li>NLTKを利用してまど☆まぎの単語と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>の解析を行った。NLTKの便利さを少しは実感する事ができた。</li>
<li>元々の台詞の数が少なかったため、「魔法」や「少女」更には登場人物名などの単語が特徴として抽出された。</li>
<li>単語と<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B7%C1%C2%D6%C1%C7">形態素</a>の頻出度を計算した。matplotlibを利用すると結果をグラフ化して保存できる事も分かった。</li>
</ul>
</blockquote>

</div>
<div class="section">
<h4><span class="deco" style="font-weight:bold;font-size:large;">リンク</span></h4>

<blockquote>
    
<ul>
<li><a href="http://www.nltk.org/">Natural Language Toolkit</a></li>
<li><a href="http://nltk.googlecode.com/svn/trunk/doc/book-jp/ch12.html">Python による日本語自然言語処理</a></li>
<li><a href="http://d.hatena.ne.jp/mickey24/20110212/nlp_with_the_social_network">映画「The Social Network」の脚本をNLTKで解析して遊んでみた - ぬいぐるみライフ(仮)</a></li>
<li><a href="http://www22.atwiki.jp/madoka-magica/pages/83.html">魔法少女まどか☆マギカWiki</a></li>
<li><a href="http://d.hatena.ne.jp/dekaduki/20110207/1297086149">入門自然言語処理を読み進めるためのPython＆NLTKインストール</a></li>
<li><a href="https://github.com/yutakikuchi/NLTK/tree/master/madmagi">NLTKサンプルコード</a></li>
</ul>
</blockquote>
<p><br />
<div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873114705/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/51EoFqAGo1L._SL160_.jpg" class="hatena-asin-detail-image" alt="入門 自然言語処理" title="入門 自然言語処理"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873114705/yutakikuchi-22/">入門 自然言語処理</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> Steven Bird,Ewan Klein,Edward Loper,萩<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B8%B6%C0%B5%BF%CD">原正人</a>,中山敬広,水野貴明</li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%E9%A5%A4%A5%EA%A1%BC%A5%B8%A5%E3%A5%D1%A5%F3">オライリージャパン</a></li><li><span class="hatena-asin-detail-label">発売日:</span> 2010/11/11</li><li><span class="hatena-asin-detail-label">メディア:</span> 大型本</li><li><span class="hatena-asin-detail-label">購入</span>: 20人 <span class="hatena-asin-detail-label">クリック</span>: 639回</li><li><a href="http://d.hatena.ne.jp/asin/4873114705/yutakikuchi-22" target="_blank">この商品を含むブログ (44件) を見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

</div>

