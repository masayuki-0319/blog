
---
title: "Machine Learning With Hadoop"
date: 2012-10-15T08:38:00+00:00
category : [機械学習]
canonicalurl: http://yut.hatenablog.com/entry/20121015/1350257880
---

## [機械学習] : Machine Learning With Hadoop

<p><div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/0262018020/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/41IsY16f9PL._SL160_.jpg" class="hatena-asin-detail-image" alt="Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series)" title="Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series)"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/0262018020/yutakikuchi-22/">Machine Learning: A Probabilistic Perspective (Adaptive Computation and Machine Learning series)</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> Kevin P. Murphy</li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> The MIT Press</li><li><span class="hatena-asin-detail-label">発売日:</span> 2012/08/24</li><li><span class="hatena-asin-detail-label">メディア:</span> ハードカバー</li><li><span class="hatena-asin-detail-label">購入</span>: 1人 <span class="hatena-asin-detail-label">クリック</span>: 26回</li><li><a href="http://d.hatena.ne.jp/asin/0262018020/yutakikuchi-22" target="_blank">この商品を含むブログを見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

<div class="section">
<h4>Big DataのMachine Learning</h4>

<blockquote>
    <p>Daily数百ギ<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AC%A5%D0%A5%A4%A5%C8">ガバイト</a>のAccessLogからDataMiningに必要なFeatureをかき集めるのに<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%BF%A5%F3%A5%C9%A5%A2%A5%ED%A5%F3">スタンドアロン</a>の端末で処理を行うには時間が掛かりすぎます。<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%C3%A5%C1%BD%E8%CD%FD">バッチ処理</a>で1日以内にUserのAccessLogを整形、必要な部分を取り出してDataMining/Machine Learningに掛けて、Userが利用するSystemに反映して行こうと考えると最初の<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%C3%A5%C1%BD%E8%CD%FD">バッチ処理</a>で利用できる時間はそれほど多くありません。処理時間改善のために<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>を使い<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>台のマシンに大量のログデータと<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D0%A5%C3%A5%C1%BD%E8%CD%FD">バッチ処理</a>を分散させる仕組みはBig Dataを扱う人の中では常識として利用されています。今日はBigDataをMachineLearningさせたいときの方法について調べた内容を載せます。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> Mahout、PigのUDF、独自<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>の3つのうちどれかを使う事になりそうです。</p>

<div class="section">
<h5><a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> Mahout</h5>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>上で実行可能な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>ライブラリ。ファイルをDownloadして展開するだけで利用可能。一番お手軽だが未実装のAlgorithmもあり、公開されているPatchファイルを当てるなどの対応が必要になる場合がある。</li>
<li><a href="http://mahout.apache.org/">Apache Mahout: Scalable machine learning and data mining</a> <a href="http://b.hatena.ne.jp/entry/mahout.apache.org/"><img src="http://b.hatena.ne.jp/entry/image/http://mahout.apache.org/" alt="はてなブックマーク - Apache Mahout: Scalable machine learning and data mining" border="0" /></a></li>
<li><a href="https://cwiki.apache.org/MAHOUT/algorithms.html">Algorithms</a> <a href="http://b.hatena.ne.jp/entry/s/cwiki.apache.org/MAHOUT/algorithms.html"><img src="http://b.hatena.ne.jp/entry/image/https://cwiki.apache.org/MAHOUT/algorithms.html" alt="はてなブックマーク - Algorithms" border="0" /></a>
<ul>
<li>Classification</li>
<li>Clustering</li>
<li>Pattern Mining</li>
<li>Regression</li>
<li>Dimension reduction</li>
<li>Evolutionary Algorithms</li>
<li>Recommenders / Collaborative Filtering</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Vector">Vector</a> Similarity</li>
</ul></li>
</ul>
</div>
<div class="section">
<h5>Pig</h5>

<ul>
<li>Pig専用のScriptを書く事でMap/Reduceが可能。データのjoinなどもできる。Hiveのライバルプロジェクト。MachineLearningを行う場合はuser-defined functions (UDFs)を書く必要がある。MachineLearningのUDFsはほとんどWeb上に公開されていない。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Twitter">Twitter</a>はPigを使って<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>している。</li>
<li><a href="http://pig.apache.org/">Welcome to Apache Pig!</a> <a href="http://b.hatena.ne.jp/entry/pig.apache.org/"><img src="http://b.hatena.ne.jp/entry/image/http://pig.apache.org/" alt="はてなブックマーク - Welcome to Apache Pig!" border="0" /></a></li>
<li><a href="http://www.umiacs.umd.edu/~jimmylin/publications/Lin_Kolcz_SIGMOD2012.pdf">Large-Scale Machine Learning at Twitter</a></li>
<li><a href="https://speakerdeck.com/u/lintool/p/large-scale-machine-learning-at-twitter">Large-Scale Machine Learning at Twitter // Speaker Deck</a> <a href="http://b.hatena.ne.jp/entry/s/speakerdeck.com/u/lintool/p/large-scale-machine-learning-at-twitter"><img src="http://b.hatena.ne.jp/entry/image/https://speakerdeck.com/u/lintool/p/large-scale-machine-learning-at-twitter" alt="はてなブックマーク - Large-Scale Machine Learning at Twitter // Speaker Deck" border="0" /></a>
<ul>
<li>UDFsを定義したロジスティック回帰などの学習</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>は以下のような<a class="keyword" href="http://d.hatena.ne.jp/keyword/DSL">DSL</a>で書けてしまう。</li>
</ul></li>
</ul><pre class="code" data-lang="" data-unlink>training = load `training.txt'
using SVMLightStorage()
as (target: int, features: map[]);
store training into `model/'
using FeaturesLRClassifierBuilder();</pre>
</div>
<div class="section">
<h5>独自<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a></h5>

<ul>
<li>自分で<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>を組み込んだ<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>を書く必要がある。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Python">Python</a>などではNumpyやScipyを利用したStreamingを書く事も可能だが手間がかかる。</li>
<li><a href="http://www.cs.stanford.edu/people/ang/papers/nips06-mapreducemulticore.pdf">Map-Reduce for Machine Learning on Multicore</a></li>
<li><a href="http://atbrox.com/2010/02/08/parallel-machine-learning-for-hadoopmapreduce-a-python-example/">Parallel Machine Learning for Hadoop/Mapreduce – A Python Example</a> <a href="http://b.hatena.ne.jp/entry/atbrox.com/2010/02/08/parallel-machine-learning-for-hadoopmapreduce-a-python-example/"><img src="http://b.hatena.ne.jp/entry/image/http://atbrox.com/2010/02/08/parallel-machine-learning-for-hadoopmapreduce-a-python-example/" alt="はてなブックマーク - Parallel Machine Learning for Hadoop/Mapreduce – A Python Example" border="0" /></a></li>
</ul>
</div>
<div class="section">
<h5>その他</h5>

<ul>
<li><a href="http://hama.apache.org/">Hama - a Bulk Synchronous Parallel computing framework on top of Hadoop</a> <a href="http://b.hatena.ne.jp/entry/hama.apache.org/"><img src="http://b.hatena.ne.jp/entry/image/http://hama.apache.org/" alt="はてなブックマーク - Hama - a Bulk Synchronous Parallel computing framework on top of Hadoop" border="0" /></a>
<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/Apache">Apache</a> Hama is a pure BSP (Bulk Synchronous Parallel) computing framework on top of <a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a></li>
<li><a href="https://issues.apache.org/jira/browse/HAMA/component/12318906">Hama: machine learning - ASF JIRA</a> <a href="http://b.hatena.ne.jp/entry/s/issues.apache.org/jira/browse/HAMA/component/12318906"><img src="http://b.hatena.ne.jp/entry/image/https://issues.apache.org/jira/browse/HAMA/component/12318906" alt="はてなブックマーク - Hama: machine learning - ASF JIRA" border="0" /></a></li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>は発展途上なようで今後に期待？！</li>
</ul></li>
<li><a href="http://www.hapyrus.com/">Hapyrus</a> <a href="http://b.hatena.ne.jp/entry/www.hapyrus.com/"><img src="http://b.hatena.ne.jp/entry/image/http://www.hapyrus.com/" alt="はてなブックマーク - Hapyrus" border="0" /></a>
<ul>
<li>お会いした事は無いのですが、元会社の先輩が立ち上げているシステム。まだ使っていません。</li>
</ul></li>
<li><a href="http://www.slideshare.net/yatsuta/tokyowebmining12">Tokyowebmining12</a> <a href="http://b.hatena.ne.jp/entry/www.slideshare.net/yatsuta/tokyowebmining12"><img src="http://b.hatena.ne.jp/entry/image/http://www.slideshare.net/yatsuta/tokyowebmining12" alt="はてなブックマーク - Tokyowebmining12" border="0" /></a>
<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>での並列処理 <a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>関係無し。</li>
</ul></li>
</ul>
</div>
</blockquote>

</div>

