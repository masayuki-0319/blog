
---
title: "10秒で設定可能なlibsvmで機械学習を行う"
date: 2012-08-29T08:41:30+00:00
category : [機械学習]
canonicalurl: http://yut.hatenablog.com/entry/20120829/1346197290
---

## [機械学習] : 10秒で設定可能なlibsvmで機械学習を行う

<p><div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/0387772413/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/31IgiriksFL._SL160_.jpg" class="hatena-asin-detail-image" alt="Support Vector Machines (Information Science and Statistics)" title="Support Vector Machines (Information Science and Statistics)"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/0387772413/yutakikuchi-22/">Support Vector Machines (Information Science and Statistics)</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> Ingo Steinwart,Andreas Christmann</li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> Springer</li><li><span class="hatena-asin-detail-label">発売日:</span> 2008/08/29</li><li><span class="hatena-asin-detail-label">メディア:</span> ハードカバー</li><li> <span class="hatena-asin-detail-label">クリック</span>: 17回</li><li><a href="http://d.hatena.ne.jp/asin/0387772413/yutakikuchi-22" target="_blank">この商品を含むブログを見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

<div class="section">
<h4><a class="keyword" href="http://d.hatena.ne.jp/keyword/libsvm">libsvm</a></h4>

<blockquote>
    
<ul>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM -- A Library for Support Vector Machines</a> <a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/libsvm/"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/libsvm/" alt="はてなブックマーク - LIBSVM -- A Library for Support Vector Machines" border="0" /></a></li>
<li><a href="http://d.hatena.ne.jp/yutakikuchi/20120827/1346024147">R言語でSVM(Support Vector Machine)による分類学習 - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20120827/1346024147"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20120827/1346024147" alt="はてなブックマーク - R言語でSVM(Support Vector Machine)による分類学習 - Yuta.Kikuchiの日記" border="0" /></a></li>
</ul><p>前回Rでの<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>を簡単に紹介しましたが、今日は<a class="keyword" href="http://d.hatena.ne.jp/keyword/libsvm">libsvm</a>を利用したirisの分類学習を行いたいと思います。<a class="keyword" href="http://d.hatena.ne.jp/keyword/libsvm">libsvm</a>は導入がめちゃくちゃ簡単なところが売りだと思います。zipを<a class="keyword" href="http://d.hatena.ne.jp/keyword/libsvm">libsvm</a>サイトから<span class="deco" style="color:#FF0000;">downloadして展開してgmakeで設定完了</span>です。</p>

<div class="section">
<h5>設定</h5>
<pre class="code" data-lang="" data-unlink>$ wget "http://www.csie.ntu.edu.tw/~cjlin/cgi-bin/libsvm.cgi?+http://www.csie.ntu.edu.tw/~cjlin/libsvm+zip"
$ unzip libsvm-3.12.zip
$ cd libsvm-3.12
$ gmake
$ ls
-rw-r--r-- 1 yuta yuta  1497  1月 31  2012 COPYRIGHT
-rw-r--r-- 1 yuta yuta 72186  4月  1 07:17 FAQ.html
-rw-r--r-- 1 yuta yuta   732  1月  2  2012 Makefile
-rw-r--r-- 1 yuta yuta  1087  9月 12  2010 Makefile.win
-rw-r--r-- 1 yuta yuta 27332  2月  3  2012 README
-rw-r--r-- 1 yuta yuta 27670  7月 12  2003 heart_scale
drwxr-xr-x 3 yuta yuta  4096  4月  1 07:18 java
drwxr-xr-x 2 yuta yuta  4096 10月 30  2011 matlab
drwxr-xr-x 2 yuta yuta  4096  3月 22 12:25 python
-rwxr-xr-x 1 yuta yuta 67413  8月 29 07:53 svm-predict
-rw-r--r-- 1 yuta yuta  5381  2月  5  2011 svm-predict.c
-rwxr-xr-x 1 yuta yuta 15650  8月 29 07:53 svm-scale
-rw-r--r-- 1 yuta yuta  7042  5月 28  2011 svm-scale.c
drwxr-xr-x 5 yuta yuta  4096  2月  3  2012 svm-toy
-rwxr-xr-x 1 yuta yuta 71912  8月 29 07:53 svm-train
-rw-r--r-- 1 yuta yuta  8891  5月 27  2011 svm-train.c
-rw-r--r-- 1 yuta yuta 63412 12月 26  2011 svm.cpp
-rw-r--r-- 1 yuta yuta   434  9月 12  2010 svm.def
-rw-r--r-- 1 yuta yuta  3129  2月  3  2012 svm.h
-rw-r--r-- 1 yuta yuta 93208  8月 29 07:53 svm.o
drwxr-xr-x 2 yuta yuta  4096  2月 24  2012 tools
drwxr-xr-x 2 yuta yuta  4096  3月 16 00:44 windows</pre>
</div>
<div class="section">
<h5>scale,train,predictコマンド</h5>
<p>gmakeを行うと以下のコマンドが生成されます。これらのコマンドに対して学習データ,学習Model,評価データを与える事により<a class="keyword" href="http://d.hatena.ne.jp/keyword/SVM">SVM</a>による<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>が実現できます。各種コマンドの使い方については以下のサイトが詳しいと思います。またコマンドに対してaliasを貼っておきます。</p>

<ul>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/svm">svm</a>-scale : データの正規化を行うコマンド</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/svm">svm</a>-train : 学習データからModelを生成するコマンド</li>
<li><a class="keyword" href="http://d.hatena.ne.jp/keyword/svm">svm</a>-predict：評価データとModelから分類とaccuracyを導きだすコマンド</li>
</ul>
<ul>
<li><a href="http://www.okuma.nuee.nagoya-u.ac.jp/~sakaguti/wiki/index.php?LibSVM">LibSVM - 名古屋大学大熊研究室-坂口敦俊-研究業績</a> <a href="http://b.hatena.ne.jp/entry/www.okuma.nuee.nagoya-u.ac.jp/~sakaguti/wiki/index.php?LibSVM"><img src="http://b.hatena.ne.jp/entry/image/http://www.okuma.nuee.nagoya-u.ac.jp/~sakaguti/wiki/index.php?LibSVM" alt="はてなブックマーク - LibSVM - 名古屋大学大熊研究室-坂口敦俊-研究業績" border="0" /></a></li>
<li><a href="http://www.jnlp.org/sannomiya/libsvm">LIBSVM - 長岡技術科学大学 自然言語処理研究室</a> <a href="http://b.hatena.ne.jp/entry/www.jnlp.org/sannomiya/libsvm"><img src="http://b.hatena.ne.jp/entry/image/http://www.jnlp.org/sannomiya/libsvm" alt="はてなブックマーク - LIBSVM - 長岡技術科学大学 自然言語処理研究室" border="0" /></a></li>
</ul><pre class="code" data-lang="" data-unlink>alias svm-predict=/home/yuta/work/libsvm/libsvm-3.12/svm-predict
alias svm-scale=/home/yuta/work/libsvm/libsvm-3.12/svm-scale
alias svm-train=/home/yuta/work/libsvm/libsvm-3.12/svm-train</pre>
</div>
<div class="section">
<h5>irisデータの学習</h5>

<ul>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/">LIBSVM Data: Classification, Regression, and Multi-label</a> <a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/" alt="はてなブックマーク - LIBSVM Data: Classification, Regression, and Multi-label" border="0" /></a></li>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale">iris.scale</a><a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale" alt="はてなブックマーク - " border="0" /></a></li>
<li><a href="http://archive.ics.uci.edu/ml/datasets/Iris">UCI Machine Learning Repository: Iris Data Set</a> <a href="http://b.hatena.ne.jp/entry/archive.ics.uci.edu/ml/datasets/Iris"><img src="http://b.hatena.ne.jp/entry/image/http://archive.ics.uci.edu/ml/datasets/Iris" alt="はてなブックマーク - UCI Machine Learning Repository: Iris Data Set" border="0" /></a></li>
</ul><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/R%B8%C0%B8%EC">R言語</a>には標準でirisのデータが備わっていましたが、<a class="keyword" href="http://d.hatena.ne.jp/keyword/libsvm">libsvm</a>のdataformatに従ったサンプルも以下にあります。<a class="keyword" href="http://d.hatena.ne.jp/keyword/libsvm">libsvm</a>に対しての学習にはiris.scaleのデータはiris.scaleを利用します。Iris Setosa、Iris Versicolour 、Iris Virginicaといった3つのアヤメ種別(class)と蕚片の長さ/幅、花びらの長さ/幅といった4つの特徴(attribute)を持つものです。種別に対しては1から3のラベルを貼り、各種特徴にも特徴番号を付け、-1〜1の正規化した特徴量を持たせています。以下にデータ取得から学習までのコマンドを記載します。<span class="deco" style="color:#FF0000;"><a class="keyword" href="http://d.hatena.ne.jp/keyword/svm">svm</a>-trainコマンドを実行するとiris.scale.modelというmodelファイルが生成されます。</span></p>
<pre class="code" data-lang="" data-unlink>$ wget "http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale"

$ less iris.scale
1 1:-0.555556 2:0.25 3:-0.864407 4:-0.916667 
1 1:-0.666667 2:-0.166667 3:-0.864407 4:-0.916667 
1 1:-0.777778 3:-0.898305 4:-0.916667 
1 1:-0.833333 2:-0.0833334 3:-0.830508 4:-0.916667 
1 1:-0.611111 2:0.333333 3:-0.864407 4:-0.916667 
1 1:-0.388889 2:0.583333 3:-0.762712 4:-0.75 
1 1:-0.833333 2:0.166667 3:-0.864407 4:-0.833333 
1 1:-0.611111 2:0.166667 3:-0.830508 4:-0.916667 
1 1:-0.944444 2:-0.25 3:-0.864407 4:-0.916667 
1 1:-0.666667 2:-0.0833334 3:-0.830508 4:-1 
1 1:-0.388889 2:0.416667 3:-0.830508 4:-0.916667 
1 1:-0.722222 2:0.166667 3:-0.79661 4:-0.916667

$ svm-train iris.scale 
*
optimization finished, #iter = 12
nu = 0.092569
obj = -5.138435, rho = -0.062041
nSV = 11, nBSV = 8
*
optimization finished, #iter = 25
nu = 0.048240
obj = -2.538201, rho = 0.016007
nSV = 8, nBSV = 2
*
optimization finished, #iter = 36
nu = 0.447449
obj = -32.467419, rho = 0.105572
nSV = 46, nBSV = 42
Total nSV = 58

$ ls
drwxr-xr-x 2 yuta yuta 4096  8月 29 09:03 .
drwxr-xr-x 4 yuta yuta 4096  8月 29 08:57 ..
-rw-r--r-- 1 yuta yuta 6954  6月  8  2005 iris.scale
-rw-r--r-- 1 yuta yuta 3226  8月 29 09:03 iris.scale.model</pre>
</div>
<div class="section">
<h5>Modelによる評価</h5>
<p>予測は<a class="keyword" href="http://d.hatena.ne.jp/keyword/svm">svm</a>-predictコマンドで行います。ここでは学習データで使ったデータをそのまま予測用データとして利用します。<a class="keyword" href="http://d.hatena.ne.jp/keyword/svm">svm</a>-predictの第一引数に評価データ、第二引数に学習で生成したmodel、第三引数にラベル付けの結果ファイルを指定します。標準出力でaccuracyが出てくるのでそれをファイルにリダイレクトしておきます。個々の結果ではaccuracyが<span class="deco" style="color:#FF0000;">97%</span>と出ました。</p>
<pre class="code" data-lang="" data-unlink>$ svm-predict iris.scale iris.scale.model iris.scale.output > accuracy.txt
$ less accuracy.txt
Accuracy = 97.3333% (146/150) (classification)</pre>
</div>
<div class="section">
<h5>K-分割交差検定</h5>

<ul>
<li><a href="http://ja.wikipedia.org/wiki/交差検定">交差検定 - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/交差検定"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/交差検定" alt="はてなブックマーク - 交差検定 - Wikipedia" border="0" /></a></li>
</ul><p>上の評価ではaccuracyが97%と出ていますが、学習データと評価データが同じでは本来のModel精度が分からないので、まずは学習データと評価データを分離します。ここでは一般的なCross Validationにしたがって150個のirisサンプルを50個ずつに分割します。50個のデー<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%BF%A5%BB%A5%C3%A5%C8">タセット</a>をA,B,Cというファイルで定義した場合、学習と評価を3パターンで試します。交差検定を"K-fold cross-validation"と呼びますが、ここではK=3となります。</p>

<ul>
<li>学習(A,B) 評価(C)</li>
<li>学習(A,C) 評価(B)</li>
<li>学習(B,C) 評価(A)</li>
</ul><p>行を完全にrandomでshuffleして100行の学習データ/50行の評価データを作成します。</p>
<pre class="code" data-lang="" data-unlink>$ perl -MList::Util=shuffle -e 'print shuffle(<>)' < iris.scale | split -l 50
$ cat xaa xab | wc -l
$ cat xaa xab > 1.train.txt
$ cat xaa xac > 2.train.txt
$ cat xab xac > 3.train.txt
$ mv xac 1.predict.txt
$ mv xab 2.predict.txt
$ mv xaa 3.predict.txt</pre><p>続いて学習と予測、accuracy算出までをやります。下の結果から分かるようにAccuracyの算出が<span class="deco" style="color:#FF0000;">94%、96%、98%</span>といずれも高い数値が出ました。Cross Validationでもかなり高い確率で予測が出来ていると言えます。</p>
<pre class="code" data-lang="" data-unlink>$ svm-train 1.train.txt
$ svm-train 2.train.txt
$ svm-train 3.train.txt
*
optimization finished, #iter = 21
nu = 0.065188
obj = -2.237066, rho = 0.057124
nSV = 7, nBSV = 1
*
optimization finished, #iter = 30
nu = 0.558458
obj = -26.839488, rho = -0.084482
nSV = 39, nBSV = 34
*
optimization finished, #iter = 8
nu = 0.119403
obj = -4.403712, rho = 0.039139
nSV = 10, nBSV = 7
Total nSV = 49
*
optimization finished, #iter = 22
nu = 0.070101
obj = -2.437480, rho = 0.018715
nSV = 8, nBSV = 2
*
optimization finished, #iter = 17
nu = 0.443524
obj = -20.533308, rho = -0.040417
nSV = 30, nBSV = 28
*
optimization finished, #iter = 12
nu = 0.128258
obj = -4.819891, rho = -0.074851
nSV = 11, nBSV = 8
Total nSV = 44
*
optimization finished, #iter = 8
nu = 0.129629
obj = -4.619123, rho = 0.001523
nSV = 11, nBSV = 8
*
optimization finished, #iter = 9
nu = 0.067031
obj = -2.349066, rho = 0.175743
nSV = 9, nBSV = 3
*
optimization finished, #iter = 39
nu = 0.506626
obj = -27.356803, rho = 0.120588
nSV = 38, nBSV = 33
Total nSV = 50

$ svm-predict 1.predict.txt 1.train.txt.model 1.output.txt > 1.accuracy.txt
$ svm-predict 2.predict.txt 2.train.txt.model 2.output.txt > 2.accuracy.txt
$ svm-predict 3.predict.txt 3.train.txt.model 3.output.txt > 3.accuracy.txt

$ less 1.accuracy.txt 
Accuracy = 94% (47/50) (classification)
$ less 2.accuracy.txt 
Accuracy = 96% (48/50) (classification)
$ less 3.accuracy.txt 
Accuracy = 98% (49/50) (classification)</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4>Links</h4>

<blockquote>
    
<ul>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM -- A Library for Support Vector Machines</a> <a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/libsvm/"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/libsvm/" alt="はてなブックマーク - LIBSVM -- A Library for Support Vector Machines" border="0" /></a></li>
<li><a href="http://d.hatena.ne.jp/yutakikuchi/20120827/1346024147">R言語でSVM(Support Vector Machine)による分類学習 - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20120827/1346024147"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20120827/1346024147" alt="はてなブックマーク - R言語でSVM(Support Vector Machine)による分類学習 - Yuta.Kikuchiの日記" border="0" /></a></li>
<li><a href="http://www.okuma.nuee.nagoya-u.ac.jp/~sakaguti/wiki/index.php?LibSVM">LibSVM - 名古屋大学大熊研究室-坂口敦俊-研究業績</a> <a href="http://b.hatena.ne.jp/entry/www.okuma.nuee.nagoya-u.ac.jp/~sakaguti/wiki/index.php?LibSVM"><img src="http://b.hatena.ne.jp/entry/image/http://www.okuma.nuee.nagoya-u.ac.jp/~sakaguti/wiki/index.php?LibSVM" alt="はてなブックマーク - LibSVM - 名古屋大学大熊研究室-坂口敦俊-研究業績" border="0" /></a></li>
<li><a href="http://www.jnlp.org/sannomiya/libsvm">LIBSVM - 長岡技術科学大学 自然言語処理研究室</a> <a href="http://b.hatena.ne.jp/entry/www.jnlp.org/sannomiya/libsvm"><img src="http://b.hatena.ne.jp/entry/image/http://www.jnlp.org/sannomiya/libsvm" alt="はてなブックマーク - LIBSVM - 長岡技術科学大学 自然言語処理研究室" border="0" /></a></li>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/">LIBSVM Data: Classification, Regression, and Multi-label</a> <a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/" alt="はてなブックマーク - LIBSVM Data: Classification, Regression, and Multi-label" border="0" /></a></li>
<li><a href="http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale">iris.scale</a><a href="http://b.hatena.ne.jp/entry/www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale"><img src="http://b.hatena.ne.jp/entry/image/http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/iris.scale" alt="はてなブックマーク - " border="0" /></a></li>
<li><a href="http://archive.ics.uci.edu/ml/datasets/Iris">UCI Machine Learning Repository: Iris Data Set</a> <a href="http://b.hatena.ne.jp/entry/archive.ics.uci.edu/ml/datasets/Iris"><img src="http://b.hatena.ne.jp/entry/image/http://archive.ics.uci.edu/ml/datasets/Iris" alt="はてなブックマーク - UCI Machine Learning Repository: Iris Data Set" border="0" /></a></li>
<li><a href="http://ja.wikipedia.org/wiki/交差検定">交差検定 - Wikipedia</a> <a href="http://b.hatena.ne.jp/entry/ja.wikipedia.org/wiki/交差検定"><img src="http://b.hatena.ne.jp/entry/image/http://ja.wikipedia.org/wiki/交差検定" alt="はてなブックマーク - 交差検定 - Wikipedia" border="0" /></a></li>
</ul>
</blockquote>

</div>

