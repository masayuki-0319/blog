
---
title: "機械学習のOverfitting対策"
date: 2014-11-13T01:40:15+00:00
category : [機械学習]
canonicalurl: http://yut.hatenablog.com/entry/2014/11/13/014015
---

## [機械学習] : 機械学習のOverfitting対策


<div class="section">
<h4>Overfitting対策</h4>

<blockquote>
    <p><a href="http://www.quora.com/How-can-I-avoid-overfitting">How can I avoid overfitting? - Quora</a> <a href="http://b.hatena.ne.jp/entry/www.quora.com/How-can-I-avoid-overfitting"><img src="http://b.hatena.ne.jp/entry/image/http://www.quora.com/How-can-I-avoid-overfitting" alt="はてなブックマーク - How can I avoid overfitting? - Quora" border="0" /></a></p><p><a class="keyword" href="http://d.hatena.ne.jp/keyword/%B5%A1%B3%A3%B3%D8%BD%AC">機械学習</a>で偏った学習データに適合したモデルを評価データに対して利用した場合、精度が悪い結果が得られることがあります。単純にモデルにInputする訓練データが少なかったり、局所領域に存在するデータ扱っていたり、モデルの自由度が高く複雑である事など幾つか原因が考えられ、上のQuoraで解決策について意見が書かれています。ここでは結論として書かれた内容について簡単に紹介します。</p>

<div class="section">
<h5>K-Fold Cross Validation</h5>
<p>単純な解決方法としては学習時に偏ったデータに適合しすぎないように学習データをK個のまとまりに分割して、<a class="keyword" href="http://d.hatena.ne.jp/keyword/K-1">K-1</a>個のデータを用いて学習、残りの1個を用いて評価する作業を組みわせパターン全てで行うというK-Fold Cross Validationという手法が用いられます。こうすることによってデータの偏りは防ぐことができますし、モデルの汎化性能(評価データへの適用能力)を正しく評価することも可能であり、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%CA%A3%BF%F4">複数</a>のモデルからより秀でたモデルを選択する手段としても有効かと思います。</p>

</div>
<div class="section">
<h5>Regularization</h5>
<p>Regularizationは<a class="keyword" href="http://d.hatena.ne.jp/keyword/%B2%E1%B3%D8%BD%AC">過学習</a>を抑止するためのペナルティ項で、モデルのパラメータがより複雑になればなるほど値を大きくする仕組みです。 代表的な例としてL1,L2,L1L2<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>といったものがあり、それぞれ精度やメモリの消費、スパース具合が異なります。よく目にする報告としてはL1がL2よりも計算量が少なく済む(精度が低く、スパースになりがちであるため)があります。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Support%20Vector%20Machine">Support Vector Machine</a>の一つの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C4%A1%BC%A5%EB">ツール</a>であるliblinearを例にとると、学習コマンドであるtrainで学習データを指定すると同時に<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%C2%A7%B2%BD">正則化</a>パラメータを設定することが可能です。<br />
<a class="keyword" href="http://d.hatena.ne.jp/keyword/Support%20Vector%20Machine">Support Vector Machine</a>は特徴ベクトルの「マージン最大化」により分類を行う手法ですが、綺麗にデータを分類できない場合にマージンの具合を決めるための定数Cというものを指定したりします。Cを大きくすると誤りを許さないハードマージン、Cを小さくするとソフトマージンで多少の誤差は許容とするという働きになります。正確にはRegularizationとは異なりますが、役割は似ているところがあります。</p>

</div>
</blockquote>

</div>

