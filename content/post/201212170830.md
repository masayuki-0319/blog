
---
title: "PigでHadoopをより便利に使う！PigでのMapReduceまとめ"
date: 2012-12-17T08:30:37+00:00
category : [Hadoop]
canonicalurl: http://yut.hatenablog.com/entry/20121217/1355700637
---

## [Hadoop] : PigでHadoopをより便利に使う！PigでのMapReduceまとめ

<p><div class="amazlet-box"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873115469/yutakikuchi-22/"><img src="http://ecx.images-amazon.com/images/I/51d3cV8bDwL._SL160_.jpg" class="hatena-asin-detail-image" alt="Hadoop Hacks ―プロフェッショナルが使う実践テクニック" title="Hadoop Hacks ―プロフェッショナルが使う実践テクニック"></a><div class="hatena-asin-detail-info"><p class="hatena-asin-detail-title"><a href="http://www.amazon.co.jp/exec/obidos/ASIN/4873115469/yutakikuchi-22/">Hadoop Hacks ―プロフェッショナルが使う実践テクニック</a></p><ul><li><span class="hatena-asin-detail-label">作者:</span> 中野猛,山下真一,猿田浩輔,上新卓也,<a class="keyword" href="http://d.hatena.ne.jp/keyword/%BE%AE%CE%D3%CE%B4">小林隆</a></li><li><span class="hatena-asin-detail-label">出版社/メーカー:</span> <a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AA%A5%E9%A5%A4%A5%EA%A1%BC%A5%B8%A5%E3%A5%D1%A5%F3">オライリージャパン</a></li><li><span class="hatena-asin-detail-label">発売日:</span> 2012/04/25</li><li><span class="hatena-asin-detail-label">メディア:</span> 単行本（ソフトカバー）</li><li><span class="hatena-asin-detail-label">購入</span>: 3人 <span class="hatena-asin-detail-label">クリック</span>: 156回</li><li><a href="http://d.hatena.ne.jp/asin/4873115469/yutakikuchi-22" target="_blank">この商品を含むブログ (8件) を見る</a></li></ul></div><div class="hatena-asin-detail-foot"></div></div></p>

<div class="section">
<h4>Pig</h4>

<blockquote>
    <p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a>の<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>を独自で記述するのは手間が掛かります。それらの手間を出来るだけ緩和させるための便利な<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%C4%A1%BC%A5%EB">ツール</a>として<a class="keyword" href="http://d.hatena.ne.jp/keyword/DSL">DSL</a>形式の処理フローを定義する事で<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>を実行するHiveやPIgというものが存在します。HiveとPigはライバルブロジェクトのようで、本日紹介するPigは<a class="keyword" href="http://d.hatena.ne.jp/keyword/Yahoo%21">Yahoo!</a>が開発している<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%DF%A5%C9%A5%EB%A5%A6%A5%A7%A5%A2">ミドルウェア</a>になります。Hiveについては以前簡単に紹介をしたので以下のリンクを参考にしてください。PigLatinという手続き型の文法でDataのload/filter/join/sort/group/join/limit/storeなどの処理を組み合わせ、inputからoutputまでの一連の<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>を定義する事ができます。<a class="keyword" href="http://d.hatena.ne.jp/keyword/Java">Java</a>やStreamingでの<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>では目的のデータを抽出するために多段<a class="keyword" href="http://d.hatena.ne.jp/keyword/MapReduce">MapReduce</a>処理を記述する事もありますが、PigやHiveを使うと1回の実行で済んだりします。<br />
<a href="http://d.hatena.ne.jp/yutakikuchi/20111219/1324251034">Hadoopをより便利に使う！HiveでのMapReduceまとめ - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20111219/1324251034"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20111219/1324251034" alt="はてなブックマーク - Hadoopをより便利に使う！HiveでのMapReduceまとめ - Yuta.Kikuchiの日記" border="0" /></a></p>

</blockquote>

</div>
<div class="section">
<h4>Pigの実行</h4>

<blockquote>
    
<div class="section">
<h5>Install</h5>
<p><a class="keyword" href="http://d.hatena.ne.jp/keyword/Centos">Centos</a>でInstallする内容については以前まとめたので、詳しくはそちらを参照してください。<br />
<a href="http://d.hatena.ne.jp/yutakikuchi/20111205/1323041424">CentOSでHadoopを使ってみる - Yuta.Kikuchiの日記</a> <a href="http://b.hatena.ne.jp/entry/d.hatena.ne.jp/yutakikuchi/20111205/1323041424"><img src="http://b.hatena.ne.jp/entry/image/http://d.hatena.ne.jp/yutakikuchi/20111205/1323041424" alt="はてなブックマーク - CentOSでHadoopを使ってみる - Yuta.Kikuchiの日記" border="0" /></a><br />
必要な<a class="keyword" href="http://d.hatena.ne.jp/keyword/yum">yum</a> installは以下のものになります。</p>
<pre class="code" data-lang="" data-unlink>$ yum install hadoop-0.20 -y
$ yum install hadoop-0.20-conf-pseudo -y
$ yum install hadoop-pig -y</pre>
</div>
<div class="section">
<h5>PigLatin</h5>
<p><a href="http://pig.apache.org/docs/r0.10.0/basic.html">Pig Latin Basics</a> <a href="http://b.hatena.ne.jp/entry/pig.apache.org/docs/r0.10.0/basic.html"><img src="http://b.hatena.ne.jp/entry/image/http://pig.apache.org/docs/r0.10.0/basic.html" alt="はてなブックマーク - Pig Latin Basics" border="0" /></a><br />
PigLatinとはPigの便利な文法のことです。ここでは代表的なLatinをいくつか紹介します。</p>

<table>
<tr>
<th> 文法 </th>
<th> 役割 </th>
<td> </td>
</tr>
<tr>
<td> LOAD </td>
<td> データの<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%A1%A5%A4%A5%EB%A5%B7%A5%B9%A5%C6%A5%E0">ファイルシステム</a>から読み込み </td>
</tr>
<tr>
<td> STORE </td>
<td> データを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%D5%A5%A1%A5%A4%A5%EB%A5%B7%A5%B9%A5%C6%A5%E0">ファイルシステム</a>に保存する  </td>
</tr>
<tr>
<td> DUMP </td>
<td> 結果をコンソールに出力する </td>
</tr>
<tr>
<td> FILTER </td>
<td> 条件を指定しデータのフィルタリングを行う </td>
<td> </td>
</tr>
<tr>
<td> MATCHES </td>
<td> データを<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%B5%AC%C9%BD%B8%BD">正規表現</a>の条件でフィルタリングする </td>
</tr>
<tr>
<td> FOREACH </td>
<td> 繰り返しデータ変換を行う </td>
</tr>
<tr>
<td> SPLIT </td>
<td> データのを分割する </td>
</tr>
<tr>
<td> JOIN </td>
<td> データの結合を行う </td>
</tr>
<tr>
<td> GROUP </td>
<td> データのグループ化を行う </td>
</tr>
<tr>
<td> ORDER </td>
<td> データをソートする </td>
</tr>
<tr>
<td> DISTINCT </td>
<td> データの重複を排除する </td>
</tr>
<tr>
<td> LIMIT </td>
<td> データの出力件数を制限する </td>
</tr>
<tr>
<td> SAMPLE </td>
<td> データのサンプリングを行う </td>
</tr>
</table>
</div>
<div class="section">
<h5>LocalModeで実行</h5>
<p>Pigはlocalmodeとmapreducemodeをそれぞれ実行で切り分ける事が出来ます。localmodeはjobを投げるサーバの1台で、データのLoad/Storeもローカルサーバのものに対して行います。mapreducemodeは<a class="keyword" href="http://d.hatena.ne.jp/keyword/HDFS">HDFS</a>上のデータを利用し、全<a class="keyword" href="http://d.hatena.ne.jp/keyword/Hadoop">Hadoop</a><a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%AF%A5%E9%A5%B9%A5%BF">クラスタ</a>に対して分散処理を行うモードになります。localで実行したい場合は-x localというオプションを起動時に設定します。pigコマンドを実行すると対話コンソールが出力されます。</p>
<pre class="code" data-lang="" data-unlink>$ man pig
   -x, -exectype=[local|mapreduce]
          execution type; mapreduce is default

$ pig -x local
2012-12-15 02:28:51,942 [main] INFO  org.apache.pig.Main - Logging error messages to: /home/yuta/pig_1355506131872.log
2012-12-15 02:28:52,375 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///
grunt> </pre>
</div>
<div class="section">
<h5>Pig Practice</h5>
<p>テストとして以下のようなTab区切りのデータをinput.txtとして用意し、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%C0%B5%B5%AC%C9%BD%B8%BD">正規表現</a>の条件にマッチした行を抽出し、outputとして保存するような処理を実行します。</p>
<pre class="code" data-lang="" data-unlink>$ cat intput.txt
Sample1  1981  1/1   11:00
Sample2  1982  1/2   12:00
Sample3  1983  1/3   13:00

$ pig -x local
grunt> input_data = LOAD 'input.txt';
(Sample1  1981  1/1   11:00)
(Sample2  1982  1/2   12:00)
(Sample3  1983  1/3   13:00)

grunt> filter_data = FILTER input_data BY $0 MATCHES '.*1983.*';
grunt> DUMP filter_data;
(Sample3  1983  1/3   13:00)
grunt> STORE filter_data INTO 'output';  
grunt> quit

$ cat output/part-m-00000 
Sample3  1983  1/3   13:00</pre><p>PigStorage関数を使う事によって指定したDelimiterによるデータの分離と、分離したデータをリレーションに格納してくれます。分離後のデータはAS(リレーション名:データ型)のように定義し、データ型はchararayが文字列、intが整数、floatが実数です。</p>
<pre class="code" data-lang="" data-unlink>grunt> input_data = LOAD 'input.txt' USING PigStorage() AS (label:chararray,year:int,day:chararray,time:chararray);
grunt> filter_data = FILTER input_data BY year != 1981 AND date != '1/2' AND time == '13:00';
grunt> DUMP filter_data; 
(Sample3,1983,1/3,13:00)</pre><p>Filterした結果をGroup化させます。</p>
<pre class="code" data-lang="" data-unlink>grunt> input_data = LOAD 'input.txt' USING PigStorage() AS (label:chararray,year:int,day:chararray,time:chararray);
grunt> filter_data = FILTER input_data BY label MATCHES '.*Sample.*';
grunt> DUMP filter_data;
(Sample1,1981,1/1,11:00)
(Sample2,1982,1/2,12:00)
(Sample3,1983,1/3,13:00)
(Sample4,1983,1/4,14:00)
(Sample5,1983,1/5,15:00)
grunt> group_data = GROUP filter_data BY year;
grunt> DUMP group_data;
(1981,{(Sample1,1981,1/1,11:00)})
(1982,{(Sample2,1982,1/2,12:00)})
(1983,{(Sample3,1983,1/3,13:00),(Sample4,1983,1/4,14:00),(Sample5,1983,1/5,15:00)})</pre><p>Group化した結果を繰り返しのFOREACHを利用する事でGROUP内の最大値を求めます。</p>
<pre class="code" data-lang="" data-unlink>grunt> input_data = LOAD 'input.txt' USING PigStorage() AS (label:chararray,year:int,day:chararray,time:chararray);
grunt> group_data = GROUP input_data BY year;
grunt> max_data = FOREACH group_data GENERATE group, MAX(input_data.time);
grunt> DUMP max_data;
(1981,11:00)
(1982,12:00)
(1983,15:00)</pre><p>Filterした結果を降順にソートします。</p>
<pre class="code" data-lang="" data-unlink>grunt> input_data = LOAD 'input.txt' USING PigStorage() AS (label:chararray,year:int,day:chararray,time:chararray);
grunt> filter_data = FILTER input_data BY label MATCHES '.*Sample.*';
grunt> order_data = ORDER filter_data BY year DESC;
grunt> DUMP order_data;
(Sample3,1983,1/3,13:00)
(Sample4,1983,1/4,14:00)
(Sample5,1983,1/5,15:00)
(Sample2,1982,1/2,12:00)
(Sample1,1981,1/1,11:00)</pre>
</div>
<div class="section">
<h5>外部<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EA%A5%D7%A5%C8">スクリプト</a>に保存して実行</h5>
<p>Pigの実行は対話的なコンソールだけでなく、<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EA%A5%D7%A5%C8">スクリプト</a>を外部ファイルとして保存してコマンドに流すこともできます。</p>
<pre class="code" data-lang="" data-unlink>$ cat file.pig
input_data = LOAD 'input.txt' USING PigStorage() AS (label:chararray,year:int,day:chararray,time:chararray);
filter_data = FILTER input_data BY label MATCHES '.*Sample.*';
group_data = GROUP filter_data BY year;
DUMP group_data;

$ pig -x local file.pig
(1981,{(Sample1,1981,1/1,11:00)})
(1982,{(Sample2,1982,1/2,12:00)})
(1983,{(Sample3,1983,1/3,13:00),(Sample4,1983,1/4,14:00),(Sample5,1983,1/5,15:00)})</pre><p>外部<a class="keyword" href="http://d.hatena.ne.jp/keyword/%A5%B9%A5%AF%A5%EA%A5%D7%A5%C8">スクリプト</a>に対して必要なパラメータを設定したり、デフォルトの変数を設定する事ができます。パラメータの設定には-paramオプションを利用、デフォルト変数を利用するためには%defaultを使います。</p>
<pre class="code" data-lang="" data-unlink>$ cat test.pig
%default INPUT input.txt 
%default OUTPUT /home/yuta/work/pig/result  

input_data = LOAD '$INPUT' USING PigStorage() AS (label:chararray,year:int,day:chararray,time:chararray);
group_data = GROUP input_data BY year;
max_data = FOREACH group_data GENERATE group, MAX(input_data.time);
STORE max_data INTO '$OUTPUT';

$ pig -x local -param INPUT=input.txt -param OUTPUT=/home/yuta/work/pig/result test.pig
$ cat /home/yuta/work/pig/result/part-r-00000
1981 	11:00
1982 	12:00
1983 	15:00</pre>
</div>
</blockquote>

</div>
<div class="section">
<h4>Links</h4>

<blockquote>
    
<ul>
<li><a href="http://pig.apache.org/docs/r0.10.0/basic.html">Pig Latin Basics</a> <a href="http://b.hatena.ne.jp/entry/pig.apache.org/docs/r0.10.0/basic.html"><img src="http://b.hatena.ne.jp/entry/image/http://pig.apache.org/docs/r0.10.0/basic.html" alt="はてなブックマーク - Pig Latin Basics" border="0" /></a></li>
<li><a href="http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html">Pig Latin Reference Manual 2</a> <a href="http://b.hatena.ne.jp/entry/pig.apache.org/docs/r0.7.0/piglatin_ref2.html"><img src="http://b.hatena.ne.jp/entry/image/http://pig.apache.org/docs/r0.7.0/piglatin_ref2.html" alt="はてなブックマーク - Pig Latin Reference Manual 2" border="0" /></a></li>
<li><a href="http://www.ibm.com/developerworks/jp/linux/library/l-apachepigdataquery/">Apache Pig でデータを処理する</a> <a href="http://b.hatena.ne.jp/entry/www.ibm.com/developerworks/jp/linux/library/l-apachepigdataquery/"><img src="http://b.hatena.ne.jp/entry/image/http://www.ibm.com/developerworks/jp/linux/library/l-apachepigdataquery/" alt="はてなブックマーク - Apache Pig でデータを処理する" border="0" /></a></li>
</ul>
</blockquote>

</div>

